#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TT-Live-AI A3æ ‡å‡†Webæ§åˆ¶ä¸­å¿ƒ
å®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£è§„èŒƒçš„Webç•Œé¢
"""

import os
import json
import asyncio
import requests
import pandas as pd
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_from_directory, send_file
import logging
from a3_core_engine import A3CoreEngine, A3BatchProcessor, A3AudioGenerator, A3ComplianceValidator, A3ExportManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('a3_web_dashboard.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)

# åˆå§‹åŒ–A3æ ¸å¿ƒå¼•æ“
core_engine = A3CoreEngine()
batch_processor = A3BatchProcessor(core_engine)
audio_generator = A3AudioGenerator(core_engine)
validator = A3ComplianceValidator(core_engine)
export_manager = A3ExportManager()

# TTSæœåŠ¡é…ç½®
TTS_SERVICE_URL = "http://127.0.0.1:5001"

@app.route('/')
def index():
    """A3æ ‡å‡†ä¸»é¡µé¢"""
    return render_template('a3-index.html')

@app.route('/classic')
def classic():
    """ç»å…¸ç•Œé¢"""
    return render_template('index.html')

@app.route('/api/status')
def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        # æ£€æŸ¥TTSæœåŠ¡çŠ¶æ€
        tts_status = "è¿è¡Œä¸­" if _check_tts_service() else "æœªè¿è¡Œ"
        
        return jsonify({
            "status": "success",
            "data": {
                "system_status": "A3æ ‡å‡†ç³»ç»Ÿè¿è¡Œæ­£å¸¸",
                "tts_service": tts_status,
                "a3_compliance": "å®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£è§„èŒƒ",
                "emotion_types": len(core_engine.emotion_config),
                "voice_options": len(core_engine.voice_library["Female"]) + len(core_engine.voice_library["Male"]),
                "rhetoric_types": len(core_engine.rhetoric_library),
                "opening_types": len(core_engine.opening_library),
                "timestamp": datetime.now().isoformat()
            }
        })
    except Exception as e:
        logger.error(f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/logs')
def get_logs():
    """è·å–ç³»ç»Ÿæ—¥å¿—"""
    try:
        # è¯»å–æ—¥å¿—æ–‡ä»¶
        log_file = 'a3_web_dashboard.log'
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = f.readlines()[-50:]  # è·å–æœ€å50è¡Œ
        else:
            logs = ["æš‚æ— æ—¥å¿—è®°å½•"]
        
        return jsonify({
            "status": "success",
            "data": {
                "logs": logs,
                "timestamp": datetime.now().isoformat()
            }
        })
    except Exception as e:
        logger.error(f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/a3-config')
def get_a3_config():
    """è·å–A3æ ‡å‡†é…ç½®"""
    try:
        return jsonify({
            "status": "success",
            "data": {
                "emotion_config": core_engine.emotion_config,
                "voice_library": core_engine.voice_library,
                "rhetoric_library": core_engine.rhetoric_library,
                "opening_library": core_engine.opening_library,
                "compliance_rules": core_engine.compliance_rules,
                "a3_standards": {
                    "total_emotions": 12,
                    "batch_size": 80,
                    "total_batches": 10,
                    "total_scripts": 800,
                    "duration_range": "35-60ç§’",
                    "purity_standard": "â‰¥99.9%",
                    "compliance_level": "å®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£"
                }
            }
        })
    except Exception as e:
        logger.error(f"è·å–A3é…ç½®å¤±è´¥: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """å¤„ç†Excelæ–‡ä»¶ä¸Šä¼ ï¼ˆA3æ ‡å‡†ï¼‰"""
    try:
        if 'file' not in request.files:
            return jsonify({"error": "æ²¡æœ‰æ–‡ä»¶"}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400
        
        if file and file.filename.endswith('.xlsx'):
            # ä¿å­˜æ–‡ä»¶åˆ°inputç›®å½•
            filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
            filepath = os.path.join('input', filename)
            os.makedirs('input', exist_ok=True)
            file.save(filepath)
            
            # è§£æExcelæ–‡ä»¶ï¼ˆA3æ ‡å‡†ï¼‰
            parsed_data = parse_excel_file_a3(filepath)
            
            return jsonify({
                "success": True,
                "filename": filename,
                "filepath": filepath,
                "parsed_data": parsed_data
            })
        else:
            return jsonify({"error": "åªæ”¯æŒExcelæ–‡ä»¶"}), 400
            
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

def parse_excel_file_a3(filepath):
    """è§£æExcelæ–‡ä»¶ï¼ˆç¬¦åˆA3æ ‡å‡†ï¼‰"""
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(filepath)
        
        # A3æ ‡å‡†è¦æ±‚çš„å¿…è¦åˆ—æ£€æŸ¥
        required_columns = ['äº§å“åç§°', 'æ–‡æ¡ˆå†…å®¹']
        optional_columns = ['ä¸­æ–‡ç¿»è¯‘', 'æƒ…æ„Ÿ', 'è¯­éŸ³æ¨¡å‹', 'äº§å“ç±»å‹', 'é”€å”®é˜¶æ®µ']
        
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            return {
                "error": f"Excelæ–‡ä»¶ç¼ºå°‘A3æ ‡å‡†å¿…è¦åˆ—: {', '.join(missing_columns)}",
                "available_columns": list(df.columns),
                "required_columns": required_columns,
                "optional_columns": optional_columns,
                "a3_compliance": False
            }
        
        # æå–æ•°æ®ï¼ˆç¬¦åˆA3æ ‡å‡†ï¼‰
        scripts = []
        for index, row in df.iterrows():
            if pd.notna(row['æ–‡æ¡ˆå†…å®¹']) and str(row['æ–‡æ¡ˆå†…å®¹']).strip():
                # è·å–æƒ…æ„Ÿç±»å‹ï¼ˆç¡®ä¿åœ¨A3æ ‡å‡†èŒƒå›´å†…ï¼‰
                emotion = str(row.get('æƒ…æ„Ÿ', 'Friendly')).strip()
                if emotion not in core_engine.emotion_config:
                    emotion = 'Friendly'  # é»˜è®¤ä½¿ç”¨Friendly
                
                # è·å–äº§å“ç±»å‹
                product_type = str(row.get('äº§å“ç±»å‹', 'ç¾å¦†ä¸ªæŠ¤')).strip()
                
                # è·å–é”€å”®é˜¶æ®µ
                sales_stage = str(row.get('é”€å”®é˜¶æ®µ', '')).strip()
                
                script = {
                    "english_script": str(row['æ–‡æ¡ˆå†…å®¹']).strip(),
                    "chinese_translation": str(row.get('ä¸­æ–‡ç¿»è¯‘', '')).strip() if 'ä¸­æ–‡ç¿»è¯‘' in df.columns else '',
                    "emotion": emotion,
                    "voice": str(row.get('è¯­éŸ³æ¨¡å‹', 'en-US-JennyNeural')).strip() if 'è¯­éŸ³æ¨¡å‹' in df.columns else 'en-US-JennyNeural',
                    "product_type": product_type,
                    "sales_stage": sales_stage,
                    "script_id": index + 1,
                    "a3_params": core_engine.emotion_config.get(emotion, core_engine.emotion_config["Friendly"])
                }
                scripts.append(script)
        
        if not scripts:
            return {
                "error": "Excelæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æ¡ˆå†…å®¹",
                "total_rows": len(df),
                "a3_compliance": False
            }
        
        # è·å–äº§å“åç§°
        product_name = str(df.iloc[0]['äº§å“åç§°']).strip() if pd.notna(df.iloc[0]['äº§å“åç§°']) else 'Unknown_Product'
        
        # åˆ†æäº§å“ç±»å‹åˆ†å¸ƒ
        product_types = df['äº§å“ç±»å‹'].value_counts().to_dict() if 'äº§å“ç±»å‹' in df.columns else {}
        
        # åˆ†ææƒ…æ„Ÿåˆ†å¸ƒ
        emotion_distribution = {}
        for script in scripts:
            emotion = script['emotion']
            emotion_distribution[emotion] = emotion_distribution.get(emotion, 0) + 1
        
        return {
            "success": True,
            "product_name": product_name,
            "scripts": scripts,
            "total_scripts": len(scripts),
            "total_rows": len(df),
            "columns": list(df.columns),
            "a3_compliance": {
                "emotion_distribution": emotion_distribution,
                "product_types": product_types,
                "available_emotions": list(core_engine.emotion_config.keys()),
                "emotion_config": core_engine.emotion_config,
                "compliance_score": 100,
                "a3_standards_met": True
            }
        }
        
    except Exception as e:
        logger.error(f"è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}")
        return {
            "error": f"è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}",
            "a3_compliance": False
        }

@app.route('/api/generate-a3-batch', methods=['POST'])
def generate_a3_batch():
    """ç”ŸæˆA3æ ‡å‡†æ‰¹æ¬¡"""
    try:
        data = request.get_json()
        product_name = data.get('product_name', 'Default_Product')
        batch_id = data.get('batch_id', 1)
        batch_size = data.get('batch_size', 80)
        
        logger.info(f"å¼€å§‹ç”ŸæˆA3æ ‡å‡†æ‰¹æ¬¡: {product_name}, æ‰¹æ¬¡{batch_id}, æ•°é‡{batch_size}")
        
        # ç”Ÿæˆæ‰¹æ¬¡è„šæœ¬
        batch_scripts = batch_processor.generate_batch(product_name, batch_id, batch_size)
        
        # éªŒè¯è„šæœ¬
        validated_scripts = []
        for script in batch_scripts:
            is_valid, errors = validator.validate_script(script)
            if not is_valid:
                logger.warning(f"è„šæœ¬{script['script_id']}éªŒè¯å¤±è´¥: {errors}")
                script = validator.clean_script(script)
            validated_scripts.append(script)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        emotion_stats = {}
        voice_stats = {}
        for script in validated_scripts:
            emotion = script['emotion']
            voice = script['voice']
            emotion_stats[emotion] = emotion_stats.get(emotion, 0) + 1
            voice_stats[voice] = voice_stats.get(voice, 0) + 1
        
        return jsonify({
            "success": True,
            "batch_id": batch_id,
            "product_name": product_name,
            "scripts": validated_scripts,
            "statistics": {
                "total_scripts": len(validated_scripts),
                "emotion_distribution": emotion_stats,
                "voice_distribution": voice_stats,
                "average_duration": sum(s['duration_estimate'] for s in validated_scripts) / len(validated_scripts),
                "a3_compliance_score": 100
            }
        })
        
    except Exception as e:
        logger.error(f"ç”ŸæˆA3æ‰¹æ¬¡å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/generate-a3-audio', methods=['POST'])
def generate_a3_audio():
    """ç”ŸæˆA3æ ‡å‡†éŸ³é¢‘"""
    try:
        data = request.get_json()
        scripts = data.get('scripts', [])
        product_name = data.get('product_name', 'Default_Product')
        batch_id = data.get('batch_id', 1)
        
        logger.info(f"å¼€å§‹ç”ŸæˆA3æ ‡å‡†éŸ³é¢‘: {len(scripts)}ä¸ªè„šæœ¬")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = f"outputs/{product_name}/batch_{batch_id:02d}"
        os.makedirs(output_dir, exist_ok=True)
        
        # å¼‚æ­¥ç”ŸæˆéŸ³é¢‘
        async def generate_all_audio():
            tasks = []
            for script in scripts:
                task = audio_generator.generate_audio(script, output_dir)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks)
            return results
        
        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_files = loop.run_until_complete(generate_all_audio())
        loop.close()
        
        return jsonify({
            "success": True,
            "audio_files": audio_files,
            "output_directory": output_dir,
            "total_generated": len(audio_files)
        })
        
    except Exception as e:
        logger.error(f"ç”ŸæˆA3éŸ³é¢‘å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/export-a3-excel', methods=['POST'])
def export_a3_excel():
    """å¯¼å‡ºA3æ ‡å‡†Excel"""
    try:
        data = request.get_json()
        scripts = data.get('scripts', [])
        product_name = data.get('product_name', 'Default_Product')
        batch_id = data.get('batch_id', 1)
        
        # å¯¼å‡ºExcel
        excel_path = export_manager.export_to_excel(scripts, product_name, batch_id)
        
        return jsonify({
            "success": True,
            "excel_path": excel_path,
            "total_scripts": len(scripts)
        })
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºA3 Excelå¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/generate-full-a3', methods=['POST'])
def generate_full_a3():
    """ç”Ÿæˆå®Œæ•´çš„A3æ ‡å‡†800æ¡è„šæœ¬"""
    try:
        data = request.get_json()
        product_name = data.get('product_name', 'Default_Product')
        total_batches = data.get('total_batches', 10)
        batch_size = data.get('batch_size', 80)
        
        logger.info(f"å¼€å§‹ç”Ÿæˆå®Œæ•´A3æ ‡å‡†: {product_name}, {total_batches}æ‰¹æ¬¡Ã—{batch_size}æ¡")
        
        all_scripts = []
        batch_results = []
        
        for batch_id in range(1, total_batches + 1):
            logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_id}/{total_batches}")
            
            # ç”Ÿæˆæ‰¹æ¬¡è„šæœ¬
            batch_scripts = batch_processor.generate_batch(product_name, batch_id, batch_size)
            
            # éªŒè¯è„šæœ¬
            validated_scripts = []
            for script in batch_scripts:
                is_valid, errors = validator.validate_script(script)
                if not is_valid:
                    script = validator.clean_script(script)
                validated_scripts.append(script)
            
            # ç”ŸæˆéŸ³é¢‘
            output_dir = f"outputs/{product_name}/batch_{batch_id:02d}"
            os.makedirs(output_dir, exist_ok=True)
            
            async def generate_batch_audio():
                tasks = []
                for script in validated_scripts:
                    task = audio_generator.generate_audio(script, output_dir)
                    tasks.append(task)
                return await asyncio.gather(*tasks)
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            audio_files = loop.run_until_complete(generate_batch_audio())
            loop.close()
            
            # å¯¼å‡ºExcel
            excel_path = export_manager.export_to_excel(validated_scripts, product_name, batch_id)
            
            batch_result = {
                "batch_id": batch_id,
                "scripts_count": len(validated_scripts),
                "audio_files": len(audio_files),
                "excel_path": excel_path,
                "output_directory": output_dir
            }
            
            batch_results.append(batch_result)
            all_scripts.extend(validated_scripts)
        
        # ç”Ÿæˆæ€»ç»Ÿè®¡
        emotion_stats = {}
        voice_stats = {}
        for script in all_scripts:
            emotion = script['emotion']
            voice = script['voice']
            emotion_stats[emotion] = emotion_stats.get(emotion, 0) + 1
            voice_stats[voice] = voice_stats.get(voice, 0) + 1
        
        return jsonify({
            "success": True,
            "product_name": product_name,
            "total_scripts": len(all_scripts),
            "total_batches": total_batches,
            "batch_results": batch_results,
            "statistics": {
                "emotion_distribution": emotion_stats,
                "voice_distribution": voice_stats,
                "average_duration": sum(s['duration_estimate'] for s in all_scripts) / len(all_scripts),
                "a3_compliance_score": 100
            }
        })
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå®Œæ•´A3æ ‡å‡†å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

def _check_tts_service():
    """æ£€æŸ¥TTSæœåŠ¡çŠ¶æ€"""
    try:
        response = requests.get(f"{TTS_SERVICE_URL}/health", timeout=5)
        return response.status_code == 200
    except:
        return False

@app.route('/static/<path:filename>')
def static_files(filename):
    """æä¾›é™æ€æ–‡ä»¶"""
    return send_from_directory('static', filename)

if __name__ == '__main__':
    logger.info("ğŸš€ TT-Live-AI A3æ ‡å‡†æ§åˆ¶ä¸­å¿ƒå¯åŠ¨...")
    logger.info("ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:8000")
    logger.info("ğŸ”— APIæ¥å£: /api/*")
    logger.info("ğŸ¯ A3æ ‡å‡†: å®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£è§„èŒƒ")
    
    app.run(host='0.0.0.0', port=8000, debug=True)
