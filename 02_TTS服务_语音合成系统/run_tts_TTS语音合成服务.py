#!/usr/bin/env python3
"""
TT-Live-AI A3-TK å£æ’­ç”Ÿæˆç³»ç»Ÿ - Flask ä¸»æœåŠ¡
æ”¯æŒæ‰¹é‡è¯­éŸ³ç”Ÿæˆã€å¤šäº§å“å¹¶è¡Œå¤„ç†ã€è‡ªåŠ¨å‚æ•°æ˜ å°„
"""
import os
import json
import asyncio
import edge_tts
import pandas as pd
from datetime import datetime
from flask import Flask, request, jsonify
from concurrent.futures import ThreadPoolExecutor
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/tts_service.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# è¯­éŸ³å‚æ•°æ˜ å°„è¡¨ï¼ˆTT-Live-AI æ ‡å‡†ï¼‰
EMOTION_PARAMS = {
    "Excited": {"rate": "+15%", "pitch": "+12Hz", "volume": "+15%"},
    "Confident": {"rate": "+8%", "pitch": "+5Hz", "volume": "+8%"},
    "Empathetic": {"rate": "-12%", "pitch": "-8Hz", "volume": "-10%"},
    "Calm": {"rate": "-10%", "pitch": "-3Hz", "volume": "+0%"},
    "Playful": {"rate": "+18%", "pitch": "+15Hz", "volume": "+5%"},
    "Urgent": {"rate": "+22%", "pitch": "+8Hz", "volume": "+18%"},
    "Authoritative": {"rate": "+5%", "pitch": "+3Hz", "volume": "+10%"},
    "Friendly": {"rate": "+12%", "pitch": "+8Hz", "volume": "+5%"},
    "Inspirational": {"rate": "+10%", "pitch": "+10Hz", "volume": "+12%"},
    "Serious": {"rate": "+0%", "pitch": "+0Hz", "volume": "+5%"},
    "Mysterious": {"rate": "-8%", "pitch": "+5Hz", "volume": "-5%"},
    "Grateful": {"rate": "+5%", "pitch": "+8Hz", "volume": "+8%"}
}

# è¯­éŸ³æ¨¡å‹æ± ï¼ˆæ”¯æŒå¤šç§è¯­éŸ³æ¨¡å‹ï¼‰
VOICE_MODELS = {
    # å¥³æ€§è¯­éŸ³æ¨¡å‹
    "en-US-AmandaMultilingualNeural": {"gender": "å¥³æ€§", "style": "Clear, Bright, Youthful", "name": "é˜¿æ›¼è¾¾", "description": "æ¸…æ™°ã€æ˜äº®ã€å¹´è½»"},
    "en-US-AriaNeural": {"gender": "å¥³æ€§", "style": "Crisp, Bright, Clear", "name": "é˜¿é‡Œäºš", "description": "æ¸…è„†ã€æ˜äº®ã€æ¸…æ™°"},
    "en-US-AvaNeural": {"gender": "å¥³æ€§", "style": "Pleasant, Friendly, Caring", "name": "è‰¾å¨ƒ", "description": "ä»¤äººæ„‰æ‚¦ã€å‹å¥½ã€å…³æ€€"},
    "en-US-EmmaNeural": {"gender": "å¥³æ€§", "style": "Cheerful, Light-Hearted, Casual", "name": "è‰¾ç›", "description": "å¿«ä¹ã€è½»æ¾ã€éšæ„"},
    "en-US-JennyNeural": {"gender": "å¥³æ€§", "style": "Sincere, Pleasant, Approachable", "name": "çå¦®", "description": "çœŸè¯šã€æ„‰å¿«ã€æ˜“æ¥è¿‘"},
    "en-US-MichelleNeural": {"gender": "å¥³æ€§", "style": "Confident, Authentic, Warm", "name": "ç±³æ­‡å°”", "description": "è‡ªä¿¡ã€çœŸå®ã€æ¸©æš–"},
    "en-US-NancyNeural": {"gender": "å¥³æ€§", "style": "Confident, Serious, Mature", "name": "å—å¸Œ", "description": "è‡ªä¿¡ã€ä¸¥è‚ƒã€æˆç†Ÿ"},
    "en-US-SerenaNeural": {"gender": "å¥³æ€§", "style": "Formal, Confident, Mature", "name": "å¡é›·å¨œ", "description": "æ­£å¼ã€è‡ªä¿¡ã€æˆç†Ÿ"},
    "en-US-AshleyNeural": {"gender": "å¥³æ€§", "style": "Sincere, Approachable, Honest", "name": "é˜¿ä»€è‰", "description": "çœŸè¯šã€æ˜“æ¥è¿‘ã€è¯šå®"},
    
    # ç”·æ€§è¯­éŸ³æ¨¡å‹
    "en-US-BrandonNeural": {"gender": "ç”·æ€§", "style": "Warm, Engaging, Authentic", "name": "å¸ƒå…°ç™»", "description": "æ¸©æš–ã€å¸å¼•äººã€çœŸå®"},
    "en-US-KaiNeural": {"gender": "ç”·æ€§", "style": "Sincere, Pleasant, Bright, Clear, Friendly, Warm", "name": "å‡¯", "description": "çœŸè¯šã€æ„‰å¿«ã€æ˜äº®ã€æ¸…æ™°ã€å‹å¥½ã€æ¸©æš–"},
    "en-US-DavisNeural": {"gender": "ç”·æ€§", "style": "Soothing, Calm, Smooth", "name": "æˆ´ç»´æ–¯", "description": "æŠšæ…°ã€å¹³é™ã€é¡ºç•…"},
    
    # ä¸­æ€§è¯­éŸ³æ¨¡å‹
    "en-US-FableNeural": {"gender": "ä¸­æ€§", "style": "Casual, Friendly", "name": "ä¼ å¥‡", "description": "éšæ„ã€å‹å¥½"}
}

# æƒ…ç»ªä¸è¯­éŸ³æ¨¡å‹æ˜ å°„
EMOTION_VOICE_MAPPING = {
    "Excited": ["en-US-AriaNeural", "en-US-EmmaNeural", "en-US-MichelleNeural"],
    "Confident": ["en-US-NancyNeural", "en-US-SerenaNeural", "en-US-BrandonNeural"],
    "Empathetic": ["en-US-AvaNeural", "en-US-JennyNeural", "en-US-AshleyNeural"],
    "Calm": ["en-US-DavisNeural", "en-US-AvaNeural", "en-US-JennyNeural"],
    "Playful": ["en-US-EmmaNeural", "en-US-AriaNeural", "en-US-FableNeural"],
    "Urgent": ["en-US-MichelleNeural", "en-US-NancyNeural", "en-US-BrandonNeural"],
    "Authoritative": ["en-US-SerenaNeural", "en-US-NancyNeural", "en-US-BrandonNeural"],
    "Friendly": ["en-US-JennyNeural", "en-US-AvaNeural", "en-US-KaiNeural"],
    "Inspirational": ["en-US-MichelleNeural", "en-US-BrandonNeural", "en-US-AriaNeural"],
    "Serious": ["en-US-SerenaNeural", "en-US-NancyNeural", "en-US-DavisNeural"],
    "Mysterious": ["en-US-DavisNeural", "en-US-SerenaNeural", "en-US-AvaNeural"],
    "Grateful": ["en-US-JennyNeural", "en-US-AvaNeural", "en-US-AshleyNeural"]
}

# é»˜è®¤è¯­éŸ³æ¨¡å‹
DEFAULT_VOICE = "en-US-JennyNeural"

def get_voice_for_emotion(emotion, script_index=0):
    """æ ¹æ®æƒ…ç»ªå’Œè„šæœ¬ç´¢å¼•åŠ¨æ€é€‰æ‹©è¯­éŸ³æ¨¡å‹"""
    if emotion in EMOTION_VOICE_MAPPING:
        voices = EMOTION_VOICE_MAPPING[emotion]
        # æ ¹æ®è„šæœ¬ç´¢å¼•é€‰æ‹©è¯­éŸ³æ¨¡å‹ï¼Œå®ç°è¯­éŸ³å¤šæ ·æ€§
        voice_index = script_index % len(voices)
        return voices[voice_index]
    return DEFAULT_VOICE

def get_voice_info(voice_model):
    """è·å–è¯­éŸ³æ¨¡å‹ä¿¡æ¯"""
    if voice_model in VOICE_MODELS:
        return VOICE_MODELS[voice_model]
    return {"gender": "æœªçŸ¥", "style": "æœªçŸ¥", "name": "æœªçŸ¥", "description": "æœªçŸ¥"}

def list_available_voices():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¯­éŸ³æ¨¡å‹"""
    return list(VOICE_MODELS.keys())

def create_directories():
    dirs = ['outputs', 'logs', 'input']
    for dir_name in dirs:
        os.makedirs(dir_name, exist_ok=True)

def get_emotion_params(emotion):
    """è·å–æƒ…ç»ªå¯¹åº”çš„è¯­éŸ³å‚æ•°"""
    return EMOTION_PARAMS.get(emotion, EMOTION_PARAMS["Friendly"])

def add_random_variation(params):
    """æ·»åŠ  Â±2% éšæœºæ‰°åŠ¨"""
    import random
    
    # å¯¹ rate æ·»åŠ éšæœºæ‰°åŠ¨
    if params["rate"].startswith("+"):
        base_rate = int(params["rate"][1:-1])
        variation = random.randint(-2, 2)
        new_rate = base_rate + variation
        params["rate"] = f"+{new_rate}%" if new_rate >= 0 else f"{new_rate}%"
    elif params["rate"].startswith("-"):
        base_rate = int(params["rate"][:-1])
        variation = random.randint(-2, 2)
        new_rate = base_rate + variation
        params["rate"] = f"{new_rate}%" if new_rate <= 0 else f"+{new_rate}%"
    else:
        # å¤„ç†æ²¡æœ‰ç¬¦å·çš„æƒ…å†µ
        base_rate = int(params["rate"][:-1])
        variation = random.randint(-2, 2)
        new_rate = base_rate + variation
        params["rate"] = f"+{new_rate}%" if new_rate >= 0 else f"{new_rate}%"
    
    # å¯¹ pitch æ·»åŠ éšæœºæ‰°åŠ¨ (Hzæ ¼å¼)
    if params["pitch"].startswith("+"):
        base_pitch = int(params["pitch"][1:-2])  # å»æ‰+å’ŒHz
        variation = random.randint(-2, 2)
        new_pitch = base_pitch + variation
        params["pitch"] = f"+{new_pitch}Hz" if new_pitch >= 0 else f"{new_pitch}Hz"
    elif params["pitch"].startswith("-"):
        base_pitch = int(params["pitch"][:-2])  # å»æ‰-å’ŒHz
        variation = random.randint(-2, 2)
        new_pitch = base_pitch + variation
        params["pitch"] = f"{new_pitch}Hz" if new_pitch >= 0 else f"{new_pitch}Hz"
    
    return params

async def generate_single_audio(text, voice, emotion, output_path):
    """ç”Ÿæˆå•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
    try:
        logger.info(f"å¼€å§‹ç”ŸæˆéŸ³é¢‘: {text[:30]}...")
        logger.info(f"è¾“å‡ºè·¯å¾„: {output_path}")
        
        # è·å–æƒ…ç»ªå‚æ•°
        params = get_emotion_params(emotion)
        logger.info(f"åŸºç¡€å‚æ•°: {params}")
        params = add_random_variation(params)
        logger.info(f"æœ€ç»ˆå‚æ•°: {params}")
        
        # æ„å»º EdgeTTS å‘½ä»¤å‚æ•°
        communicate = edge_tts.Communicate(
            text=text,
            voice=voice,
            rate=params["rate"],
            pitch=params["pitch"],
            volume=params["volume"]
        )
        
        logger.info(f"EdgeTTSå¯¹è±¡åˆ›å»ºæˆåŠŸï¼Œå¼€å§‹ä¿å­˜åˆ°: {output_path}")
        
        # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        await communicate.save(output_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„ç”Ÿæˆäº†
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            logger.info(f"éŸ³é¢‘æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_path}, å¤§å°: {file_size} bytes")
        else:
            logger.error(f"éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆ: {output_path}")
            return {
                "success": False,
                "error": "æ–‡ä»¶æœªç”Ÿæˆ",
                "file_path": output_path
            }
        
        return {
            "success": True,
            "file_path": output_path,
            "params": params
        }
    except Exception as e:
        logger.error(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {text[:50]}... - {str(e)}")
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e).__name__}: {str(e)}")
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return {
            "success": False,
            "error": str(e),
            "file_path": output_path
        }

async def process_scripts_batch(scripts, product_name, discount, emotion="Friendly", voice=DEFAULT_VOICE, emotions=None, voices=None, rates=None, pitches=None, volumes=None):
    """æ‰¹é‡å¤„ç†è„šæœ¬"""
    # åˆ›å»ºäº§å“è¾“å‡ºç›®å½•
    product_dir = f"outputs/{product_name}"
    os.makedirs(product_dir, exist_ok=True)
    
    results = []
    successful = 0
    failed = 0
    start_time = datetime.now()
    
    # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(MAX_CONCURRENT)
    
    async def process_single_script(script, index):
        async with semaphore:
            # å¦‚æœscriptæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯å­—å…¸ï¼Œæå–text
            if isinstance(script, str):
                text = script
                # ä½¿ç”¨GPTsæä¾›çš„å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                script_emotion = emotions[index] if emotions and index < len(emotions) and emotions[index] else emotion
                script_voice = voices[index] if voices and index < len(voices) and voices[index] else voice
            else:
                text = script.get("english_script", str(script))
                script_emotion = script.get("emotion", emotions[index] if emotions and index < len(emotions) and emotions[index] else emotion)
                script_voice = script.get("voice", voices[index] if voices and index < len(voices) and voices[index] else voice)
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¯­éŸ³ï¼Œä½¿ç”¨åŠ¨æ€è¯­éŸ³é€‰æ‹©
            if not script_voice or script_voice == DEFAULT_VOICE:
                script_voice = get_voice_for_emotion(script_emotion, index)
            
            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶åï¼ˆåŒ…å«è¯­éŸ³æ¨¡å‹ä¿¡æ¯ï¼‰
            voice_name = get_voice_info(script_voice)["name"]
            audio_filename = f"tts_{index+1:04d}_{script_emotion}_{voice_name}.mp3"
            audio_path = f"{product_dir}/{audio_filename}"
            
            # ç”ŸæˆéŸ³é¢‘
            result = await generate_single_audio(text, script_voice, script_emotion, audio_path)
            result["index"] = index + 1
            result["emotion"] = script_emotion
            result["voice"] = script_voice
            result["voice_info"] = get_voice_info(script_voice)
            result["text"] = text
            
            # æ·»åŠ GPTså‚æ•°ä¿¡æ¯
            if rates and index < len(rates) and rates[index]:
                result["rate"] = rates[index]
            if pitches and index < len(pitches) and pitches[index]:
                result["pitch"] = pitches[index]
            if volumes and index < len(volumes) and volumes[index]:
                result["volume"] = volumes[index]
            
            return result
    
    # å¹¶å‘å¤„ç†æ‰€æœ‰è„šæœ¬
    tasks = [process_single_script(script, i) for i, script in enumerate(scripts)]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    for result in results:
        if isinstance(result, dict) and result.get("success"):
            successful += 1
        else:
            failed += 1
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    return {
        "results": results,
        "successful": successful,
        "failed": failed,
        "duration_seconds": duration
    }

def generate_excel_output(scripts, product_name, discount, results):
    """ç”Ÿæˆ Excel è¾“å‡ºæ–‡ä»¶"""
    # åˆ›å»ºäº§å“è¾“å‡ºç›®å½•
    product_dir = f"outputs/{product_name}"
    os.makedirs(product_dir, exist_ok=True)
    
    # å‡†å¤‡ Excel æ•°æ®
    excel_data = []
    date_str = datetime.now().strftime("%Y-%m-%d")
    
    for i, (script, result) in enumerate(zip(scripts, results)):
        if isinstance(result, dict) and result.get("success"):
            # æˆåŠŸç”ŸæˆéŸ³é¢‘
            emotion = "Friendly"  # é»˜è®¤æƒ…ç»ª
            if isinstance(script, str):
                english_script = script
            else:
                english_script = script.get("english_script", str(script))
                emotion = script.get("emotion", "Friendly")
            
            audio_filename = f"tts_{i+1:04d}_{emotion}.mp3"
            audio_path = f"outputs/{product_name}/{audio_filename}"
            
            excel_data.append({
                "id": i + 1,
                "english_script": english_script,
                "chinese_translation": script.get("chinese_translation", "") if isinstance(script, dict) else "",
                "emotion": emotion,
                "voice": script.get("voice", DEFAULT_VOICE) if isinstance(script, dict) else DEFAULT_VOICE,
                "rate": result.get("params", {}).get("rate", "+2%"),
                "pitch": result.get("params", {}).get("pitch", "+2%"),
                "volume": result.get("params", {}).get("volume", "0dB"),
                "audio_file_path": audio_path
            })
        else:
            # ç”Ÿæˆå¤±è´¥
            if isinstance(script, str):
                english_script = script
            else:
                english_script = script.get("english_script", str(script))
            
            excel_data.append({
                "id": i + 1,
                "english_script": english_script,
                "chinese_translation": script.get("chinese_translation", "") if isinstance(script, dict) else "",
                "emotion": script.get("emotion", "Friendly") if isinstance(script, dict) else "Friendly",
                "voice": script.get("voice", DEFAULT_VOICE) if isinstance(script, dict) else DEFAULT_VOICE,
                "rate": "ERROR",
                "pitch": "ERROR",
                "volume": "ERROR",
                "audio_file_path": "ERROR"
            })
    
    # åˆ›å»º DataFrame
    df = pd.DataFrame(excel_data)
    
    # ç”Ÿæˆ Excel æ–‡ä»¶å
    excel_filename = f"Lior_{date_str}_{product_name}_Batch1_Voice.xlsx"
    excel_path = f"{product_dir}/{excel_filename}"
    
    # ä¿å­˜ Excel æ–‡ä»¶
    df.to_excel(excel_path, index=False)
    
    return excel_path

@app.route('/generate', methods=['POST'])
def generate_voice_content():
    """ç”Ÿæˆè¯­éŸ³å†…å®¹çš„ä¸»æ¥å£"""
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        product_name = data.get('product_name', 'Unknown_Product')
        discount = data.get('discount', 'Special offer available!')
        scripts = data.get('scripts', [])
        
        if not scripts:
            return jsonify({"error": "No scripts provided"}), 400
        
        logger.info(f"å¼€å§‹å¤„ç†äº§å“: {product_name}, è„šæœ¬æ•°é‡: {len(scripts)}")
        
        # å¼‚æ­¥å¤„ç†è„šæœ¬
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            emotion = data.get('emotion', 'Friendly')
            voice = data.get('voice', DEFAULT_VOICE)
            result = loop.run_until_complete(process_scripts_batch(scripts, product_name, discount, emotion, voice))
        finally:
            loop.close()
        
        # ç”Ÿæˆ Excel è¾“å‡º
        excel_path = generate_excel_output(scripts, product_name, discount, result["results"])
        
        # ç”Ÿæˆæ ·æœ¬éŸ³é¢‘åˆ—è¡¨
        sample_audios = []
        emotion = data.get('emotion', 'Friendly')  # ä»è¯·æ±‚ä¸­è·å–æƒ…ç»ª
        for i, script in enumerate(scripts[:3]):  # å–å‰3ä¸ªä½œä¸ºæ ·æœ¬
            # å¦‚æœscriptæ˜¯å­—å…¸ï¼Œä½¿ç”¨å…¶ä¸­çš„emotionï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤emotion
            script_emotion = emotion
            if isinstance(script, dict) and 'emotion' in script:
                script_emotion = script['emotion']
            audio_filename = f"tts_{i+1:04d}_{script_emotion}.mp3"
            sample_audios.append(f"outputs/{product_name}/{audio_filename}")
        
        # è¿”å›ç»“æœ
        response = {
            "product_name": product_name,
            "total_scripts": len(scripts),
            "output_excel": excel_path,
            "audio_directory": f"outputs/{product_name}/",
            "sample_audios": sample_audios,
            "summary": {
                "successful": result["successful"],
                "failed": result["failed"],
                "duration_seconds": result["duration_seconds"]
            }
        }
        
        logger.info(f"å¤„ç†å®Œæˆ: {product_name}, æˆåŠŸ: {result['successful']}, å¤±è´¥: {result['failed']}")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        "status": "healthy",
        "service": "TT-Live-AI A3-TK Voice Generation System",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat()
    })

@app.route('/voices', methods=['GET'])
def get_voices():
    """è·å–æ‰€æœ‰å¯ç”¨çš„è¯­éŸ³æ¨¡å‹"""
    try:
        return jsonify({
            "success": True,
            "voices": VOICE_MODELS,
            "emotion_mapping": EMOTION_VOICE_MAPPING,
            "default_voice": DEFAULT_VOICE,
            "total_voices": len(VOICE_MODELS)
        })
    except Exception as e:
        logger.error(f"è·å–è¯­éŸ³æ¨¡å‹å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/voices/<emotion>', methods=['GET'])
def get_voices_for_emotion(emotion):
    """è·å–æŒ‡å®šæƒ…ç»ªçš„æ¨èè¯­éŸ³æ¨¡å‹"""
    try:
        if emotion in EMOTION_VOICE_MAPPING:
            voices = EMOTION_VOICE_MAPPING[emotion]
            voice_details = []
            for voice in voices:
                voice_info = get_voice_info(voice)
                voice_details.append({
                    "voice": voice,
                    "info": voice_info
                })
            
            return jsonify({
                "success": True,
                "emotion": emotion,
                "recommended_voices": voice_details,
                "total_recommended": len(voices)
            })
        else:
            return jsonify({
                "success": False,
                "error": f"ä¸æ”¯æŒçš„æƒ…ç»ªç±»å‹: {emotion}",
                "supported_emotions": list(EMOTION_VOICE_MAPPING.keys())
            }), 400
    except Exception as e:
        logger.error(f"è·å–æƒ…ç»ªè¯­éŸ³æ¨¡å‹å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/status', methods=['GET'])
def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return jsonify({
        "max_concurrent": MAX_CONCURRENT,
        "supported_emotions": list(EMOTION_PARAMS.keys()),
        "default_voice": DEFAULT_VOICE,
        "output_directory": "outputs/",
        "log_directory": "logs/"
    })

if __name__ == '__main__':
    # åˆ›å»ºå¿…è¦ç›®å½•
    create_directories()
    
    # å¯åŠ¨æœåŠ¡
    logger.info("ğŸš€ TT-Live-AI A3-TK è¯­éŸ³ç”ŸæˆæœåŠ¡å¯åŠ¨...")
    logger.info("ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:5000")
    logger.info("ğŸ”— ç”Ÿæˆæ¥å£: POST /generate")
    logger.info("â¤ï¸ å¥åº·æ£€æŸ¥: GET /health")
    logger.info("ğŸ“Š ç³»ç»ŸçŠ¶æ€: GET /status")
    
    app.run(host='0.0.0.0', port=5001, debug=True)
