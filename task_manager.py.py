import os
import sys
import time
import asyncio
import pandas as pd
import argparse
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from batch_tts import process_excel  # ç¡®ä¿ batch_tts.py å†…æš´éœ²è¯¥å‡½æ•°
from tqdm import tqdm

# -----------------------------
# å…¨å±€é…ç½®
# -----------------------------
INPUT_DIR = "input"
OUTPUT_DIR = "outputs"
LOG_DIR = "logs"
REPORT_FILE = os.path.join(OUTPUT_DIR, "task_report.csv")
MAX_CONCURRENT_TASKS = 10  # æ”¯æŒ 5-10 ä¸ªå¹¶è¡Œä»»åŠ¡
RETRY_LIMIT = 3

# -----------------------------
# å·¥å…·å‡½æ•°
# -----------------------------
def log_message(product, message):
    os.makedirs(LOG_DIR, exist_ok=True)
    log_path = os.path.join(LOG_DIR, f"{product}.log")
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {message}\n")

def get_product_name_from_filename(filename):
    # æ–‡ä»¶æ ¼å¼ç¤ºä¾‹ï¼š2025-10-25_Dark_Spot_Patch.xlsx
    base = os.path.basename(filename)
    name = os.path.splitext(base)[0]
    parts = name.split("_", 3)
    return parts[-1] if len(parts) > 1 else name

def discover_tasks():
    os.makedirs(INPUT_DIR, exist_ok=True)
    excel_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".xlsx")]
    return [os.path.join(INPUT_DIR, f) for f in excel_files]

# -----------------------------
# å•ä»»åŠ¡æ‰§è¡Œé€»è¾‘
# -----------------------------
def run_single_task(file_path):
    product_name = get_product_name_from_filename(file_path)
    start_time = time.time()
    result = {"product_name": product_name, "status": "pending"}

    try:
        log_message(product_name, f"å¼€å§‹å¤„ç†ä»»åŠ¡ï¼š{file_path}")
        process_excel(file_path)  # è°ƒç”¨æ‰¹é‡è¯­éŸ³ç”Ÿæˆå‡½æ•°
        duration = time.time() - start_time
        result.update({
            "status": "success",
            "duration_sec": round(duration, 2)
        })
        log_message(product_name, f"âœ… ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶ {duration:.2f}s")
    except Exception as e:
        log_message(product_name, f"âŒ ä»»åŠ¡å¤±è´¥ï¼š{e}")
        result.update({"status": "failed", "error": str(e)})
    return result

# -----------------------------
# å¼‚æ­¥ä»»åŠ¡è°ƒåº¦å™¨
# -----------------------------
async def run_tasks_concurrently(task_files):
    loop = asyncio.get_event_loop()
    results = []
    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    async def sem_task(file):
        async with sem:
            for attempt in range(RETRY_LIMIT):
                result = await loop.run_in_executor(None, run_single_task, file)
                if result["status"] == "success":
                    return result
                log_message(result["product_name"], f"é‡è¯•ç¬¬ {attempt+1}/{RETRY_LIMIT} æ¬¡...")
                time.sleep(3)
            return result

    with tqdm(total=len(task_files), desc="ğŸ§ ä»»åŠ¡è¿›åº¦", ncols=100) as pbar:
        tasks = [asyncio.create_task(sem_task(f)) for f in task_files]
        for coro in asyncio.as_completed(tasks):
            result = await coro
            results.append(result)
            pbar.update(1)
    return results

# -----------------------------
# æŠ¥å‘Šç”Ÿæˆ
# -----------------------------
def generate_report(results):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    df = pd.DataFrame(results)
    df.to_csv(REPORT_FILE, index=False, encoding="utf-8-sig")

    success = len(df[df["status"] == "success"])
    failed = len(df[df["status"] == "failed"])
    avg_time = round(df["duration_sec"].mean(), 2) if success else 0

    print("\nğŸ“Š ä»»åŠ¡æŠ¥å‘Šæ±‡æ€»")
    print("=" * 40)
    print(f"æ€»ä»»åŠ¡æ•°ï¼š{len(df)}")
    print(f"æˆåŠŸï¼š{success}")
    print(f"å¤±è´¥ï¼š{failed}")
    print(f"å¹³å‡è€—æ—¶ï¼š{avg_time}s")
    print(f"æŠ¥å‘Šæ–‡ä»¶ï¼š{REPORT_FILE}")
    print("=" * 40)

# -----------------------------
# å‘½ä»¤è¡Œæ§åˆ¶é€»è¾‘
# -----------------------------
def main():
    parser = argparse.ArgumentParser(description="TT-Live-AI å¤šäº§å“ä»»åŠ¡æ§åˆ¶å™¨")
    parser.add_argument("command", choices=["run", "status", "retry", "report"], help="æ“ä½œå‘½ä»¤")
    parser.add_argument("arg", nargs="?", default="all", help="å‚æ•°ï¼ˆå¦‚äº§å“åï¼‰")
    args = parser.parse_args()

    if args.command == "run":
        print(f"\nğŸš€ å¯åŠ¨ä»»åŠ¡ï¼š{args.arg}\n")
        all_tasks = discover_tasks()
        if not all_tasks:
            print("âš ï¸ æœªåœ¨ input/ ç›®å½•ä¸­å‘ç° Excel æ–‡ä»¶")
            return

        if args.arg != "all":
            all_tasks = [t for t in all_tasks if args.arg in t]
            if not all_tasks:
                print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…äº§å“ {args.arg}")
                return

        asyncio.run(async_run(all_tasks))

    elif args.command == "status":
        if os.path.exists(REPORT_FILE):
            df = pd.read_csv(REPORT_FILE)
            print("\nğŸ“Š å½“å‰ä»»åŠ¡çŠ¶æ€ï¼š")
            print(df[["product_name", "status", "duration_sec"]])
        else:
            print("ğŸ“‚ æš‚æ— æŠ¥å‘Šæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œä»»åŠ¡ã€‚")

    elif args.command == "retry":
        if not os.path.exists(REPORT_FILE):
            print("âš ï¸ æ— æŠ¥å‘Šæ–‡ä»¶ï¼Œæ— æ³•é‡è¯•ã€‚")
            return
        df = pd.read_csv(REPORT_FILE)
        failed_files = [os.path.join(INPUT_DIR, f"{p}.xlsx")
                        for p in df[df["status"] == "failed"]["product_name"]]
        if not failed_files:
            print("ğŸ‰ æ²¡æœ‰å¤±è´¥ä»»åŠ¡ï¼")
            return
        asyncio.run(async_run(failed_files))

    elif args.command == "report":
        if os.path.exists(REPORT_FILE):
            df = pd.read_csv(REPORT_FILE)
            print("\nğŸ“ˆ å…¨éƒ¨ä»»åŠ¡æŠ¥å‘Šï¼š")
            print(df)
        else:
            print("ğŸ“ å°šæœªç”ŸæˆæŠ¥å‘Šã€‚")

async def async_run(task_files):
    results = await run_tasks_concurrently(task_files)
    generate_report(results)

if __name__ == "__main__":
    main()