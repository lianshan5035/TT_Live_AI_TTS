#!/usr/bin/env python3
"""
çœŸäººç›´æ’­è¯­éŸ³ç”Ÿæˆå™¨
åŸºäºçœŸäººç›´æ’­ç‰¹ç‚¹ç”Ÿæˆå¤šç§é£æ ¼çš„æµ‹è¯•éŸ³é¢‘
"""

import random
import logging
import subprocess
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# å¯¼å…¥è§„åˆ™åŠ è½½å™¨
import sys
sys.path.append('/Volumes/M2/TT_Live_AI_TTS/audio_pipeline')
from rules_loader import get_rules_loader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LiveSpeechGenerator:
    """çœŸäººç›´æ’­è¯­éŸ³ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.rules = get_rules_loader()
        self.logger = logging.getLogger(__name__)
        
        # çœŸäººç›´æ’­åœºæ™¯é…ç½®
        self.live_scenarios = {
            "gaming": {
                "name": "æ¸¸æˆç›´æ’­",
                "tempo_range": (1.05, 1.15),
                "pitch_range": (0.1, 0.3),
                "background_prob": 0.9,
                "event_prob": 0.4,
                "compression_ratio": 2.8,
                "description": "æ¸¸æˆç›´æ’­ï¼šè¯­é€Ÿå¿«ã€éŸ³è°ƒé«˜ã€èƒŒæ™¯éŸ³ä¸°å¯Œ"
            },
            "chatting": {
                "name": "èŠå¤©ç›´æ’­",
                "tempo_range": (0.95, 1.05),
                "pitch_range": (-0.1, 0.1),
                "background_prob": 0.7,
                "event_prob": 0.2,
                "compression_ratio": 2.2,
                "description": "èŠå¤©ç›´æ’­ï¼šè¯­é€Ÿæ­£å¸¸ã€éŸ³è°ƒç¨³å®šã€ç¯å¢ƒéŸ³é€‚ä¸­"
            },
            "teaching": {
                "name": "æ•™å­¦ç›´æ’­",
                "tempo_range": (0.90, 1.00),
                "pitch_range": (-0.2, 0.0),
                "background_prob": 0.5,
                "event_prob": 0.15,
                "compression_ratio": 2.0,
                "description": "æ•™å­¦ç›´æ’­ï¼šè¯­é€Ÿç¨æ…¢ã€éŸ³è°ƒè¾ƒä½ã€ç¯å¢ƒéŸ³è¾ƒå°‘"
            },
            "entertainment": {
                "name": "å¨±ä¹ç›´æ’­",
                "tempo_range": (1.00, 1.10),
                "pitch_range": (0.0, 0.2),
                "background_prob": 0.8,
                "event_prob": 0.3,
                "compression_ratio": 2.5,
                "description": "å¨±ä¹ç›´æ’­ï¼šè¯­é€Ÿé€‚ä¸­ã€éŸ³è°ƒç•¥é«˜ã€ç¯å¢ƒéŸ³ä¸°å¯Œ"
            },
            "news": {
                "name": "æ–°é—»ç›´æ’­",
                "tempo_range": (0.95, 1.05),
                "pitch_range": (-0.1, 0.1),
                "background_prob": 0.3,
                "event_prob": 0.1,
                "compression_ratio": 2.3,
                "description": "æ–°é—»ç›´æ’­ï¼šè¯­é€Ÿç¨³å®šã€éŸ³è°ƒä¸­æ€§ã€ç¯å¢ƒéŸ³æœ€å°‘"
            }
        }
    
    def generate_scenario_audio(self, input_file: str, scenario: str) -> Dict[str, Any]:
        """ç”Ÿæˆç‰¹å®šåœºæ™¯çš„éŸ³é¢‘"""
        if scenario not in self.live_scenarios:
            self.logger.error(f"âŒ æœªçŸ¥åœºæ™¯: {scenario}")
            return None
        
        config = self.live_scenarios[scenario]
        self.logger.info(f"ğŸ¤ ç”Ÿæˆ {config['name']} åœºæ™¯éŸ³é¢‘")
        self.logger.info(f"ğŸ“ åœºæ™¯æè¿°: {config['description']}")
        
        # ç”Ÿæˆå‚æ•°
        params = self._generate_scenario_params(config)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%H%M%S")
        base_name = Path(input_file).stem
        output_file = f"{base_name}_{scenario}_{timestamp}.m4a"
        
        # æ„å»ºFFmpegå‘½ä»¤
        cmd = self._build_scenario_command(input_file, output_file, params)
        
        # æ‰§è¡Œå‘½ä»¤
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                self.logger.info(f"âœ… {config['name']} éŸ³é¢‘åˆ›å»ºæˆåŠŸ: {output_file}")
                return {
                    'scenario': scenario,
                    'output_file': output_file,
                    'params': params,
                    'success': True
                }
            else:
                self.logger.error(f"âŒ {config['name']} éŸ³é¢‘åˆ›å»ºå¤±è´¥: {result.stderr}")
                return {'success': False, 'error': result.stderr}
        except Exception as e:
            self.logger.error(f"âŒ {config['name']} éŸ³é¢‘åˆ›å»ºå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def _generate_scenario_params(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆåœºæ™¯å‚æ•°"""
        params = {}
        
        # è¯­é€Ÿå’ŒéŸ³é«˜
        params['tempo'] = random.uniform(*config['tempo_range'])
        params['pitch_semitones'] = random.uniform(*config['pitch_range'])
        
        # èƒŒæ™¯éŸ³æ•ˆ
        if random.random() < config['background_prob']:
            environments = ['room_tone', 'living_room', 'office', 'cafe']
            env = random.choice(environments)
            params['background_sound'] = {
                'file': f"{env}.wav",
                'volume': random.uniform(0.06, 0.18),
                'start_offset': random.uniform(0, 30),
                'looped': True
            }
        else:
            params['background_sound'] = None
        
        # äº‹ä»¶éŸ³æ•ˆ
        params['events'] = []
        if random.random() < config['event_prob']:
            event_types = ['keyboard', 'water_pour', 'chair_creak', 'paper_rustle']
            num_events = random.randint(1, 2)
            
            for _ in range(num_events):
                event_type = random.choice(event_types)
                params['events'].append({
                    'file': f"{event_type}.wav",
                    'volume': random.uniform(0.08, 0.20),
                    'trigger_time': random.uniform(3, 27),
                    'duration': random.uniform(1.0, 3.0)
                })
        
        # éŸ³é¢‘å¢å¼ºå‚æ•°
        params['compressor'] = {
            'threshold': -20,
            'ratio': config['compression_ratio'],
            'attack': 15,
            'release': 150,
            'makeup': 2
        }
        
        params['equalizer'] = {
            'bands': [
                {'frequency': 250, 'gain_range': (1.1, 1.6), 'width': 100},
                {'frequency': 3000, 'gain_range': (1.3, 1.9), 'width': 600}
            ]
        }
        
        params['highpass_frequency'] = 60
        params['noise_amplitude'] = random.uniform(0.005, 0.012)
        
        return params
    
    def _build_scenario_command(self, input_file: str, output_file: str, params: Dict[str, Any]) -> List[str]:
        """æ„å»ºåœºæ™¯FFmpegå‘½ä»¤"""
        cmd = ['ffmpeg', '-y', '-i', input_file]
        
        # æ„å»ºæ»¤é•œé“¾
        filters = []
        
        # 1. é‡‡æ ·ç‡è½¬æ¢
        filters.append('aresample=48000')
        
        # 2. è¯­é€Ÿå’ŒéŸ³é«˜è°ƒæ•´
        if params['tempo'] != 1.0 or params['pitch_semitones'] != 0.0:
            pitch_ratio = 2 ** (params['pitch_semitones'] / 12)
            filters.append(f"rubberband=tempo={params['tempo']}:pitch={pitch_ratio}:formant=preserved")
        
        # 3. éŸ³é¢‘å¢å¼º
        compressor = params['compressor']
        filters.append(f"acompressor=threshold={compressor['threshold']}dB:ratio={compressor['ratio']}:attack={compressor['attack']}:release={compressor['release']}:makeup={compressor['makeup']}")
        
        # EQè°ƒæ•´
        for band in params['equalizer']['bands']:
            gain = random.uniform(*band['gain_range'])
            filters.append(f"equalizer=f={band['frequency']}:width_type=h:width={band['width']}:g={gain}")
        
        # é«˜é€šæ»¤æ³¢å™¨
        filters.append(f"highpass=f={params['highpass_frequency']}")
        
        # 4. å“åº¦å½’ä¸€åŒ–
        filters.append("loudnorm=I=-16:TP=-1.5:LRA=11")
        
        # åº”ç”¨æ»¤é•œ
        if filters:
            cmd.extend(['-af', ','.join(filters)])
        
        # 5. è¾“å‡ºç¼–ç 
        cmd.extend(['-c:a', 'aac', '-b:a', '192k'])
        cmd.extend(['-ar', '48000', '-ac', '2'])
        cmd.append(output_file)
        
        return cmd
    
    def generate_all_scenarios(self, input_file: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰€æœ‰åœºæ™¯çš„éŸ³é¢‘"""
        self.logger.info("ğŸ¤ ç”Ÿæˆæ‰€æœ‰çœŸäººç›´æ’­åœºæ™¯éŸ³é¢‘")
        self.logger.info("=" * 60)
        
        results = {}
        
        for scenario in self.live_scenarios.keys():
            self.logger.info(f"\nğŸ¯ å¤„ç†åœºæ™¯: {scenario}")
            result = self.generate_scenario_audio(input_file, scenario)
            results[scenario] = result
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        self.logger.info("\nğŸ“‹ ç”Ÿæˆç»“æœæ‘˜è¦:")
        for scenario, result in results.items():
            if result and result.get('success'):
                self.logger.info(f"  âœ… {scenario}: {result['output_file']}")
            else:
                self.logger.info(f"  âŒ {scenario}: ç”Ÿæˆå¤±è´¥")
        
        return results
    
    def create_comparison_set(self, input_file: str) -> Dict[str, str]:
        """åˆ›å»ºå®Œæ•´çš„å¯¹æ¯”éŸ³é¢‘é›†"""
        self.logger.info("ğŸ”„ åˆ›å»ºå®Œæ•´å¯¹æ¯”éŸ³é¢‘é›†...")
        
        # ç”Ÿæˆæ‰€æœ‰åœºæ™¯
        scenario_results = self.generate_all_scenarios(input_file)
        
        # ç”ŸæˆåŸå§‹éŸ³é¢‘
        timestamp = datetime.now().strftime("%H%M%S")
        base_name = Path(input_file).stem
        original_file = f"{base_name}_original_{timestamp}.m4a"
        
        cmd_original = [
            'ffmpeg', '-y', '-i', input_file,
            '-c:a', 'aac', '-b:a', '192k',
            '-ar', '48000', '-ac', '2',
            original_file
        ]
        
        try:
            result = subprocess.run(cmd_original, capture_output=True, text=True)
            if result.returncode == 0:
                self.logger.info(f"âœ… åŸå§‹éŸ³é¢‘åˆ›å»ºæˆåŠŸ: {original_file}")
            else:
                self.logger.error(f"âŒ åŸå§‹éŸ³é¢‘åˆ›å»ºå¤±è´¥: {result.stderr}")
        except Exception as e:
            self.logger.error(f"âŒ åŸå§‹éŸ³é¢‘åˆ›å»ºå¤±è´¥: {e}")
        
        # æ•´ç†ç»“æœ
        comparison_set = {
            'original': original_file,
            'scenarios': {}
        }
        
        for scenario, result in scenario_results.items():
            if result and result.get('success'):
                comparison_set['scenarios'][scenario] = result['output_file']
        
        return comparison_set

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¤ çœŸäººç›´æ’­è¯­éŸ³ç”Ÿæˆå™¨")
    logger.info("=" * 60)
    
    # æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    test_audio = '/Volumes/M2/TT_Live_AI_TTS/audio_pipeline/audio_pipeline/input_raw/test_1.wav'
    
    if not Path(test_audio).exists():
        logger.error(f"âŒ æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {test_audio}")
        return
    
    logger.info(f"ğŸµ ä½¿ç”¨æµ‹è¯•éŸ³é¢‘: {test_audio}")
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = LiveSpeechGenerator()
    
    # æ˜¾ç¤ºå¯ç”¨åœºæ™¯
    logger.info("\nğŸ¯ å¯ç”¨ç›´æ’­åœºæ™¯:")
    for scenario, config in generator.live_scenarios.items():
        logger.info(f"  {scenario}: {config['name']} - {config['description']}")
    
    # åˆ›å»ºå®Œæ•´å¯¹æ¯”éŸ³é¢‘é›†
    comparison_set = generator.create_comparison_set(test_audio)
    
    # æ˜¾ç¤ºç»“æœ
    logger.info("\nğŸ“‹ ç”Ÿæˆçš„å¯¹æ¯”éŸ³é¢‘é›†:")
    logger.info(f"  åŸå§‹éŸ³é¢‘: {comparison_set['original']}")
    logger.info("  åœºæ™¯éŸ³é¢‘:")
    for scenario, file_path in comparison_set['scenarios'].items():
        logger.info(f"    {scenario}: {file_path}")
    
    # æ˜¾ç¤ºåœºæ™¯ç‰¹ç‚¹
    logger.info("\nğŸ¤ å„åœºæ™¯ç‰¹ç‚¹:")
    for scenario, config in generator.live_scenarios.items():
        logger.info(f"  {config['name']}:")
        logger.info(f"    è¯­é€ŸèŒƒå›´: {config['tempo_range']}")
        logger.info(f"    éŸ³é«˜èŒƒå›´: {config['pitch_range']}")
        logger.info(f"    èƒŒæ™¯éŸ³æ¦‚ç‡: {config['background_prob']}")
        logger.info(f"    äº‹ä»¶éŸ³æ¦‚ç‡: {config['event_prob']}")

if __name__ == '__main__':
    main()
