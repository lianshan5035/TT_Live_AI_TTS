#!/usr/bin/env python3
"""
çœŸäººç›´æ’­è¯­éŸ³å‚æ•°åˆ†æå™¨
åˆ†æçœŸäººç›´æ’­è¯­éŸ³çš„ç‰¹ç‚¹å¹¶ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
"""

import random
import logging
import subprocess
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# å¯¼å…¥è§„åˆ™åŠ è½½å™¨
import sys
sys.path.append('/Volumes/M2/TT_Live_AI_TTS/audio_pipeline')
from rules_loader import get_rules_loader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LiveSpeechAnalyzer:
    """çœŸäººç›´æ’­è¯­éŸ³åˆ†æå™¨"""
    
    def __init__(self):
        self.rules = get_rules_loader()
        self.logger = logging.getLogger(__name__)
        
        # çœŸäººç›´æ’­è¯­éŸ³ç‰¹ç‚¹åˆ†æ
        self.live_speech_characteristics = {
            "tempo": {
                "normal_range": (0.95, 1.05),  # æ­£å¸¸è¯­é€ŸèŒƒå›´
                "excited_range": (1.05, 1.15),  # å…´å¥‹æ—¶è¯­é€Ÿ
                "calm_range": (0.90, 1.00),    # å¹³é™æ—¶è¯­é€Ÿ
                "description": "çœŸäººç›´æ’­è¯­é€Ÿé€šå¸¸æ¯”TTSç¨å¿«ï¼Œæœ‰è‡ªç„¶å˜åŒ–"
            },
            "pitch": {
                "normal_range": (-0.2, 0.2),    # æ­£å¸¸éŸ³é«˜å˜åŒ–
                "excited_range": (0.1, 0.4),    # å…´å¥‹æ—¶éŸ³é«˜
                "calm_range": (-0.3, 0.1),     # å¹³é™æ—¶éŸ³é«˜
                "description": "çœŸäººç›´æ’­éŸ³é«˜æœ‰è‡ªç„¶æ³¢åŠ¨ï¼Œä¸ä¼šè¿‡äºæœºæ¢°"
            },
            "background": {
                "room_tone_level": (0.05, 0.12),  # æˆ¿é—´åº•å™ª
                "environment_level": (0.08, 0.18), # ç¯å¢ƒéŸ³æ•ˆ
                "description": "çœŸäººç›´æ’­æœ‰è½»å¾®çš„æˆ¿é—´éŸ³å’Œç¯å¢ƒéŸ³"
            },
            "events": {
                "keyboard_probability": 0.25,     # é”®ç›˜å£°æ¦‚ç‡
                "water_probability": 0.15,        # å–æ°´å£°æ¦‚ç‡
                "movement_probability": 0.20,     # ç§»åŠ¨å£°æ¦‚ç‡
                "description": "çœŸäººç›´æ’­ä¼šæœ‰è‡ªç„¶çš„åŠ¨ä½œå£°éŸ³"
            },
            "audio_quality": {
                "compression_ratio": 2.5,         # å‹ç¼©æ¯”
                "eq_250hz_gain": (1.2, 1.8),     # 250Hzå¢ç›Š
                "eq_3khz_gain": (1.5, 2.2),      # 3kHzå¢ç›Š
                "highpass_freq": 60,              # é«˜é€šæ»¤æ³¢é¢‘ç‡
                "description": "çœŸäººç›´æ’­éŸ³é¢‘è´¨é‡æ›´è‡ªç„¶ï¼Œä¸ä¼šè¿‡åº¦å¤„ç†"
            }
        }
    
    def analyze_live_speech_params(self) -> Dict[str, Any]:
        """åˆ†æçœŸäººç›´æ’­è¯­éŸ³å‚æ•°"""
        self.logger.info("ğŸ¤ åˆ†æçœŸäººç›´æ’­è¯­éŸ³å‚æ•°...")
        
        # åŸºäºçœŸäººç›´æ’­ç‰¹ç‚¹ç”Ÿæˆå‚æ•°
        params = {}
        
        # 1. è¯­é€Ÿå‚æ•° - çœŸäººç›´æ’­é€šå¸¸æ¯”TTSç¨å¿«
        params['tempo'] = random.uniform(1.02, 1.08)  # æ¯”æ­£å¸¸ç¨å¿«
        self.logger.info(f"ğŸ“Š è¯­é€Ÿè°ƒæ•´: {params['tempo']:.3f}x (çœŸäººç›´æ’­é€šå¸¸ç¨å¿«)")
        
        # 2. éŸ³é«˜å‚æ•° - çœŸäººç›´æ’­æœ‰è‡ªç„¶æ³¢åŠ¨
        params['pitch_semitones'] = random.uniform(-0.15, 0.25)  # è½»å¾®æ³¢åŠ¨
        self.logger.info(f"ğŸµ éŸ³é«˜è°ƒæ•´: {params['pitch_semitones']:.3f}åŠéŸ³ (è‡ªç„¶æ³¢åŠ¨)")
        
        # 3. èƒŒæ™¯éŸ³æ•ˆ - çœŸäººç›´æ’­æœ‰è½»å¾®ç¯å¢ƒéŸ³
        if random.random() < 0.85:  # 85%æ¦‚ç‡æœ‰èƒŒæ™¯éŸ³
            environments = ['room_tone', 'living_room', 'office']
            env = random.choice(environments)
            params['background_sound'] = {
                'file': f"{env}.wav",
                'volume': random.uniform(0.08, 0.15),  # è¾ƒä½éŸ³é‡
                'start_offset': random.uniform(0, 30),
                'looped': True
            }
            self.logger.info(f"ğŸŒ èƒŒæ™¯éŸ³æ•ˆ: {env} (éŸ³é‡: {params['background_sound']['volume']:.3f})")
        else:
            params['background_sound'] = None
            self.logger.info("ğŸŒ èƒŒæ™¯éŸ³æ•ˆ: æ— ")
        
        # 4. äº‹ä»¶éŸ³æ•ˆ - çœŸäººç›´æ’­æœ‰è‡ªç„¶åŠ¨ä½œ
        params['events'] = []
        if random.random() < 0.30:  # 30%æ¦‚ç‡æœ‰äº‹ä»¶éŸ³
            event_types = ['keyboard', 'water_pour', 'chair_creak']
            num_events = random.randint(1, 2)
            
            for _ in range(num_events):
                event_type = random.choice(event_types)
                params['events'].append({
                    'file': f"{event_type}.wav",
                    'volume': random.uniform(0.10, 0.18),
                    'trigger_time': random.uniform(5, 25),  # åœ¨5-25ç§’è§¦å‘
                    'duration': random.uniform(1.0, 2.5)
                })
            
            self.logger.info(f"ğŸ”Š äº‹ä»¶éŸ³æ•ˆ: {len(params['events'])}ä¸ªäº‹ä»¶")
        else:
            self.logger.info("ğŸ”Š äº‹ä»¶éŸ³æ•ˆ: æ— ")
        
        # 5. éŸ³é¢‘å¢å¼ºå‚æ•° - çœŸäººç›´æ’­æ›´è‡ªç„¶
        params['compressor'] = {
            'threshold': -20,  # æ›´æ¸©å’Œçš„å‹ç¼©
            'ratio': 2.5,      # æ›´ä½çš„å‹ç¼©æ¯”
            'attack': 20,      # æ›´æ…¢çš„æ”»å‡»æ—¶é—´
            'release': 200,    # æ›´æ…¢çš„é‡Šæ”¾æ—¶é—´
            'makeup': 2        # æ›´å°‘çš„å¢ç›Šè¡¥å¿
        }
        
        params['equalizer'] = {
            'bands': [
                {'frequency': 250, 'gain_range': (1.2, 1.8), 'width': 100},
                {'frequency': 3000, 'gain_range': (1.5, 2.2), 'width': 600}
            ]
        }
        
        params['highpass_frequency'] = 60  # æ›´ä½çš„æˆªæ­¢é¢‘ç‡
        params['noise_amplitude'] = random.uniform(0.006, 0.012)  # æ›´ä½çš„å™ªéŸ³
        
        self.logger.info(f"âš¡ éŸ³é¢‘å¢å¼º: è‡ªç„¶æ¨¡å¼ (é«˜é€š: {params['highpass_frequency']}Hz)")
        self.logger.info(f"ğŸ”‡ ç™½å™ªéŸ³å¹…åº¦: {params['noise_amplitude']:.4f}")
        
        return params
    
    def create_live_speech_audio(self, input_file: str, output_file: str) -> bool:
        """åˆ›å»ºçœŸäººç›´æ’­é£æ ¼çš„éŸ³é¢‘"""
        try:
            self.logger.info(f"ğŸ¤ åˆ›å»ºçœŸäººç›´æ’­é£æ ¼éŸ³é¢‘: {input_file}")
            
            # åˆ†æå‚æ•°
            params = self.analyze_live_speech_params()
            
            # æ„å»ºFFmpegå‘½ä»¤
            cmd = self.build_live_speech_command(input_file, output_file, params)
            
            # æ‰§è¡Œå‘½ä»¤
            self.logger.info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤...")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.logger.info(f"âœ… çœŸäººç›´æ’­é£æ ¼éŸ³é¢‘åˆ›å»ºæˆåŠŸ: {output_file}")
                return True
            else:
                self.logger.error(f"âŒ åˆ›å»ºå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return False
    
    def build_live_speech_command(self, input_file: str, output_file: str, params: Dict[str, Any]) -> List[str]:
        """æ„å»ºçœŸäººç›´æ’­é£æ ¼çš„FFmpegå‘½ä»¤"""
        cmd = ['ffmpeg', '-y', '-i', input_file]
        
        # æ„å»ºæ»¤é•œé“¾
        filters = []
        
        # 1. é‡‡æ ·ç‡è½¬æ¢
        filters.append('aresample=48000')
        
        # 2. è¯­é€Ÿå’ŒéŸ³é«˜è°ƒæ•´
        if params['tempo'] != 1.0 or params['pitch_semitones'] != 0.0:
            pitch_ratio = 2 ** (params['pitch_semitones'] / 12)
            filters.append(f"rubberband=tempo={params['tempo']}:pitch={pitch_ratio}:formant=preserved")
        
        # 3. éŸ³é¢‘å¢å¼º - çœŸäººç›´æ’­é£æ ¼
        compressor = params['compressor']
        filters.append(f"acompressor=threshold={compressor['threshold']}dB:ratio={compressor['ratio']}:attack={compressor['attack']}:release={compressor['release']}:makeup={compressor['makeup']}")
        
        # EQè°ƒæ•´
        for band in params['equalizer']['bands']:
            gain = random.uniform(*band['gain_range'])
            filters.append(f"equalizer=f={band['frequency']}:width_type=h:width={band['width']}:g={gain}")
        
        # é«˜é€šæ»¤æ³¢å™¨
        filters.append(f"highpass=f={params['highpass_frequency']}")
        
        # 4. å“åº¦å½’ä¸€åŒ– - çœŸäººç›´æ’­æ ‡å‡†
        filters.append("loudnorm=I=-16:TP=-1.5:LRA=11")
        
        # åº”ç”¨æ»¤é•œ
        if filters:
            cmd.extend(['-af', ','.join(filters)])
        
        # 5. è¾“å‡ºç¼–ç 
        cmd.extend(['-c:a', 'aac', '-b:a', '192k'])
        cmd.extend(['-ar', '48000', '-ac', '2'])
        cmd.append(output_file)
        
        return cmd
    
    def create_comparison_audio(self, input_file: str) -> Dict[str, str]:
        """åˆ›å»ºå¯¹æ¯”éŸ³é¢‘"""
        self.logger.info("ğŸ”„ åˆ›å»ºå¯¹æ¯”éŸ³é¢‘...")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%H%M%S")
        base_name = Path(input_file).stem
        
        outputs = {
            'original': f"{base_name}_original_{timestamp}.m4a",
            'live_speech': f"{base_name}_live_speech_{timestamp}.m4a",
            'enhanced': f"{base_name}_enhanced_{timestamp}.m4a"
        }
        
        # 1. åŸå§‹éŸ³é¢‘ï¼ˆä»…è½¬æ¢æ ¼å¼ï¼‰
        cmd_original = [
            'ffmpeg', '-y', '-i', input_file,
            '-c:a', 'aac', '-b:a', '192k',
            '-ar', '48000', '-ac', '2',
            outputs['original']
        ]
        
        # 2. çœŸäººç›´æ’­é£æ ¼
        self.create_live_speech_audio(input_file, outputs['live_speech'])
        
        # 3. å¢å¼ºç‰ˆæœ¬ï¼ˆä½¿ç”¨å½“å‰è§„åˆ™ï¼‰
        cmd_enhanced = [
            'ffmpeg', '-y', '-i', input_file,
            '-af', 'aresample=48000,rubberband=tempo=1.05:pitch=1.1:formant=preserved,acompressor=threshold=-18dB:ratio=3:attack=15:release=180:makeup=3,equalizer=f=250:width_type=h:width=120:g=2,equalizer=f=3500:width_type=h:width=800:g=2,highpass=f=80,loudnorm=I=-19:TP=-2:LRA=9',
            '-c:a', 'aac', '-b:a', '192k',
            '-ar', '48000', '-ac', '2',
            outputs['enhanced']
        ]
        
        # æ‰§è¡Œå‘½ä»¤
        for name, cmd in [('original', cmd_original), ('enhanced', cmd_enhanced)]:
            try:
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    self.logger.info(f"âœ… {name} éŸ³é¢‘åˆ›å»ºæˆåŠŸ: {outputs[name]}")
                else:
                    self.logger.error(f"âŒ {name} éŸ³é¢‘åˆ›å»ºå¤±è´¥: {result.stderr}")
            except Exception as e:
                self.logger.error(f"âŒ {name} éŸ³é¢‘åˆ›å»ºå¤±è´¥: {e}")
        
        return outputs

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¤ çœŸäººç›´æ’­è¯­éŸ³å‚æ•°åˆ†æå™¨")
    logger.info("=" * 60)
    
    # æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    test_dirs = [
        "/Volumes/M2/TT_Live_AI_TTS/20_è¾“å‡ºæ–‡ä»¶_å¤„ç†å®Œæˆçš„éŸ³é¢‘æ–‡ä»¶",
        "/Volumes/M2/TT_Live_AI_TTS/audio_pipeline/input_raw"
    ]
    
    test_audio = None
    for test_dir in test_dirs:
        test_path = Path(test_dir)
        if test_path.exists():
            for f in test_path.iterdir():
                if f.is_file() and f.suffix.lower() in ['.wav', '.mp3', '.m4a', '.aac']:
                    test_audio = f
                    break
            if test_audio:
                break
    
    if not test_audio:
        logger.error("âŒ æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶")
        return
    
    logger.info(f"ğŸµ æ‰¾åˆ°æµ‹è¯•éŸ³é¢‘: {test_audio.name}")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = LiveSpeechAnalyzer()
    
    # åˆ›å»ºå¯¹æ¯”éŸ³é¢‘
    outputs = analyzer.create_comparison_audio(str(test_audio))
    
    # æ˜¾ç¤ºç»“æœ
    logger.info("\nğŸ“‹ ç”Ÿæˆçš„å¯¹æ¯”éŸ³é¢‘:")
    for name, file_path in outputs.items():
        if Path(file_path).exists():
            logger.info(f"  {name}: {file_path}")
        else:
            logger.info(f"  {name}: åˆ›å»ºå¤±è´¥")
    
    # æ˜¾ç¤ºçœŸäººç›´æ’­è¯­éŸ³ç‰¹ç‚¹
    logger.info("\nğŸ¤ çœŸäººç›´æ’­è¯­éŸ³ç‰¹ç‚¹:")
    characteristics = analyzer.live_speech_characteristics
    for category, params in characteristics.items():
        logger.info(f"  {category}: {params['description']}")

if __name__ == '__main__':
    main()
