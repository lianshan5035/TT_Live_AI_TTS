#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EdgeTTSåˆ°FFmpegå¤„ç†æ‰§è¡Œå™¨
å®ç°EdgeTTSç”ŸæˆéŸ³é¢‘åä½¿ç”¨FFmpegè¿›è¡ŒçœŸäººç›´æ’­è¯­éŸ³å¤„ç†çš„å®Œæ•´æµç¨‹
"""

import json
import random
import asyncio
import subprocess
import edge_tts
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
import os
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EdgeTTSFFmpegProcessor:
    """EdgeTTSåˆ°FFmpegå¤„ç†æ‰§è¡Œå™¨"""
    
    def __init__(self, config_file: str = "edgetts_ffmpeg_config.json"):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.config_file = config_file
        self.config = self._load_config()
        self.emotion_strategies = self.config.get('emotion_strategies', {})
        self.background_sounds = self.config.get('background_sounds', {})
        self.event_sounds = self.config.get('event_sounds', {})
        
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "emotion_strategies": {
                "Urgent": {
                    "rate_range": [0.95, 1.2],
                    "pitch_range": [0.95, 1.1],
                    "volume_range": [0.95, 1.0],
                    "ffmpeg_processing": {
                        "tempo_adjustment": {"base_range": [1.02, 1.08], "method": "rubberband"},
                        "pitch_adjustment": {"base_range": [1.02, 1.05], "method": "rubberband"},
                        "background_sounds": {"probability": 0.85, "volume_range": [0.08, 0.15]},
                        "event_sounds": {"probability": 0.4, "max_events": 2}
                    }
                },
                "Calm": {
                    "rate_range": [0.95, 1.0],
                    "pitch_range": [0.95, 1.0],
                    "volume_range": [0.95, 1.0],
                    "ffmpeg_processing": {
                        "tempo_adjustment": {"base_range": [0.98, 1.02], "method": "rubberband"},
                        "pitch_adjustment": {"base_range": [0.98, 1.02], "method": "rubberband"},
                        "background_sounds": {"probability": 0.7, "volume_range": [0.05, 0.12]},
                        "event_sounds": {"probability": 0.2, "max_events": 1}
                    }
                },
                "Warm": {
                    "rate_range": [0.8, 1.0],
                    "pitch_range": [0.9, 1.1],
                    "volume_range": [0.8, 1.0],
                    "ffmpeg_processing": {
                        "tempo_adjustment": {"base_range": [0.95, 1.05], "method": "rubberband"},
                        "pitch_adjustment": {"base_range": [1.02, 1.08], "method": "rubberband"},
                        "background_sounds": {"probability": 0.8, "volume_range": [0.08, 0.15]},
                        "event_sounds": {"probability": 0.3, "max_events": 2}
                    }
                },
                "Excited": {
                    "rate_range": [1.0, 1.3],
                    "pitch_range": [1.0, 1.2],
                    "volume_range": [0.9, 1.1],
                    "ffmpeg_processing": {
                        "tempo_adjustment": {"base_range": [1.05, 1.15], "method": "rubberband"},
                        "pitch_adjustment": {"base_range": [1.05, 1.12], "method": "rubberband"},
                        "background_sounds": {"probability": 0.9, "volume_range": [0.12, 0.18]},
                        "event_sounds": {"probability": 0.5, "max_events": 3}
                    }
                },
                "Professional": {
                    "rate_range": [0.8, 1.0],
                    "pitch_range": [0.9, 1.0],
                    "volume_range": [0.8, 1.0],
                    "ffmpeg_processing": {
                        "tempo_adjustment": {"base_range": [0.95, 1.05], "method": "rubberband"},
                        "pitch_adjustment": {"base_range": [0.98, 1.02], "method": "rubberband"},
                        "background_sounds": {"probability": 0.5, "volume_range": [0.06, 0.12]},
                        "event_sounds": {"probability": 0.15, "max_events": 1}
                    }
                }
            },
            "background_sounds": {
                "environments": {
                    "cafe": {"file": "cafe_ambient.wav", "volume_range": [0.15, 0.25]},
                    "office": {"file": "office_ambient.wav", "volume_range": [0.12, 0.22]},
                    "living_room": {"file": "living_room.wav", "volume_range": [0.1, 0.2]},
                    "outdoor": {"file": "outdoor_ambient.wav", "volume_range": [0.18, 0.3]},
                    "room_tone": {"file": "room_tone.wav", "volume_range": [0.08, 0.15]}
                }
            },
            "event_sounds": {
                "events": {
                    "keyboard": {"file": "keyboard_typing.wav", "volume_range": [0.15, 0.25]},
                    "water_pour": {"file": "water_pour.wav", "volume_range": [0.12, 0.2]},
                    "footsteps": {"file": "footsteps.wav", "volume_range": [0.1, 0.18]},
                    "chair_creak": {"file": "chair_creak.wav", "volume_range": [0.08, 0.15]},
                    "paper_rustle": {"file": "paper_rustle.wav", "volume_range": [0.06, 0.12]}
                }
            }
        }
    
    def python_to_edge_tts_rate(self, python_rate: float) -> str:
        """Pythonè¯­é€Ÿå€¼è½¬æ¢ä¸ºEdgeTTSæ ¼å¼"""
        edge_tts_rate = int((python_rate - 1) * 100)
        return f"{edge_tts_rate:+d}%"
    
    def python_to_edge_tts_pitch(self, python_pitch: float) -> str:
        """PythonéŸ³è°ƒå€¼è½¬æ¢ä¸ºEdgeTTSæ ¼å¼"""
        edge_tts_pitch = int((python_pitch - 1) * 50)
        return f"{edge_tts_pitch:+d}Hz"
    
    def python_to_edge_tts_volume(self, python_volume: float) -> str:
        """PythonéŸ³é‡å€¼è½¬æ¢ä¸ºEdgeTTSæ ¼å¼"""
        edge_tts_volume = int((python_volume - 1) * 50)
        return f"{edge_tts_volume:+d}%"
    
    def generate_emotion_parameters(self, emotion: str) -> Dict:
        """æ ¹æ®æƒ…ç»ªç±»å‹ç”Ÿæˆå‚æ•°"""
        if emotion not in self.emotion_strategies:
            logger.warning(f"æœªçŸ¥æƒ…ç»ªç±»å‹: {emotion}ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            emotion = "Professional"
        
        strategy = self.emotion_strategies[emotion]
        
        # ç”ŸæˆEdgeTTSå‚æ•°
        rate = random.uniform(strategy['rate_range'][0], strategy['rate_range'][1])
        pitch = random.uniform(strategy['pitch_range'][0], strategy['pitch_range'][1])
        volume = random.uniform(strategy['volume_range'][0], strategy['volume_range'][1])
        
        # ç”ŸæˆFFmpegå‚æ•°
        ffmpeg_params = strategy['ffmpeg_processing']
        tempo = random.uniform(ffmpeg_params['tempo_adjustment']['base_range'][0], 
                              ffmpeg_params['tempo_adjustment']['base_range'][1])
        pitch_adj = random.uniform(ffmpeg_params['pitch_adjustment']['base_range'][0], 
                                 ffmpeg_params['pitch_adjustment']['base_range'][1])
        
        return {
            'emotion': emotion,
            'edge_tts': {
                'rate': rate,
                'pitch': pitch,
                'volume': volume,
                'rate_str': self.python_to_edge_tts_rate(rate),
                'pitch_str': self.python_to_edge_tts_pitch(pitch),
                'volume_str': self.python_to_edge_tts_volume(volume)
            },
            'ffmpeg': {
                'tempo': tempo,
                'pitch': pitch_adj,
                'background_probability': ffmpeg_params['background_sounds']['probability'],
                'background_volume_range': ffmpeg_params['background_sounds']['volume_range'],
                'event_probability': ffmpeg_params['event_sounds']['probability'],
                'max_events': ffmpeg_params['event_sounds']['max_events']
            }
        }
    
    async def generate_edge_tts_audio(self, text: str, voice: str, emotion_params: Dict, 
                                    output_file: str) -> bool:
        """ç”ŸæˆEdgeTTSéŸ³é¢‘"""
        try:
            edge_tts_params = emotion_params['edge_tts']
            
            # æ„å»ºSSML
            ssml = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">
    <voice name="{voice}">
        <prosody rate="{edge_tts_params['rate_str']}" pitch="{edge_tts_params['pitch_str']}" volume="{edge_tts_params['volume_str']}">
            {text}
        </prosody>
    </voice>
</speak>"""
            
            logger.info(f"ğŸ¤ ç”ŸæˆEdgeTTSéŸ³é¢‘: {voice}")
            logger.info(f"ğŸ“Š EdgeTTSå‚æ•°: rate={edge_tts_params['rate_str']}, pitch={edge_tts_params['pitch_str']}, volume={edge_tts_params['volume_str']}")
            
            # è°ƒç”¨EdgeTTS
            communicate = edge_tts.Communicate(ssml, voice)
            await communicate.save(output_file)
            
            logger.info(f"âœ… EdgeTTSéŸ³é¢‘ç”ŸæˆæˆåŠŸ: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ EdgeTTSéŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def select_background_sound(self, emotion: str) -> Optional[Dict]:
        """é€‰æ‹©èƒŒæ™¯éŸ³æ•ˆ"""
        ffmpeg_params = self.emotion_strategies[emotion]['ffmpeg_processing']
        
        if random.random() > ffmpeg_params['background_sounds']['probability']:
            return None
        
        # æ ¹æ®æƒ…ç»ªé€‰æ‹©ç¯å¢ƒ
        environment_mapping = {
            "Urgent": ["office", "cafe"],
            "Calm": ["living_room", "room_tone"],
            "Warm": ["cafe", "living_room"],
            "Excited": ["cafe", "outdoor"],
            "Professional": ["office", "room_tone"]
        }
        
        available_envs = environment_mapping.get(emotion, ["room_tone"])
        selected_env = random.choice(available_envs)
        
        if selected_env in self.background_sounds['environments']:
            env_config = self.background_sounds['environments'][selected_env]
            volume = random.uniform(ffmpeg_params['background_sounds']['volume_range'][0],
                                 ffmpeg_params['background_sounds']['volume_range'][1])
            
            return {
                'file': env_config['file'],
                'volume': volume,
                'environment': selected_env
            }
        
        return None
    
    def select_event_sounds(self, emotion: str) -> List[Dict]:
        """é€‰æ‹©äº‹ä»¶éŸ³æ•ˆ"""
        ffmpeg_params = self.emotion_strategies[emotion]['ffmpeg_processing']
        
        if random.random() > ffmpeg_params['event_sounds']['probability']:
            return []
        
        # æ ¹æ®æƒ…ç»ªé€‰æ‹©äº‹ä»¶
        event_mapping = {
            "Urgent": ["keyboard", "footsteps"],
            "Calm": ["paper_rustle", "chair_creak"],
            "Warm": ["water_pour", "paper_rustle"],
            "Excited": ["keyboard", "footsteps", "water_pour"],
            "Professional": ["keyboard", "paper_rustle"]
        }
        
        available_events = event_mapping.get(emotion, ["keyboard"])
        max_events = ffmpeg_params['event_sounds']['max_events']
        num_events = random.randint(1, max_events)
        
        selected_events = random.sample(available_events, min(num_events, len(available_events)))
        
        event_sounds = []
        for event in selected_events:
            if event in self.event_sounds['events']:
                event_config = self.event_sounds['events'][event]
                volume = random.uniform(event_config['volume_range'][0], event_config['volume_range'][1])
                delay = random.uniform(0.5, 3.0)  # éšæœºå»¶è¿Ÿ
                
                event_sounds.append({
                    'file': event_config['file'],
                    'volume': volume,
                    'delay': delay,
                    'event': event
                })
        
        return event_sounds
    
    def build_ffmpeg_command(self, input_file: str, emotion_params: Dict, 
                           background_sound: Optional[Dict], event_sounds: List[Dict], 
                           output_file: str) -> List[str]:
        """æ„å»ºFFmpegå¤„ç†å‘½ä»¤"""
        ffmpeg_params = emotion_params['ffmpeg']
        
        cmd = ['ffmpeg', '-y']  # -y è¦†ç›–è¾“å‡ºæ–‡ä»¶
        
        # è¾“å…¥æ–‡ä»¶
        cmd.extend(['-i', input_file])
        
        # èƒŒæ™¯éŸ³æ•ˆè¾“å…¥
        if background_sound:
            cmd.extend(['-i', background_sound['file']])
        
        # äº‹ä»¶éŸ³æ•ˆè¾“å…¥
        for event in event_sounds:
            cmd.extend(['-i', event['file']])
        
        # æ„å»ºæ»¤é•œé“¾
        filter_parts = []
        
        # 1. è¯­éŸ³å¤„ç† (tempo + pitch)
        voice_filters = []
        voice_filters.append(f"rubberband=tempo={ffmpeg_params['tempo']:.3f}:pitch={ffmpeg_params['pitch']:.3f}:formant=preserve")
        voice_filters.append("aresample=resampler=soxr")
        
        filter_parts.append(f"[0]{':'.join(voice_filters)}[voice]")
        
        # 2. èƒŒæ™¯éŸ³æ•ˆå¤„ç†
        if background_sound:
            bg_filters = []
            bg_filters.append(f"volume={background_sound['volume']:.3f}")
            bg_filters.append("aloop=loop=-1:size=2e+09")
            bg_filters.append("afade=t=in:ss=0:d=2")
            bg_filters.append("afade=t=out:st=-2:d=2")
            
            filter_parts.append(f"[1]{':'.join(bg_filters)}[bg]")
        
        # 3. äº‹ä»¶éŸ³æ•ˆå¤„ç†
        event_inputs = []
        for i, event in enumerate(event_sounds):
            event_idx = 2 + i  # èƒŒæ™¯éŸ³æ•ˆåçš„äº‹ä»¶éŸ³æ•ˆç´¢å¼•
            event_filters = []
            event_filters.append(f"volume={event['volume']:.3f}")
            event_filters.append(f"adelay={int(event['delay']*1000)}|{int(event['delay']*1000)}")
            event_filters.append("afade=t=in:ss=0:d=0.5")
            event_filters.append("afade=t=out:st=-0.5:d=0.5")
            
            filter_parts.append(f"[{event_idx}]{':'.join(event_filters)}[event{i}]")
            event_inputs.append(f"[event{i}]")
        
        # 4. æ··åˆæ‰€æœ‰éŸ³æ•ˆ
        mix_inputs = ["[voice]"]
        mix_weights = ["1"]
        
        if background_sound:
            mix_inputs.append("[bg]")
            mix_weights.append(f"{background_sound['volume']:.3f}")
        
        for i in range(len(event_sounds)):
            mix_inputs.append(f"[event{i}]")
            mix_weights.append(f"{event_sounds[i]['volume']:.3f}")
        
        mix_filter = f"{':'.join(mix_inputs)}amix=inputs={len(mix_inputs)}:weights={' '.join(mix_weights)}:dropout_transition=2[mixed]"
        filter_parts.append(mix_filter)
        
        # 5. éŸ³é¢‘å¢å¼º
        enhancement_filters = []
        enhancement_filters.append("acompressor=threshold=-18:ratio=3:attack=15:release=180:makeup=3")
        enhancement_filters.append("equalizer=f=250:width=120:g=2.0")
        enhancement_filters.append("equalizer=f=3500:width=800:g=2.5")
        enhancement_filters.append("highpass=f=80")
        enhancement_filters.append("loudnorm=I=-19:TP=-2:LRA=9")
        
        filter_parts.append(f"[mixed]{':'.join(enhancement_filters)}[output]")
        
        # æ·»åŠ æ»¤é•œé“¾
        cmd.extend(['-filter_complex', ';'.join(filter_parts)])
        
        # è¾“å‡ºè®¾ç½®
        cmd.extend(['-map', '[output]'])
        cmd.extend(['-c:a', 'aac', '-b:a', '192k', '-ar', '48000', '-ac', '2'])
        cmd.append(output_file)
        
        return cmd
    
    def run_ffmpeg_command(self, cmd: List[str]) -> bool:
        """è¿è¡ŒFFmpegå‘½ä»¤"""
        try:
            logger.info(f"ğŸ”§ è¿è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd[:10])}...")
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                logger.info("âœ… FFmpegå¤„ç†æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ FFmpegå¤„ç†å¤±è´¥: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ FFmpegå¤„ç†è¶…æ—¶")
            return False
        except Exception as e:
            logger.error(f"âŒ FFmpegå¤„ç†å¼‚å¸¸: {e}")
            return False
    
    async def process_audio(self, text: str, voice: str, emotion: str, 
                          output_file: str) -> bool:
        """å®Œæ•´çš„éŸ³é¢‘å¤„ç†æµç¨‹"""
        try:
            logger.info(f"ğŸ¯ å¼€å§‹å¤„ç†éŸ³é¢‘: {emotion} æƒ…ç»ª")
            
            # 1. ç”Ÿæˆæƒ…ç»ªå‚æ•°
            emotion_params = self.generate_emotion_parameters(emotion)
            logger.info(f"ğŸ“Š ç”Ÿæˆå‚æ•°: {emotion_params['emotion']}")
            
            # 2. ç”ŸæˆEdgeTTSéŸ³é¢‘
            temp_edge_tts_file = f"temp_edge_tts_{int(time.time())}.wav"
            edge_tts_success = await self.generate_edge_tts_audio(text, voice, emotion_params, temp_edge_tts_file)
            
            if not edge_tts_success:
                return False
            
            # 3. é€‰æ‹©èƒŒæ™¯éŸ³æ•ˆ
            background_sound = self.select_background_sound(emotion)
            if background_sound:
                logger.info(f"ğŸµ é€‰æ‹©èƒŒæ™¯éŸ³æ•ˆ: {background_sound['environment']} (éŸ³é‡: {background_sound['volume']:.3f})")
            
            # 4. é€‰æ‹©äº‹ä»¶éŸ³æ•ˆ
            event_sounds = self.select_event_sounds(emotion)
            if event_sounds:
                logger.info(f"ğŸ”Š é€‰æ‹©äº‹ä»¶éŸ³æ•ˆ: {len(event_sounds)} ä¸ª")
                for event in event_sounds:
                    logger.info(f"   - {event['event']}: éŸ³é‡ {event['volume']:.3f}, å»¶è¿Ÿ {event['delay']:.1f}s")
            
            # 5. æ„å»ºFFmpegå‘½ä»¤
            ffmpeg_cmd = self.build_ffmpeg_command(temp_edge_tts_file, emotion_params, 
                                                 background_sound, event_sounds, output_file)
            
            # 6. è¿è¡ŒFFmpegå¤„ç†
            ffmpeg_success = self.run_ffmpeg_command(ffmpeg_cmd)
            
            # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_edge_tts_file):
                os.remove(temp_edge_tts_file)
            
            if ffmpeg_success:
                logger.info(f"ğŸ‰ éŸ³é¢‘å¤„ç†å®Œæˆ: {output_file}")
                return True
            else:
                logger.error("âŒ FFmpegå¤„ç†å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘å¤„ç†å¼‚å¸¸: {e}")
            return False
    
    async def batch_process(self, texts: List[str], voices: List[str], emotions: List[str], 
                          output_dir: str = "processed_audio") -> List[str]:
        """æ‰¹é‡å¤„ç†éŸ³é¢‘"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        successful_files = []
        
        for i, (text, voice, emotion) in enumerate(zip(texts, voices, emotions)):
            try:
                timestamp = int(time.time())
                output_file = output_path / f"batch_{i+1:03d}_{emotion}_{timestamp}.m4a"
                
                success = await self.process_audio(text, voice, emotion, str(output_file))
                
                if success:
                    successful_files.append(str(output_file))
                    logger.info(f"ğŸ“ æ‰¹é‡å¤„ç†è¿›åº¦: {i+1}/{len(texts)} âœ…")
                else:
                    logger.error(f"ğŸ“ æ‰¹é‡å¤„ç†è¿›åº¦: {i+1}/{len(texts)} âŒ")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥ {i+1}: {e}")
        
        logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ: {len(successful_files)}/{len(texts)} æˆåŠŸ")
        return successful_files

async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºEdgeTTSåˆ°FFmpegå¤„ç†æµç¨‹"""
    logger.info("ğŸš€ EdgeTTSåˆ°FFmpegå¤„ç†æ‰§è¡Œå™¨å¯åŠ¨")
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = EdgeTTSFFmpegProcessor()
    
    # æµ‹è¯•æ•°æ®
    test_data = [
        {
            "text": "Hello, this is urgent content! Limited time offer available now!",
            "voice": "en-US-JennyNeural",
            "emotion": "Urgent"
        },
        {
            "text": "This is calm and soothing content. Take a deep breath and relax.",
            "voice": "en-US-AvaNeural",
            "emotion": "Calm"
        },
        {
            "text": "Welcome to our warm and friendly community. We're here to help you.",
            "voice": "en-US-NancyNeural",
            "emotion": "Warm"
        },
        {
            "text": "Exciting news! Our new product is launching today! Don't miss out!",
            "voice": "en-US-AriaNeural",
            "emotion": "Excited"
        },
        {
            "text": "This is professional content. Let me explain the technical details.",
            "voice": "en-US-BrandonNeural",
            "emotion": "Professional"
        }
    ]
    
    # å•ä¸ªå¤„ç†æµ‹è¯•
    logger.info("ğŸµ å•ä¸ªéŸ³é¢‘å¤„ç†æµ‹è¯•...")
    test_item = test_data[0]
    try:
        success = await processor.process_audio(
            text=test_item["text"],
            voice=test_item["voice"],
            emotion=test_item["emotion"],
            output_file=f"single_test_{test_item['emotion']}.m4a"
        )
        if success:
            logger.info("âœ… å•ä¸ªéŸ³é¢‘å¤„ç†æµ‹è¯•æˆåŠŸ")
        else:
            logger.error("âŒ å•ä¸ªéŸ³é¢‘å¤„ç†æµ‹è¯•å¤±è´¥")
    except Exception as e:
        logger.error(f"âŒ å•ä¸ªéŸ³é¢‘å¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æ‰¹é‡å¤„ç†æµ‹è¯•
    logger.info("ğŸ“¦ æ‰¹é‡éŸ³é¢‘å¤„ç†æµ‹è¯•...")
    try:
        texts = [item["text"] for item in test_data]
        voices = [item["voice"] for item in test_data]
        emotions = [item["emotion"] for item in test_data]
        
        batch_files = await processor.batch_process(texts, voices, emotions, "batch_test_output")
        
        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {len(batch_files)} ä¸ªæ–‡ä»¶")
        for file in batch_files:
            logger.info(f"   ğŸ“„ {file}")
            
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
    
    logger.info("ğŸ‰ EdgeTTSåˆ°FFmpegå¤„ç†æ‰§è¡Œå™¨æ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
