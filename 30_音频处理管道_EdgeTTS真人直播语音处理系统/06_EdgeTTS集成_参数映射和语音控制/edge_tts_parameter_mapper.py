#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EdgeTTSå‚æ•°é›†æˆç³»ç»Ÿ
å®ç°Pythonè¯­éŸ³æ§åˆ¶å‚æ•°ä¸EdgeTTSåº•å±‚å‚æ•°çš„å®Œæ•´æ˜ å°„å’Œè½¬æ¢
"""

import json
import random
import asyncio
import edge_tts
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EdgeTTSParameterMapper:
    """EdgeTTSå‚æ•°æ˜ å°„å™¨"""
    
    def __init__(self, config_file: str = "tts_config.json"):
        """åˆå§‹åŒ–å‚æ•°æ˜ å°„å™¨"""
        self.config_file = config_file
        self.config = self._load_config()
        self.emotion_params = self.config.get('emotion_settings', {}).get('emotion_parameters', {})
        
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "emotion_settings": {
                "emotion_parameters": {
                    "Urgent": {
                        "rate_range": [0.95, 1.2],
                        "pitch_range": [0.95, 1.1],
                        "volume_range": [0.95, 1.0],
                        "description": "ç´§è¿«å‹ - è¯­é€Ÿè¾ƒå¿«ï¼ŒéŸ³è°ƒç•¥é«˜",
                        "usage_scenario": "é™æ—¶ä¿ƒé”€ã€ç´§æ€¥é€šçŸ¥ã€å¿«èŠ‚å¥å†…å®¹"
                    },
                    "Calm": {
                        "rate_range": [0.95, 1.0],
                        "pitch_range": [0.95, 1.0],
                        "volume_range": [0.95, 1.0],
                        "description": "èˆ’ç¼“å‹ - è¯­é€Ÿæ­£å¸¸ï¼ŒéŸ³è°ƒå¹³ç¨³",
                        "usage_scenario": "å†¥æƒ³å¼•å¯¼ã€ç¡å‰æ•…äº‹ã€æ”¾æ¾å†…å®¹"
                    },
                    "Warm": {
                        "rate_range": [0.8, 1.0],
                        "pitch_range": [0.9, 1.1],
                        "volume_range": [0.8, 1.0],
                        "description": "æ¸©æš–å‹ - è¯­é€Ÿé€‚ä¸­ï¼ŒéŸ³è°ƒæ¸©æš–",
                        "usage_scenario": "æƒ…æ„Ÿåˆ†äº«ã€ç”Ÿæ´»æ„Ÿæ‚Ÿã€æ¸©é¦¨å†…å®¹"
                    },
                    "Excited": {
                        "rate_range": [1.0, 1.3],
                        "pitch_range": [1.0, 1.2],
                        "volume_range": [0.9, 1.1],
                        "description": "å…´å¥‹å‹ - è¯­é€Ÿè¾ƒå¿«ï¼ŒéŸ³è°ƒè¾ƒé«˜",
                        "usage_scenario": "æ–°å“å‘å¸ƒã€æ´»åŠ¨å®£ä¼ ã€æ¿€åŠ¨å†…å®¹"
                    },
                    "Professional": {
                        "rate_range": [0.8, 1.0],
                        "pitch_range": [0.9, 1.0],
                        "volume_range": [0.8, 1.0],
                        "description": "ä¸“ä¸šå‹ - è¯­é€Ÿç¨³å®šï¼ŒéŸ³è°ƒä¸“ä¸š",
                        "usage_scenario": "äº§å“ä»‹ç»ã€æŠ€æœ¯è®²è§£ã€å•†åŠ¡å†…å®¹"
                    }
                }
            },
            "voice_settings": {
                "file_voice_mapping": {
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v9.xlsx": "en-US-JennyNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v5.xlsx": "en-US-AvaNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v4.xlsx": "en-US-NancyNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v8.xlsx": "en-US-AriaNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v3.xlsx": "en-US-KaiNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v2.xlsx": "en-US-SerenaNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200.xlsx": "en-US-EmmaNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v7.xlsx": "en-US-MichelleNeural",
                    "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v6.xlsx": "en-US-BrandonNeural"
                }
            }
        }
    
    def python_to_edge_tts_rate(self, python_rate: float) -> str:
        """Pythonè¯­é€Ÿå€¼è½¬æ¢ä¸ºEdgeTTSæ ¼å¼"""
        edge_tts_rate = int((python_rate - 1) * 100)
        return f"{edge_tts_rate:+d}%"
    
    def python_to_edge_tts_pitch(self, python_pitch: float) -> str:
        """PythonéŸ³è°ƒå€¼è½¬æ¢ä¸ºEdgeTTSæ ¼å¼"""
        edge_tts_pitch = int((python_pitch - 1) * 50)
        return f"{edge_tts_pitch:+d}Hz"
    
    def python_to_edge_tts_volume(self, python_volume: float) -> str:
        """PythonéŸ³é‡å€¼è½¬æ¢ä¸ºEdgeTTSæ ¼å¼"""
        edge_tts_volume = int((python_volume - 1) * 50)
        return f"{edge_tts_volume:+d}%"
    
    def generate_emotion_parameters(self, emotion: str) -> Dict[str, float]:
        """æ ¹æ®æƒ…ç»ªç±»å‹ç”Ÿæˆå‚æ•°"""
        if emotion not in self.emotion_params:
            logger.warning(f"æœªçŸ¥æƒ…ç»ªç±»å‹: {emotion}ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            emotion = "Professional"
        
        params = self.emotion_params[emotion]
        
        # ç”Ÿæˆéšæœºå‚æ•°
        rate = random.uniform(params['rate_range'][0], params['rate_range'][1])
        pitch = random.uniform(params['pitch_range'][0], params['pitch_range'][1])
        volume = random.uniform(params['volume_range'][0], params['volume_range'][1])
        
        return {
            'rate': rate,
            'pitch': pitch,
            'volume': volume,
            'emotion': emotion,
            'description': params['description']
        }
    
    def build_ssml(self, text: str, voice: str, emotion_params: Dict[str, float]) -> str:
        """æ„å»ºSSMLæ ¼å¼"""
        # è½¬æ¢ä¸ºEdgeTTSæ ¼å¼
        edge_tts_rate = self.python_to_edge_tts_rate(emotion_params['rate'])
        edge_tts_pitch = self.python_to_edge_tts_pitch(emotion_params['pitch'])
        edge_tts_volume = self.python_to_edge_tts_volume(emotion_params['volume'])
        
        ssml = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">
    <voice name="{voice}">
        <prosody rate="{edge_tts_rate}" pitch="{edge_tts_pitch}" volume="{edge_tts_volume}">
            {text}
        </prosody>
    </voice>
</speak>"""
        
        return ssml
    
    async def generate_audio(self, text: str, voice: str, emotion: str, output_file: str) -> bool:
        """ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        try:
            # ç”Ÿæˆæƒ…ç»ªå‚æ•°
            emotion_params = self.generate_emotion_parameters(emotion)
            logger.info(f"ğŸ­ ä½¿ç”¨æƒ…ç»ª: {emotion} - {emotion_params['description']}")
            logger.info(f"ğŸ“Š å‚æ•°: rate={emotion_params['rate']:.2f}, pitch={emotion_params['pitch']:.2f}, volume={emotion_params['volume']:.2f}")
            
            # æ„å»ºSSML
            ssml = self.build_ssml(text, voice, emotion_params)
            
            # è°ƒç”¨EdgeTTS
            communicate = edge_tts.Communicate(ssml, voice)
            await communicate.save(output_file)
            
            logger.info(f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return False

class VoiceLibraryManager:
    """è¯­éŸ³åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯­éŸ³åº“ç®¡ç†å™¨"""
        self.voice_library = self._init_voice_library()
    
    def _init_voice_library(self) -> Dict:
        """åˆå§‹åŒ–è¯­éŸ³åº“"""
        return {
            "base_voices": {
                "en-US-JennyNeural": {"gender": "female", "age": "young", "style": "sweet", "quality": 9.0},
                "en-US-AvaNeural": {"gender": "female", "age": "mature", "style": "warm", "quality": 9.2},
                "en-US-NancyNeural": {"gender": "female", "age": "professional", "style": "professional", "quality": 8.8},
                "en-US-AriaNeural": {"gender": "female", "age": "young", "style": "dynamic", "quality": 8.5},
                "en-US-KaiNeural": {"gender": "male", "age": "young", "style": "energetic", "quality": 8.8},
                "en-US-SerenaNeural": {"gender": "female", "age": "elegant", "style": "elegant", "quality": 8.7},
                "en-US-EmmaNeural": {"gender": "female", "age": "friendly", "style": "friendly", "quality": 8.6},
                "en-US-MichelleNeural": {"gender": "female", "age": "confident", "style": "confident", "quality": 8.4},
                "en-US-BrandonNeural": {"gender": "male", "age": "mature", "style": "professional", "quality": 9.1}
            },
            "content_mapping": {
                "product_intro": ["en-US-JennyNeural", "en-US-AvaNeural", "en-US-NancyNeural"],
                "promotion": ["en-US-AriaNeural", "en-US-KaiNeural", "en-US-MichelleNeural"],
                "education": ["en-US-NancyNeural", "en-US-BrandonNeural", "en-US-AndrewNeural"],
                "entertainment": ["en-US-AriaNeural", "en-US-EmmaNeural", "en-US-GuyNeural"],
                "emotional": ["en-US-AvaNeural", "en-US-LunaNeural", "en-US-ChristopherNeural"]
            }
        }
    
    def select_voice(self, content_type: str, gender_preference: Optional[str] = None) -> str:
        """æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©è¯­éŸ³"""
        available_voices = self.voice_library["content_mapping"].get(content_type, ["en-US-JennyNeural"])
        
        if gender_preference:
            filtered_voices = [
                v for v in available_voices 
                if self.voice_library["base_voices"].get(v, {}).get("gender") == gender_preference
            ]
            if filtered_voices:
                return random.choice(filtered_voices)
        
        return random.choice(available_voices)
    
    def get_voice_info(self, voice: str) -> Dict:
        """è·å–è¯­éŸ³ä¿¡æ¯"""
        return self.voice_library["base_voices"].get(voice, {})

class EdgeTTSAudioGenerator:
    """EdgeTTSéŸ³é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self, config_file: str = "tts_config.json"):
        """åˆå§‹åŒ–éŸ³é¢‘ç”Ÿæˆå™¨"""
        self.mapper = EdgeTTSParameterMapper(config_file)
        self.voice_manager = VoiceLibraryManager()
    
    async def generate_emotion_audio(self, text: str, emotion: str, content_type: str = "product_intro", 
                                  gender_preference: Optional[str] = None, output_file: Optional[str] = None) -> str:
        """ç”Ÿæˆæƒ…ç»ªåŒ–éŸ³é¢‘"""
        # é€‰æ‹©è¯­éŸ³
        voice = self.voice_manager.select_voice(content_type, gender_preference)
        voice_info = self.voice_manager.get_voice_info(voice)
        
        logger.info(f"ğŸ¤ é€‰æ‹©è¯­éŸ³: {voice} ({voice_info.get('style', 'unknown')})")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        if not output_file:
            timestamp = int(asyncio.get_event_loop().time())
            output_file = f"audio_{emotion}_{voice}_{timestamp}.m4a"
        
        # ç”ŸæˆéŸ³é¢‘
        success = await self.mapper.generate_audio(text, voice, emotion, output_file)
        
        if success:
            return output_file
        else:
            raise Exception("éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
    
    async def generate_batch_audio(self, texts: List[str], emotions: List[str], 
                                 content_types: List[str], output_dir: str = "output") -> List[str]:
        """æ‰¹é‡ç”ŸæˆéŸ³é¢‘"""
        output_files = []
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        for i, (text, emotion, content_type) in enumerate(zip(texts, emotions, content_types)):
            try:
                output_file = output_path / f"batch_{i+1:03d}_{emotion}.m4a"
                result_file = await self.generate_emotion_audio(text, emotion, content_type, 
                                                              output_file=str(output_file))
                output_files.append(result_file)
                logger.info(f"ğŸ“ æ‰¹é‡å¤„ç†è¿›åº¦: {i+1}/{len(texts)}")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥ {i+1}: {e}")
        
        return output_files

async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºEdgeTTSå‚æ•°é›†æˆç³»ç»Ÿ"""
    logger.info("ğŸš€ EdgeTTSå‚æ•°é›†æˆç³»ç»Ÿå¯åŠ¨")
    
    # åˆ›å»ºéŸ³é¢‘ç”Ÿæˆå™¨
    generator = EdgeTTSAudioGenerator()
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "Hello, this is urgent content! Limited time offer available now!",
        "This is calm and soothing content. Take a deep breath and relax.",
        "Welcome to our warm and friendly community. We're here to help you.",
        "Exciting news! Our new product is launching today! Don't miss out!",
        "This is professional content. Let me explain the technical details."
    ]
    
    emotions = ["Urgent", "Calm", "Warm", "Excited", "Professional"]
    content_types = ["promotion", "emotional", "emotional", "promotion", "education"]
    
    # ç”Ÿæˆå•ä¸ªéŸ³é¢‘
    logger.info("ğŸµ ç”Ÿæˆå•ä¸ªæƒ…ç»ªéŸ³é¢‘...")
    try:
        output_file = await generator.generate_emotion_audio(
            text=test_texts[0],
            emotion=emotions[0],
            content_type=content_types[0],
            gender_preference="female"
        )
        logger.info(f"âœ… å•ä¸ªéŸ³é¢‘ç”ŸæˆæˆåŠŸ: {output_file}")
    except Exception as e:
        logger.error(f"âŒ å•ä¸ªéŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
    
    # æ‰¹é‡ç”ŸæˆéŸ³é¢‘
    logger.info("ğŸ“¦ æ‰¹é‡ç”Ÿæˆæƒ…ç»ªéŸ³é¢‘...")
    try:
        batch_files = await generator.generate_batch_audio(
            texts=test_texts,
            emotions=emotions,
            content_types=content_types,
            output_dir="emotion_audio_output"
        )
        logger.info(f"âœ… æ‰¹é‡éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {len(batch_files)} ä¸ªæ–‡ä»¶")
        for file in batch_files:
            logger.info(f"   ğŸ“„ {file}")
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
    
    logger.info("ğŸ‰ EdgeTTSå‚æ•°é›†æˆç³»ç»Ÿæ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
