#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šAPIå¹¶è¡Œå¤„ç†å™¨ - æ•°é‡çº§æ€§èƒ½æå‡æ–¹æ¡ˆ
æ”¯æŒåŒæ—¶ä½¿ç”¨å¤šä¸ªTTS APIæœåŠ¡ï¼Œå®ç°çœŸæ­£çš„å¹¶è¡Œå¤„ç†
"""

import asyncio
import aiohttp
import json
import time
import logging
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any
import pandas as pd
import os
import glob

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('19_æ—¥å¿—æ–‡ä»¶_ç³»ç»Ÿè¿è¡Œæ—¥å¿—å’Œé”™è¯¯è®°å½•/multi_api_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultiAPITTSProcessor:
    """å¤šAPIå¹¶è¡ŒTTSå¤„ç†å™¨"""
    
    def __init__(self):
        # å¤šä¸ªTTS APIç«¯ç‚¹
        self.api_endpoints = [
            "http://127.0.0.1:5001",  # æœ¬åœ°EdgeTTS
            "http://127.0.0.1:5002",  # ç¬¬äºŒä¸ªEdgeTTSå®ä¾‹
            "http://127.0.0.1:5003",  # ç¬¬ä¸‰ä¸ªEdgeTTSå®ä¾‹
        ]
        
        # æ¯ä¸ªAPIçš„å¹¶å‘é™åˆ¶ (æœ€å¤§æ€§èƒ½é…ç½®)
        self.api_concurrency = {
            "http://127.0.0.1:5001": 20,
            "http://127.0.0.1:5002": 20, 
            "http://127.0.0.1:5003": 20,
        }
        
        # æ€»å¹¶å‘æ•°
        self.total_concurrency = sum(self.api_concurrency.values())
        
        # æ–‡ä»¶è¯­éŸ³æ˜ å°„
        self.FILE_VOICE_MAPPING = {
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v9.xlsx": "en-US-JennyNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v5.xlsx": "en-US-AvaNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v4.xlsx": "en-US-NancyNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v8.xlsx": "en-US-AriaNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v3.xlsx": "en-US-KaiNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v2.xlsx": "en-US-SerenaNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200.xlsx": "en-US-EmmaNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v7.xlsx": "en-US-MichelleNeural",
            "å…¨äº§å“_åˆå¹¶ç‰ˆ_3200_v6.xlsx": "en-US-BrandonNeural",
        }
        
        # APIè´Ÿè½½å‡è¡¡
        self.api_load_balancer = {}
        for endpoint in self.api_endpoints:
            self.api_load_balancer[endpoint] = 0
    
    async def get_available_api(self) -> str:
        """è·å–è´Ÿè½½æœ€ä½çš„APIç«¯ç‚¹"""
        min_load = min(self.api_load_balancer.values())
        for endpoint, load in self.api_load_balancer.items():
            if load == min_load:
                return endpoint
        return self.api_endpoints[0]
    
    async def send_to_api(self, session: aiohttp.ClientSession, api_url: str, 
                         scripts: List[Dict], voice: str) -> Dict:
        """å‘é€è„šæœ¬åˆ°æŒ‡å®šAPI"""
        try:
            # æ›´æ–°è´Ÿè½½
            self.api_load_balancer[api_url] += len(scripts)
            
            payload = {
                "scripts": scripts,
                "product_name": f"batch_{int(time.time())}",
                "voice": voice,
                "emotion": "Friendly"
            }
            
            async with session.post(f"{api_url}/generate", json=payload) as response:
                if response.status == 200:
                    result = await response.json()
                    logger.info(f"âœ… API {api_url} æˆåŠŸå¤„ç† {len(scripts)} ä¸ªè„šæœ¬")
                    return result
                else:
                    logger.error(f"âŒ API {api_url} è¿”å›é”™è¯¯: {response.status}")
                    return {"success": False, "error": f"HTTP {response.status}"}
                    
        except Exception as e:
            logger.error(f"âŒ API {api_url} è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return {"success": False, "error": str(e)}
        finally:
            # å‡å°‘è´Ÿè½½
            self.api_load_balancer[api_url] -= len(scripts)
    
    async def process_scripts_parallel(self, all_scripts: List[Dict], voice: str) -> List[Dict]:
        """å¹¶è¡Œå¤„ç†æ‰€æœ‰è„šæœ¬"""
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç† {len(all_scripts)} ä¸ªè„šæœ¬")
        
        # å°†è„šæœ¬åˆ†ç»„ï¼Œæ¯ç»„å‘é€åˆ°ä¸åŒAPI (æœ€å¤§æ€§èƒ½é…ç½®)
        batch_size = 100  # æ¯æ‰¹100ä¸ªè„šæœ¬
        batches = [all_scripts[i:i + batch_size] for i in range(0, len(all_scripts), batch_size)]
        
        results = []
        
        async with aiohttp.ClientSession() as session:
            # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
            tasks = []
            
            for batch in batches:
                api_url = await self.get_available_api()
                task = self.send_to_api(session, api_url, batch, voice)
                tasks.append(task)
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            logger.info(f"ğŸ“¡ å¹¶è¡Œå‘é€ {len(tasks)} ä¸ªæ‰¹æ¬¡åˆ°å¤šä¸ªAPI")
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            for i, result in enumerate(batch_results):
                if isinstance(result, Exception):
                    logger.error(f"âŒ æ‰¹æ¬¡ {i} å¤„ç†å¼‚å¸¸: {str(result)}")
                elif result.get("success"):
                    results.append(result)
                else:
                    logger.error(f"âŒ æ‰¹æ¬¡ {i} å¤„ç†å¤±è´¥: {result.get('error', 'Unknown error')}")
        
        logger.info(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {len(results)} ä¸ªæ‰¹æ¬¡")
        return results
    
    def process_excel_file(self, file_path: str) -> Dict:
        """å¤„ç†å•ä¸ªExcelæ–‡ä»¶"""
        logger.info(f"ğŸ“ å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
        
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(file_path)
        logger.info(f"âœ… è¯»å–åˆ° {len(df)} æ¡è®°å½•")
        
        # è·å–è¯­éŸ³
        file_name = os.path.basename(file_path)
        voice = self.FILE_VOICE_MAPPING.get(file_name, "en-US-JennyNeural")
        logger.info(f"ğŸ¤ ä½¿ç”¨è¯­éŸ³: {voice}")
        
        # å‡†å¤‡è„šæœ¬æ•°æ®
        scripts = []
        for _, row in df.iterrows():
            script_data = {
                "script": str(row.get("è‹±æ–‡", "")),
                "emotion": str(row.get("æƒ…ç»ªç±»å‹", "Friendly")),
                "voice": voice,
                "rate": row.get("rate", 1.0),
                "pitch": row.get("pitch", 1.0),
                "volume": row.get("volume", 1.0)
            }
            scripts.append(script_data)
        
        # å¹¶è¡Œå¤„ç†
        start_time = time.time()
        results = asyncio.run(self.process_scripts_parallel(scripts, voice))
        end_time = time.time()
        
        # ç»Ÿè®¡ç»“æœ
        total_processed = sum(len(result.get("sample_audios", [])) for result in results)
        
        logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {file_name}")
        logger.info(f"   - æ€»è„šæœ¬: {len(scripts)}")
        logger.info(f"   - æˆåŠŸç”Ÿæˆ: {total_processed}")
        logger.info(f"   - è€—æ—¶: {(end_time - start_time)/60:.1f} åˆ†é’Ÿ")
        
        return {
            "file_name": file_name,
            "total_scripts": len(scripts),
            "successful": total_processed,
            "duration": end_time - start_time,
            "results": results
        }
    
    def process_all_files(self, input_dir: str = "18_æ‰¹é‡è¾“å…¥_æ‰¹é‡æ–‡ä»¶è¾“å…¥ç›®å½•"):
        """å¤„ç†æ‰€æœ‰Excelæ–‡ä»¶"""
        logger.info("ğŸµ å¼€å§‹å¤šAPIå¹¶è¡Œå¤„ç†")
        logger.info("=" * 80)
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_files = glob.glob(os.path.join(input_dir, "*.xlsx"))
        logger.info(f"ğŸ“ å‘ç° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
        
        total_start_time = time.time()
        all_results = []
        
        for i, file_path in enumerate(excel_files, 1):
            logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶ {i}/{len(excel_files)}: {os.path.basename(file_path)}")
            
            try:
                result = self.process_excel_file(file_path)
                all_results.append(result)
                
                # æ–‡ä»¶é—´å»¶è¿Ÿ
                if i < len(excel_files):
                    logger.info("â³ æ–‡ä»¶é—´æš‚åœ 2 ç§’...")
                    time.sleep(2)
                    
            except Exception as e:
                logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        
        total_end_time = time.time()
        
        # æœ€ç»ˆç»Ÿè®¡
        total_scripts = sum(r["total_scripts"] for r in all_results)
        total_successful = sum(r["successful"] for r in all_results)
        total_duration = total_end_time - total_start_time
        
        logger.info("=" * 80)
        logger.info("ğŸ‰ å¤šAPIå¹¶è¡Œå¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š æ€»ç»Ÿè®¡:")
        logger.info(f"   - å¤„ç†æ–‡ä»¶: {len(excel_files)}")
        logger.info(f"   - æ€»è„šæœ¬: {total_scripts}")
        logger.info(f"   - æˆåŠŸç”Ÿæˆ: {total_successful}")
        logger.info(f"   - æˆåŠŸç‡: {total_successful/total_scripts*100:.1f}%")
        logger.info(f"   - æ€»è€—æ—¶: {total_duration/60:.1f} åˆ†é’Ÿ")
        logger.info(f"   - å¹³å‡é€Ÿåº¦: {total_successful/(total_duration/60):.1f} ä¸ª/åˆ†é’Ÿ")

if __name__ == "__main__":
    processor = MultiAPITTSProcessor()
    processor.process_all_files()
