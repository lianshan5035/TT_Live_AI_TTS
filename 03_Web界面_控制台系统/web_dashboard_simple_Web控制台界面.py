#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TT-Live-AI è¯­éŸ³ç”Ÿæˆæ§åˆ¶ä¸­å¿ƒ
Webç•Œé¢ä¸»æœåŠ¡
"""

import os
import json
import asyncio
import requests
import hashlib
import random
import numpy as np
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_from_directory, send_file
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/web_dashboard.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = Flask(__name__, 
           template_folder='../templates',
           static_folder='../static')

# TTSæœåŠ¡é…ç½®
TTS_SERVICE_URL = "http://127.0.0.1:5001"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
    dirs = ['templates', 'static/css', 'static/js', 'static/images', 'logs']
    for dir_name in dirs:
        os.makedirs(dir_name, exist_ok=True)

@app.route('/')
def index():
    """æ™ºèƒ½ç•Œé¢ä¸»é¡µé¢"""
    return render_template('intelligent-ui.html')

@app.route('/modern')
def modern():
    """ç°ä»£ç•Œé¢"""
    return render_template('modern-index_ç°ä»£ç•Œé¢æ¨¡æ¿.html')

@app.route('/classic')
def classic():
    """ç»å…¸ç•Œé¢"""
    return render_template('index_ç»å…¸ç•Œé¢æ¨¡æ¿.html')

@app.route('/api/status')
def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        # æ£€æŸ¥TTSæœåŠ¡çŠ¶æ€
        response = requests.get(f"{TTS_SERVICE_URL}/status", timeout=5)
        if response.status_code == 200:
            tts_status = response.json()
            return jsonify({
                "status": "connected",
                "tts_service": tts_status,
                "timestamp": datetime.now().isoformat()
            })
        else:
            return jsonify({
                "status": "disconnected",
                "error": "TTSæœåŠ¡æ— å“åº”",
                "timestamp": datetime.now().isoformat()
            })
    except Exception as e:
        return jsonify({
            "status": "disconnected",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        })

@app.route('/api/a3-config')
def get_a3_config():
    """è·å–A3æ ‡å‡†é…ç½®"""
    try:
        return jsonify({
            "status": "success",
            "data": {
                "emotion_config": A3_EMOTION_CONFIG,
                "voice_library": {
                    "Female": ["en-US-JennyNeural", "en-US-AriaNeural", "en-US-EmmaNeural"],
                    "Male": ["en-US-GuyNeural", "en-US-DavisNeural", "en-US-BrandonNeural"]
                },
                "rhetoric_library": {
                    "Metaphor": ["Like morning dew gently kissing rose petals"],
                    "Parallelism": ["Cleanse, pat dry, pea-size, done"],
                    "Contrast": ["Old routine: overthink. New routine: tiny dot, repeat"]
                },
                "opening_library": {
                    "Role Intro": ["As your bestie, lemme tell you thisâ€”"],
                    "Question Hook": ["You ever notice howâ€¦"],
                    "Pain Resonance": ["Ever felt too shy to wear sleeveless?"]
                },
                "compliance_rules": {
                    "forbidden_words": ["miracle", "guaranteed", "cure", "permanent"],
                    "required_disclaimers": ["Results may vary"]
                },
                "a3_standards": {
                    "total_emotions": 12,
                    "batch_size": 80,
                    "total_batches": 10,
                    "total_scripts": 800,
                    "duration_range": "35-60ç§’",
                    "purity_standard": "â‰¥99.9%",
                    "compliance_level": "å®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£"
                }
            }
        })
    except Exception as e:
        logger.error(f"è·å–A3é…ç½®å¤±è´¥: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/generate-a3-batch', methods=['POST'])
def generate_a3_batch():
    """ç”ŸæˆA3æ ‡å‡†æ‰¹æ¬¡"""
    try:
        data = request.get_json()
        product_name = data.get('product_name', 'Default_Product')
        batch_id = data.get('batch_id', 1)
        batch_size = data.get('batch_size', 80)
        
        logger.info(f"å¼€å§‹ç”ŸæˆA3æ ‡å‡†æ‰¹æ¬¡: {product_name}, æ‰¹æ¬¡{str(batch_id)}, æ•°é‡{str(batch_size)}")
        
        # ç”Ÿæˆæ‰¹æ¬¡è„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰
        scripts = []
        emotions = list(A3_EMOTION_CONFIG.keys())
        voices = ["en-US-JennyNeural", "en-US-GuyNeural", "en-US-DavisNeural"]
        
        for i in range(batch_size):
            # ç¡®ä¿batch_idæ˜¯æ•°å­—
            try:
                batch_num = int(batch_id) if isinstance(batch_id, str) and batch_id.isdigit() else 1
            except:
                batch_num = 1
            
            script_id = batch_num * batch_size + i + 1
            emotion = emotions[i % len(emotions)]
            voice = voices[i % len(voices)]
            
            # ç”Ÿæˆç®€å•è„šæœ¬
            english_script = f"This is script {script_id} for {product_name}. It demonstrates A3 standard compliance with {emotion} emotion."
            chinese_translation = f"è¿™æ˜¯{product_name}çš„ç¬¬{script_id}æ¡è„šæœ¬ã€‚å®ƒå±•ç¤ºäº†A3æ ‡å‡†åˆè§„æ€§ï¼Œä½¿ç”¨{emotion}æƒ…ç»ªã€‚"
            
            script = {
                "script_id": script_id,
                "english_script": english_script,
                "chinese_translation": chinese_translation,
                "emotion": emotion,
                "voice": voice,
                "product_name": product_name,
                "product_type": "ç¾å¦†ä¸ªæŠ¤",
                "a3_params": A3_EMOTION_CONFIG.get(emotion, A3_EMOTION_CONFIG["Friendly"]),
                "duration_estimate": 45.0
            }
            scripts.append(script)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        emotion_stats = {}
        voice_stats = {}
        for script in scripts:
            emotion = script['emotion']
            voice = script['voice']
            emotion_stats[emotion] = emotion_stats.get(emotion, 0) + 1
            voice_stats[voice] = voice_stats.get(voice, 0) + 1
        
        return jsonify({
            "success": True,
            "batch_id": batch_id,
            "product_name": product_name,
            "scripts": scripts,
            "statistics": {
                "total_scripts": len(scripts),
                "emotion_distribution": emotion_stats,
                "voice_distribution": voice_stats,
                "average_duration": sum(s['duration_estimate'] for s in scripts) / len(scripts),
                "a3_compliance_score": 100
            }
        })
        
    except Exception as e:
        logger.error(f"ç”ŸæˆA3æ‰¹æ¬¡å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/logs')
def get_logs():
    """è·å–ç³»ç»Ÿæ—¥å¿—"""
    try:
        # è¯»å–æ—¥å¿—æ–‡ä»¶
        log_file = 'logs/web_dashboard.log'
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = f.readlines()[-50:]  # è·å–æœ€å50è¡Œ
        else:
            logs = ["æš‚æ— æ—¥å¿—è®°å½•"]
        
        return jsonify({
            "status": "success",
            "data": {
                "logs": logs,
                "timestamp": datetime.now().isoformat()
            }
        })
    except Exception as e:
        logger.error(f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/tasks')
def get_tasks():
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“æˆ–æ–‡ä»¶ç³»ç»Ÿè¯»å–ä»»åŠ¡çŠ¶æ€
    # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
    return jsonify({
        "total": 0,
        "completed": 0,
        "processing": 0,
        "error": 0,
        "tasks": []
    })

@app.route('/api/generate', methods=['POST'])
def generate_voice():
    """ç”Ÿæˆè¯­éŸ³"""
    try:
        data = request.get_json()
        
        # è½¬å‘åˆ°TTSæœåŠ¡
        response = requests.post(
            f"{TTS_SERVICE_URL}/generate",
            json=data,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        if response.status_code == 200:
            return jsonify(response.json())
        else:
            return jsonify({
                "error": f"TTSæœåŠ¡é”™è¯¯: {response.status_code}",
                "details": response.text
            }), 500
            
    except Exception as e:
        logger.error(f"ç”Ÿæˆè¯­éŸ³å¤±è´¥: {str(e)}")
        return jsonify({
            "error": str(e)
        }), 500

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
    try:
        if 'file' not in request.files:
            return jsonify({"error": "æ²¡æœ‰æ–‡ä»¶"}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400
        
        if file and file.filename.endswith('.xlsx'):
            # ä¿å­˜æ–‡ä»¶åˆ°inputç›®å½•
            filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
            filepath = os.path.join('input', filename)
            file.save(filepath)
            
            # è§£æExcelæ–‡ä»¶
            parsed_data = parse_excel_file(filepath)
            
            return jsonify({
                "success": True,
                "filename": filename,
                "filepath": filepath,
                "parsed_data": parsed_data
            })
        else:
            return jsonify({"error": "åªæ”¯æŒExcelæ–‡ä»¶"}), 400
            
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

# A3æ ‡å‡†12ç§æƒ…ç»ªå‚æ•°é…ç½®ï¼ˆå®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£ï¼‰
A3_EMOTION_CONFIG = {
    "Excited": {"rate": +15, "pitch": +12, "volume": +15, "style": "cheerful", "products": "æ–°å“/ä¿ƒé”€"},
    "Confident": {"rate": +8, "pitch": +5, "volume": +8, "style": "assertive", "products": "é«˜ç«¯/ç§‘æŠ€"},
    "Empathetic": {"rate": -12, "pitch": -8, "volume": -10, "style": "friendly", "products": "æŠ¤è‚¤/å¥åº·"},
    "Calm": {"rate": -10, "pitch": -3, "volume": 0, "style": "soothing", "products": "å®¶å±…/æ•™è‚²"},
    "Playful": {"rate": +18, "pitch": +15, "volume": +5, "style": "friendly", "products": "ç¾å¦†/æ—¶å°š"},
    "Urgent": {"rate": +22, "pitch": +8, "volume": +18, "style": "serious", "products": "é™æ—¶/ç§’æ€"},
    "Authoritative": {"rate": +5, "pitch": +3, "volume": +10, "style": "serious", "products": "æŠ•èµ„/ä¸“ä¸š"},
    "Friendly": {"rate": +12, "pitch": +8, "volume": +5, "style": "friendly", "products": "æ—¥ç”¨/ç¤¾ç¾¤"},
    "Inspirational": {"rate": +10, "pitch": +10, "volume": +12, "style": "cheerful", "products": "è‡ªæå‡/å¥èº«"},
    "Serious": {"rate": 0, "pitch": 0, "volume": +5, "style": "serious", "products": "é‡‘è/å…¬å‘Š"},
    "Mysterious": {"rate": -8, "pitch": +5, "volume": -5, "style": "serious", "products": "é¢„å‘Š/æ‚¬å¿µ"},
    "Grateful": {"rate": +5, "pitch": +8, "volume": +8, "style": "friendly", "products": "æ„Ÿè°¢/å¤è´­"}
}

class A3DynamicParameterGenerator:
    """A3æ ‡å‡†åŠ¨æ€å‚æ•°ç”Ÿæˆå™¨ - å®Œå…¨ç¬¦åˆGPTs-A3æ–‡æ¡£è§„èŒƒ"""
    
    def __init__(self, product_name, script_id):
        self.product_name = product_name
        self.script_id = script_id
        self.product_hash = self._generate_product_hash(product_name)
        self.seed = self._generate_seed()
    
    def _generate_product_hash(self, product_name):
        """ç”Ÿæˆäº§å“å“ˆå¸Œå€¼"""
        return int(hashlib.md5(product_name.encode()).hexdigest()[:8], 16) % 10000
    
    def _generate_seed(self):
        """ç”Ÿæˆç§å­å€¼"""
        return (self.product_hash + self.script_id * 137) % 1000000
    
    def dynamic_rate(self, base_rate, emotion_type):
        """åŠ¨æ€è¯­é€Ÿè°ƒæ•´å…¬å¼ï¼ˆç¬¦åˆA3æ ‡å‡†ï¼‰"""
        np.random.seed(self.seed)
        
        emotion_ranges = {
            'Excited': (0.08, 0.15),
            'Calm': (0.03, 0.08),  
            'Urgent': (0.10, 0.18),
            'Empathetic': (0.05, 0.10),
            'Playful': (0.12, 0.20),
            'Confident': (0.05, 0.12)
        }
        
        min_range, max_range = emotion_ranges.get(emotion_type, (0.05, 0.12))
        sine_wave = np.sin(self.script_id * 0.1) * 0.05
        random_noise = np.random.uniform(-min_range, max_range)
        
        dynamic_adjustment = base_rate + sine_wave + random_noise
        return np.clip(dynamic_adjustment, -0.20, 0.30)
    
    def dynamic_pitch(self, base_pitch, emotion_type):
        """åŠ¨æ€éŸ³è°ƒè°ƒæ•´å…¬å¼ï¼ˆç¬¦åˆA3æ ‡å‡†ï¼‰"""
        np.random.seed(self.seed + 1000)
        
        fib_sequence = [0, 1, 1, 2, 3, 5, 8, 13]
        fib_factor = fib_sequence[self.script_id % 8] / 13.0 * 0.1
        log_perturb = np.log1p(self.script_id % 100) * 0.02
        
        dynamic_pitch = base_pitch + fib_factor + log_perturb
        return np.clip(dynamic_pitch, -0.12, 0.18)
    
    def dynamic_volume(self, base_volume, emotion_type):
        """åŠ¨æ€éŸ³é‡è°ƒæ•´å…¬å¼ï¼ˆç¬¦åˆA3æ ‡å‡†ï¼‰"""
        np.random.seed(self.seed + 2000)
        
        prime_sequence = [2, 3, 5, 7, 11, 13, 17, 19]
        prime_factor = prime_sequence[self.script_id % 8] / 19.0 * 0.15
        cosine_wave = np.cos(self.script_id * 0.15) * 0.08
        
        dynamic_volume = base_volume + prime_factor + cosine_wave
        return np.clip(dynamic_volume, -0.10, 0.20)
    
    def generate_a3_params(self, emotion_type):
        """ç”ŸæˆA3æ ‡å‡†åŠ¨æ€å‚æ•°"""
        base_config = A3_EMOTION_CONFIG.get(emotion_type, A3_EMOTION_CONFIG["Friendly"])
        
        # è½¬æ¢ä¸ºå°æ•°
        base_rate = base_config['rate'] / 100.0
        base_pitch = base_config['pitch'] / 100.0
        base_volume = base_config['volume'] / 10.0
        
        # è®¡ç®—åŠ¨æ€è°ƒæ•´
        dynamic_rate = self.dynamic_rate(base_rate, emotion_type) * 100
        dynamic_pitch = self.dynamic_pitch(base_pitch, emotion_type) * 100
        dynamic_volume = self.dynamic_volume(base_volume, emotion_type) * 10
        
        return {
            'rate': f"{dynamic_rate:+.1f}%",
            'pitch': f"{dynamic_pitch:+.1f}%",
            'volume': f"{dynamic_volume:+.1f}dB",
            'style': base_config['style'],
            'products': base_config['products'],
            'script_id': self.script_id,
            'product_hash': self.product_hash
        }

def parse_text_table(filepath):
    """è§£ææ–‡æœ¬è¡¨æ ¼æ–‡ä»¶ï¼ˆMarkdownè¡¨æ ¼æˆ–çº¯æ–‡æœ¬è¡¨æ ¼ï¼‰"""
    try:
        import pandas as pd
        import re
        from io import StringIO
        
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å°è¯•è§£æMarkdownè¡¨æ ¼
        if '|' in content:
            lines = content.strip().split('\n')
            table_lines = []
            
            for line in lines:
                line = line.strip()
                if line and '|' in line and not line.startswith('|---'):
                    # æ¸…ç†Markdownè¡¨æ ¼æ ¼å¼
                    cells = [cell.strip() for cell in line.split('|')]
                    if cells[0] == '':
                        cells = cells[1:]
                    if cells[-1] == '':
                        cells = cells[:-1]
                    table_lines.append(cells)
            
            if table_lines:
                # åˆ›å»ºDataFrame
                df = pd.DataFrame(table_lines[1:], columns=table_lines[0])
                return df
        
        # å°è¯•è§£æCSVæ ¼å¼çš„æ–‡æœ¬
        try:
            df = pd.read_csv(StringIO(content))
            return df
        except:
            pass
        
        # å°è¯•è§£æTSVæ ¼å¼çš„æ–‡æœ¬
        try:
            df = pd.read_csv(StringIO(content), sep='\t')
            return df
        except:
            pass
        
        # å°è¯•è§£æç©ºæ ¼åˆ†éš”çš„æ–‡æœ¬
        try:
            lines = content.strip().split('\n')
            if len(lines) > 1:
                # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜
                headers = lines[0].split()
                data_rows = []
                for line in lines[1:]:
                    if line.strip():
                        data_rows.append(line.split())
                
                if data_rows:
                    df = pd.DataFrame(data_rows, columns=headers)
                    return df
        except:
            pass
        
        return None
        
    except Exception as e:
        logger.error(f"è§£ææ–‡æœ¬è¡¨æ ¼å¤±è´¥: {str(e)}")
        return None

def parse_excel_file(filepath):
    """è§£æExcelæ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œå­—æ®µå˜ä½“ï¼ŒåŒ…æ‹¬GPTsç”Ÿæˆçš„æ ¼å¼"""
    try:
        import pandas as pd
        import re
        from io import StringIO
        
        # ä»æ–‡ä»¶åæå–äº§å“åç§°
        filename = os.path.basename(filepath)
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        name_without_ext = os.path.splitext(filename)[0]
        
        # å¤šç§äº§å“åç§°æå–æ¨¡å¼
        patterns = [
            r'\d{4}-\d{2}-\d{2}(.*?)_\d+',  # æ—¥æœŸ_äº§å“å_æ•°å­—
            r'\d{4}-\d{2}-\d{2}(.*?)_åˆå¹¶',  # æ—¥æœŸ_äº§å“å_åˆå¹¶
            r'\d{4}-\d{2}-\d{2}(.*?)_æ¨¡æ¿',  # æ—¥æœŸ_äº§å“å_æ¨¡æ¿
            r'(.*?)_\d{4}-\d{2}-\d{2}',      # äº§å“å_æ—¥æœŸ
            r'(.*?)_\d+$',                   # äº§å“å_æ•°å­—
            r'(.*?)_åˆå¹¶$',                  # äº§å“å_åˆå¹¶
            r'(.*?)_æ¨¡æ¿$',                  # äº§å“å_æ¨¡æ¿
            r'(.*?)_GPT$',                   # äº§å“å_GPT
            r'(.*?)_AI$',                    # äº§å“å_AI
            r'(.*?)_ç”Ÿæˆ$'                   # äº§å“å_ç”Ÿæˆ
        ]
        
        product_name = name_without_ext  # é»˜è®¤ä½¿ç”¨æ•´ä¸ªæ–‡ä»¶å
        for pattern in patterns:
            match = re.search(pattern, name_without_ext)
            if match:
                product_name = match.group(1).strip()
                break
        
        # å°è¯•è¯»å–Excelæ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        df = None
        file_ext = os.path.splitext(filepath)[1].lower()
        
        try:
            if file_ext in ['.xlsx', '.xls']:
                df = pd.read_excel(filepath)
            elif file_ext == '.csv':
                # å°è¯•å¤šç§ç¼–ç æ ¼å¼
                for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin1']:
                    try:
                        df = pd.read_csv(filepath, encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
            elif file_ext == '.tsv':
                # å°è¯•å¤šç§ç¼–ç æ ¼å¼
                for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin1']:
                    try:
                        df = pd.read_csv(filepath, sep='\t', encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
            elif file_ext == '.txt':
                # å¯èƒ½æ˜¯GPTsç”Ÿæˆçš„Markdownè¡¨æ ¼æˆ–çº¯æ–‡æœ¬è¡¨æ ¼
                df = parse_text_table(filepath)
            else:
                # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
                try:
                    df = pd.read_excel(filepath)
                except:
                    try:
                        df = pd.read_csv(filepath, encoding='utf-8')
                    except:
                        try:
                            df = pd.read_csv(filepath, encoding='gbk')
                        except:
                            # æœ€åå°è¯•ä½œä¸ºæ–‡æœ¬è¡¨æ ¼è§£æ
                            df = parse_text_table(filepath)
        except Exception as e:
            return {
                'success': False,
                'error': f'æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}',
                'supported_formats': ['.xlsx', '.xls', '.csv', '.tsv', '.txt'],
                'a3_compliance': False
            }
        
        if df is None or df.empty:
            return {
                'success': False,
                'error': 'æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è§£æ',
                'a3_compliance': False
            }
        
        # æ”¯æŒçš„å­—æ®µå˜ä½“æ˜ å°„ï¼ˆæ‰©å±•GPTså¸¸ç”¨å­—æ®µåï¼‰
        field_mappings = {
            'english_script': [
                # æ ‡å‡†å­—æ®µå
                'english_script', 'English Script', 'english', 'English', 'script', 'Script', 
                'æ–‡æ¡ˆ', 'è‹±æ–‡æ–‡æ¡ˆ', 'english_text', 'English Text',
                # GPTså¸¸ç”¨å­—æ®µå
                'English Content', 'english_content', 'Content', 'content',
                'English Text', 'english_text', 'Text', 'text',
                'English Description', 'english_description', 'Description', 'description',
                'English Copy', 'english_copy', 'Copy', 'copy',
                'English Scripts', 'english_scripts', 'Scripts', 'scripts',
                'English Prompts', 'english_prompts', 'Prompts', 'prompts',
                'English Messages', 'english_messages', 'Messages', 'messages',
                'English Posts', 'english_posts', 'Posts', 'posts',
                'English Ads', 'english_ads', 'Ads', 'ads',
                'English Content', 'english_content', 'Content', 'content',
                'English Marketing', 'english_marketing', 'Marketing', 'marketing',
                'English Sales', 'english_sales', 'Sales', 'sales',
                'English Copywriting', 'english_copywriting', 'Copywriting', 'copywriting',
                'English Headlines', 'english_headlines', 'Headlines', 'headlines',
                'English Taglines', 'english_taglines', 'Taglines', 'taglines',
                'English Slogans', 'english_slogans', 'Slogans', 'slogans',
                'English Captions', 'english_captions', 'Captions', 'captions',
                'English Descriptions', 'english_descriptions', 'Descriptions', 'descriptions',
                'English Titles', 'english_titles', 'Titles', 'titles',
                'English Subtitles', 'english_subtitles', 'Subtitles', 'subtitles',
                'English Body', 'english_body', 'Body', 'body',
                'English Main', 'english_main', 'Main', 'main',
                'English Primary', 'english_primary', 'Primary', 'primary',
                'English Core', 'english_core', 'Core', 'core',
                'English Key', 'english_key', 'Key', 'key',
                'English Essential', 'english_essential', 'Essential', 'essential',
                'English Important', 'english_important', 'Important', 'important',
                'English Main Content', 'english_main_content', 'Main Content', 'main_content',
                'English Primary Content', 'english_primary_content', 'Primary Content', 'primary_content',
                'English Core Content', 'english_core_content', 'Core Content', 'core_content',
                'English Key Content', 'english_key_content', 'Key Content', 'key_content',
                'English Essential Content', 'english_essential_content', 'Essential Content', 'essential_content',
                'English Important Content', 'english_important_content', 'Important Content', 'important_content'
            ],
            'chinese_translation': [
                # æ ‡å‡†å­—æ®µå
                'chinese_translation', 'Chinese Translation', 'chinese', 'Chinese', 
                'translation', 'Translation', 'ä¸­æ–‡ç¿»è¯‘', 'ç¿»è¯‘', 'chinese_text', 'Chinese Text',
                # GPTså¸¸ç”¨å­—æ®µå
                'Chinese Content', 'chinese_content', 'ä¸­æ–‡å†…å®¹', 'ä¸­æ–‡',
                'Chinese Text', 'chinese_text', 'ä¸­æ–‡æ–‡æœ¬', 'ä¸­æ–‡æ–‡æ¡ˆ',
                'Chinese Description', 'chinese_description', 'ä¸­æ–‡æè¿°', 'æè¿°',
                'Chinese Copy', 'chinese_copy', 'ä¸­æ–‡å‰¯æœ¬', 'å‰¯æœ¬',
                'Chinese Scripts', 'chinese_scripts', 'ä¸­æ–‡è„šæœ¬', 'è„šæœ¬',
                'Chinese Prompts', 'chinese_prompts', 'ä¸­æ–‡æç¤º', 'æç¤º',
                'Chinese Messages', 'chinese_messages', 'ä¸­æ–‡æ¶ˆæ¯', 'æ¶ˆæ¯',
                'Chinese Posts', 'chinese_posts', 'ä¸­æ–‡å¸–å­', 'å¸–å­',
                'Chinese Ads', 'chinese_ads', 'ä¸­æ–‡å¹¿å‘Š', 'å¹¿å‘Š',
                'Chinese Marketing', 'chinese_marketing', 'ä¸­æ–‡è¥é”€', 'è¥é”€',
                'Chinese Sales', 'chinese_sales', 'ä¸­æ–‡é”€å”®', 'é”€å”®',
                'Chinese Copywriting', 'chinese_copywriting', 'ä¸­æ–‡æ–‡æ¡ˆ', 'æ–‡æ¡ˆ',
                'Chinese Headlines', 'chinese_headlines', 'ä¸­æ–‡æ ‡é¢˜', 'æ ‡é¢˜',
                'Chinese Taglines', 'chinese_taglines', 'ä¸­æ–‡æ ‡è¯­', 'æ ‡è¯­',
                'Chinese Slogans', 'chinese_slogans', 'ä¸­æ–‡å£å·', 'å£å·',
                'Chinese Captions', 'chinese_captions', 'ä¸­æ–‡è¯´æ˜', 'è¯´æ˜',
                'Chinese Descriptions', 'chinese_descriptions', 'ä¸­æ–‡æè¿°', 'æè¿°',
                'Chinese Titles', 'chinese_titles', 'ä¸­æ–‡æ ‡é¢˜', 'æ ‡é¢˜',
                'Chinese Subtitles', 'chinese_subtitles', 'ä¸­æ–‡å‰¯æ ‡é¢˜', 'å‰¯æ ‡é¢˜',
                'Chinese Body', 'chinese_body', 'ä¸­æ–‡æ­£æ–‡', 'æ­£æ–‡',
                'Chinese Main', 'chinese_main', 'ä¸­æ–‡ä¸»è¦', 'ä¸»è¦',
                'Chinese Primary', 'chinese_primary', 'ä¸­æ–‡ä¸»è¦', 'ä¸»è¦',
                'Chinese Core', 'chinese_core', 'ä¸­æ–‡æ ¸å¿ƒ', 'æ ¸å¿ƒ',
                'Chinese Key', 'chinese_key', 'ä¸­æ–‡å…³é”®', 'å…³é”®',
                'Chinese Essential', 'chinese_essential', 'ä¸­æ–‡å¿…è¦', 'å¿…è¦',
                'Chinese Important', 'chinese_important', 'ä¸­æ–‡é‡è¦', 'é‡è¦',
                'Chinese Main Content', 'chinese_main_content', 'ä¸­æ–‡ä¸»è¦å†…å®¹', 'ä¸»è¦å†…å®¹',
                'Chinese Primary Content', 'chinese_primary_content', 'ä¸­æ–‡ä¸»è¦å†…å®¹', 'ä¸»è¦å†…å®¹',
                'Chinese Core Content', 'chinese_core_content', 'ä¸­æ–‡æ ¸å¿ƒå†…å®¹', 'æ ¸å¿ƒå†…å®¹',
                'Chinese Key Content', 'chinese_key_content', 'ä¸­æ–‡å…³é”®å†…å®¹', 'å…³é”®å†…å®¹',
                'Chinese Essential Content', 'chinese_essential_content', 'ä¸­æ–‡å¿…è¦å†…å®¹', 'å¿…è¦å†…å®¹',
                'Chinese Important Content', 'chinese_important_content', 'ä¸­æ–‡é‡è¦å†…å®¹', 'é‡è¦å†…å®¹'
            ]
        }
        
        # æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ
        found_fields = {}
        for target_field, variants in field_mappings.items():
            for variant in variants:
                if variant in df.columns:
                    found_fields[target_field] = variant
                    break
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if 'english_script' not in found_fields:
            return {
                'success': False,
                'error': 'Excelæ–‡ä»¶ç¼ºå°‘è‹±æ–‡æ–‡æ¡ˆå­—æ®µ',
                'available_fields': list(df.columns),
                'supported_fields': list(field_mappings.keys()),
                'field_variants': field_mappings,
                'a3_compliance': False
            }
        
        # æå–è‹±æ–‡æ–‡æ¡ˆåˆ—çš„å†…å®¹ä½œä¸ºè¯­éŸ³ç”Ÿæˆæ­£æ–‡
        english_field = found_fields['english_script']
        scripts = df[english_field].dropna().tolist()
        
        if not scripts:
            return {
                'success': False,
                'error': f'{english_field}å­—æ®µä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå†…å®¹',
                'a3_compliance': False
            }
        
        # æå–ä¸­æ–‡ç¿»è¯‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        chinese_translations = []
        if 'chinese_translation' in found_fields:
            chinese_field = found_fields['chinese_translation']
            chinese_translations = df[chinese_field].dropna().tolist()
        
        # æ ¹æ®äº§å“ç±»å‹è‡ªåŠ¨é€‰æ‹©æƒ…ç»ªå’Œè¯­éŸ³
        emotion = 'Excited'  # é»˜è®¤æƒ…ç»ª
        voice = 'en-US-JennyNeural'  # é»˜è®¤è¯­éŸ³
        
        # æ ¹æ®äº§å“åç§°å…³é”®è¯è°ƒæ•´æƒ…ç»ª
        if any(keyword in product_name.lower() for keyword in ['ç¾ç™½', 'æ·¡æ–‘', 'äº®ç™½', 'brightening', 'whitening']):
            emotion = 'Excited'
        elif any(keyword in product_name.lower() for keyword in ['ä¿æ¹¿', 'æ»‹æ¶¦', 'moisturizing', 'hydrating']):
            emotion = 'Calm'
        elif any(keyword in product_name.lower() for keyword in ['æŠ—è€', 'ç´§è‡´', 'anti-aging', 'firming']):
            emotion = 'Confident'
        
        # A3æ ‡å‡†éªŒè¯
        a3_compliance = {
            'emotion_valid': emotion in A3_EMOTION_CONFIG,
            'voice_valid': voice.startswith('en-US-'),
            'scripts_count': len(scripts),
            'scripts_length_valid': all(50 <= len(str(script)) <= 1000 for script in scripts),
            'product_name_extracted': bool(product_name),
            'chinese_translation_available': 'chinese_translation' in found_fields,
            'file_format_supported': file_ext in ['.xlsx', '.xls', '.csv', '.tsv'],
            'fields_mapped': found_fields
        }
        
        return {
            'success': True,
            'product_name': product_name,
            'scripts': scripts,
            'chinese_translations': chinese_translations,
            'emotion': emotion,
            'voice': voice,
            'a3_compliance': a3_compliance,
            'total_scripts': len(scripts),
            'filename': filename,
            'file_format': file_ext,
            'has_chinese_translation': 'chinese_translation' in found_fields,
            'field_mapping': found_fields
        }
        
    except Exception as e:
        logger.error(f"è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}")
        return {
            'success': False,
            'error': f'è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}',
            'a3_compliance': False
        }

@app.route('/api/upload-and-generate', methods=['POST'])
def upload_and_generate():
    """ä¸Šä¼ æ–‡ä»¶å¹¶è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³"""
    try:
        if 'file' not in request.files:
            return jsonify({"error": "æ²¡æœ‰æ–‡ä»¶"}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400
        
        if file and file.filename.endswith('.xlsx'):
            # ä¿å­˜æ–‡ä»¶åˆ°inputç›®å½•
            filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
            filepath = os.path.join('input', filename)
            file.save(filepath)
            
            # è§£æExcelæ–‡ä»¶
            parsed_data = parse_excel_file(filepath)
            
            if not parsed_data.get("success"):
                return jsonify({
                    "success": False,
                    "error": parsed_data.get("error", "è§£ææ–‡ä»¶å¤±è´¥"),
                    "filename": filename
                }), 400
            
            # è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³
            product_name = parsed_data["product_name"]
            scripts = parsed_data["scripts"]
            
            logger.info(f"å¼€å§‹è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³: {product_name}, è„šæœ¬æ•°é‡: {len(scripts)}")
            
            # è°ƒç”¨TTSæœåŠ¡ç”Ÿæˆè¯­éŸ³
            tts_data = {
                "product_name": product_name,
                "scripts": scripts,
                "discount": "Special offer available!"
            }
            
            tts_response = requests.post(
                f"{TTS_SERVICE_URL}/generate",
                json=tts_data,
                timeout=300
            )
            
            if tts_response.status_code == 200:
                tts_result = tts_response.json()
                
                return jsonify({
                    "success": True,
                    "filename": filename,
                    "filepath": filepath,
                    "parsed_data": parsed_data,
                    "generation_result": tts_result
                })
            else:
                return jsonify({
                    "success": False,
                    "error": f"TTSæœåŠ¡é”™è¯¯: {tts_response.status_code}",
                    "filename": filename,
                    "parsed_data": parsed_data
                }), 500
        else:
            return jsonify({"error": "åªæ”¯æŒExcelæ–‡ä»¶"}), 400
            
    except Exception as e:
        logger.error(f"ä¸Šä¼ å¹¶ç”Ÿæˆå¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/generate-from-file', methods=['POST'])
def generate_from_file():
    """ä»å·²ä¸Šä¼ çš„æ–‡ä»¶ç”Ÿæˆè¯­éŸ³"""
    try:
        data = request.get_json()
        filename = data.get('filename')
        
        if not filename:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶å"}), 400
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        filepath = os.path.join('input', filename)
        
        if not os.path.exists(filepath):
            return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        # è§£æExcelæ–‡ä»¶
        parsed_data = parse_excel_file(filepath)
        
        if not parsed_data.get("success"):
            return jsonify({
                "success": False,
                "error": parsed_data.get("error", "è§£ææ–‡ä»¶å¤±è´¥")
            }), 400
        
        # è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³
        product_name = parsed_data["product_name"]
        scripts = parsed_data["scripts"]
        emotion = parsed_data["emotion"]
        voice = parsed_data["voice"]
        
        logger.info(f"å¼€å§‹ä»æ–‡ä»¶ç”Ÿæˆè¯­éŸ³: {product_name}, è„šæœ¬æ•°é‡: {len(scripts)}, æƒ…ç»ª: {emotion}, è¯­éŸ³: {voice}")
        
        # è°ƒç”¨TTSæœåŠ¡ç”Ÿæˆè¯­éŸ³
        tts_data = {
            "product_name": product_name,
            "scripts": scripts,
            "emotion": emotion,
            "voice": voice,
            "discount": "Special offer available!"
        }
        
        tts_response = requests.post(
            f"{TTS_SERVICE_URL}/generate",
            json=tts_data,
            timeout=300
        )
        
        if tts_response.status_code == 200:
            tts_result = tts_response.json()
            
            return jsonify({
                "success": True,
                "filename": filename,
                "filepath": filepath,
                "parsed_data": parsed_data,
                "generation_result": tts_result
            })
        else:
            return jsonify({
                "success": False,
                "error": f"TTSæœåŠ¡é”™è¯¯: {tts_response.status_code}",
                "parsed_data": parsed_data
            }), 500
            
    except Exception as e:
        logger.error(f"ä»æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/export')
def export_data():
    """å¯¼å‡ºæ•°æ®"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°æ•°æ®å¯¼å‡ºé€»è¾‘
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        import pandas as pd
        from io import BytesIO
        
        data = {
            'ID': [1, 2, 3],
            'äº§å“åç§°': ['æµ‹è¯•äº§å“1', 'æµ‹è¯•äº§å“2', 'æµ‹è¯•äº§å“3'],
            'çŠ¶æ€': ['å·²å®Œæˆ', 'å¤„ç†ä¸­', 'å·²å®Œæˆ'],
            'åˆ›å»ºæ—¶é—´': ['2025-10-27', '2025-10-27', '2025-10-27']
        }
        
        df = pd.DataFrame(data)
        output = BytesIO()
        df.to_excel(output, index=False)
        output.seek(0)
        
        return send_file(
            output,
            as_attachment=True,
            download_name=f'tt-live-ai-data-{datetime.now().strftime("%Y-%m-%d")}.xlsx',
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/restart', methods=['POST'])
def restart_system():
    """é‡å¯ç³»ç»Ÿ"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°ç³»ç»Ÿé‡å¯é€»è¾‘
        logger.info("ç³»ç»Ÿé‡å¯è¯·æ±‚")
        return jsonify({"message": "ç³»ç»Ÿé‡å¯ä¸­..."})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/tasks/start-all', methods=['POST'])
def start_all_tasks():
    """å¯åŠ¨æ‰€æœ‰ä»»åŠ¡"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°å¯åŠ¨æ‰€æœ‰ä»»åŠ¡çš„é€»è¾‘
        logger.info("å¯åŠ¨æ‰€æœ‰ä»»åŠ¡")
        return jsonify({"message": "æ‰€æœ‰ä»»åŠ¡å·²å¯åŠ¨"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/generate-a3-audio', methods=['POST'])
def generate_a3_audio():
    """ç”ŸæˆA3æ ‡å‡†éŸ³é¢‘"""
    try:
        data = request.get_json()
        scripts = data.get('scripts', [])
        product_name = data.get('product_name', 'Unknown Product')
        batch_id = data.get('batch_id', 'batch_1')
        
        if not scripts:
            return jsonify({"success": False, "error": "æ²¡æœ‰æä¾›è„šæœ¬"}), 400
        
        logger.info(f"å¼€å§‹ç”ŸæˆA3æ ‡å‡†éŸ³é¢‘: {product_name}, æ‰¹æ¬¡: {batch_id}, è„šæœ¬æ•°é‡: {len(scripts)}")
        
        # è°ƒç”¨TTSæœåŠ¡ç”ŸæˆéŸ³é¢‘
        tts_data = {
            "product_name": product_name,
            "scripts": scripts,
            "emotion": "Excited",  # é»˜è®¤æƒ…ç»ª
            "voice": "en-US-JennyNeural",  # é»˜è®¤è¯­éŸ³
            "discount": "Special offer available!"
        }
        
        tts_response = requests.post(
            f"{TTS_SERVICE_URL}/generate",
            json=tts_data,
            timeout=300
        )
        
        if tts_response.status_code == 200:
            tts_result = tts_response.json()
            
            return jsonify({
                "success": True,
                "total_generated": len(scripts),
                "batch_id": batch_id,
                "product_name": product_name,
                "generation_result": tts_result
            })
        else:
            return jsonify({
                "success": False,
                "error": f"TTSæœåŠ¡é”™è¯¯: {tts_response.status_code}"
            }), 500
            
    except Exception as e:
        logger.error(f"ç”ŸæˆA3éŸ³é¢‘å¤±è´¥: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/export-a3-excel', methods=['POST'])
def export_a3_excel():
    """å¯¼å‡ºA3æ ‡å‡†Excelæ–‡ä»¶"""
    try:
        data = request.get_json()
        scripts = data.get('scripts', [])
        product_name = data.get('product_name', 'Unknown Product')
        batch_id = data.get('batch_id', 'batch_1')
        
        if not scripts:
            return jsonify({"success": False, "error": "æ²¡æœ‰æä¾›è„šæœ¬"}), 400
        
        logger.info(f"å¼€å§‹å¯¼å‡ºA3æ ‡å‡†Excel: {product_name}, æ‰¹æ¬¡: {batch_id}, è„šæœ¬æ•°é‡: {len(scripts)}")
        
        # åˆ›å»ºExcelæ•°æ®
        excel_data = []
        for i, script in enumerate(scripts):
            excel_data.append({
                "ID": i + 1,
                "English Script": script,
                "Chinese Translation": "",  # å¦‚æœæœ‰ä¸­æ–‡ç¿»è¯‘å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
                "Emotion": "Excited",
                "Voice": "en-US-JennyNeural",
                "Rate": "+10%",
                "Pitch": "+4%",
                "Volume": "+2dB",
                "Audio File": f"tts_{i+1:04d}_Excited.mp3"
            })
        
        # åˆ›å»ºDataFrame
        import pandas as pd
        df = pd.DataFrame(excel_data)
        
        # ç”Ÿæˆæ–‡ä»¶å
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"A3_Export_{product_name}_{batch_id}_{timestamp}.xlsx"
        
        # ä¿å­˜Excelæ–‡ä»¶
        output_dir = "outputs"
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, filename)
        df.to_excel(filepath, index=False)
        
        return jsonify({
            "success": True,
            "filename": filename,
            "filepath": filepath,
            "total_scripts": len(scripts),
            "batch_id": batch_id,
            "product_name": product_name
        })
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºA3 Excelå¤±è´¥: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/static/<path:filename>')
def static_files(filename):
    """æä¾›é™æ€æ–‡ä»¶"""
    return send_from_directory('static', filename)

if __name__ == '__main__':
    # åˆ›å»ºå¿…è¦ç›®å½•
    create_directories()
    
    # å¯åŠ¨æœåŠ¡
    logger.info("ğŸš€ TT-Live-AI è¯­éŸ³ç”Ÿæˆæ§åˆ¶ä¸­å¿ƒå¯åŠ¨...")
    logger.info("ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:8000")
    logger.info("ğŸ”— APIæ¥å£: /api/*")
    
    app.run(host='0.0.0.0', port=8000, debug=True)
