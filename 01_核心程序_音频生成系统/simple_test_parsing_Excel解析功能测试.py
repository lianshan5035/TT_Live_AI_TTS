#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆExcelè§£æåŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•å„ç§GPTsç”Ÿæˆçš„Excelæ ¼å¼ï¼ˆä¸ä¾èµ–å¤–éƒ¨åº“ï¼‰
"""

import os
import sys
import re
from datetime import datetime

def extract_product_name(filename: str) -> str:
    """ä»æ–‡ä»¶åæå–äº§å“åç§°"""
    # ç§»é™¤æ–‡ä»¶æ‰©å±•å
    name_without_ext = os.path.splitext(filename)[0]
    
    # å¤šç§äº§å“åç§°æå–æ¨¡å¼
    patterns = [
        r'\d{4}-\d{2}-\d{2}(.*?)_\d+',  # æ—¥æœŸ_äº§å“å_æ•°å­—
        r'\d{4}-\d{2}-\d{2}(.*?)_åˆå¹¶',  # æ—¥æœŸ_äº§å“å_åˆå¹¶
        r'\d{4}-\d{2}-\d{2}(.*?)_æ¨¡æ¿',  # æ—¥æœŸ_äº§å“å_æ¨¡æ¿
        r'(.*?)_\d{4}-\d{2}-\d{2}',      # äº§å“å_æ—¥æœŸ
        r'(.*?)_\d+$',                   # äº§å“å_æ•°å­—
        r'(.*?)_åˆå¹¶$',                  # äº§å“å_åˆå¹¶
        r'(.*?)_æ¨¡æ¿$',                  # äº§å“å_æ¨¡æ¿
        r'(.*?)_GPT$',                   # äº§å“å_GPT
        r'(.*?)_AI$',                    # äº§å“å_AI
        r'(.*?)_ç”Ÿæˆ$'                   # äº§å“å_ç”Ÿæˆ
    ]
    
    product_name = name_without_ext  # é»˜è®¤ä½¿ç”¨æ•´ä¸ªæ–‡ä»¶å
    for pattern in patterns:
        match = re.search(pattern, name_without_ext)
        if match:
            product_name = match.group(1).strip()
            break
    
    return product_name

def auto_select_emotion(product_name: str) -> str:
    """æ ¹æ®äº§å“åç§°è‡ªåŠ¨é€‰æ‹©æƒ…ç»ª"""
    product_emotion_map = {
        "ç¾ç™½": "Excited", "æ·¡æ–‘": "Excited", "äº®ç™½": "Excited", "brightening": "Excited",
        "æŠ—è€": "Confident", "ç´§è‡´": "Confident", "firming": "Confident", "anti-aging": "Confident",
        "ä¿æ¹¿": "Calm", "è¡¥æ°´": "Calm", "æ»‹æ¶¦": "Calm", "moisturizing": "Calm",
        "ç»´ç”Ÿç´ ": "Playful", "vitamin": "Playful", "ç²¾å": "Playful", "serum": "Playful",
        "èƒ¶åŸè›‹ç™½": "Empathetic", "collagen": "Empathetic", "å¥åº·": "Empathetic", "health": "Empathetic",
        "ç˜¦èº«": "Motivational", "å‡è‚¥": "Motivational", "fitness": "Motivational", "weight": "Motivational",
        "æŠ¤å‘": "Soothing", "hair": "Soothing", "æŸ”é¡º": "Soothing", "smooth": "Soothing",
        "çœ¼éƒ¨": "Gentle", "eye": "Gentle", "æ¸©å’Œ": "Gentle", "gentle": "Gentle"
    }
    
    product_lower = product_name.lower()
    
    for keyword, emotion in product_emotion_map.items():
        if keyword.lower() in product_lower:
            return emotion
    
    return "Excited"  # é»˜è®¤æƒ…ç»ª

def parse_text_table(filepath: str):
    """è§£ææ–‡æœ¬è¡¨æ ¼æ–‡ä»¶ï¼ˆMarkdownè¡¨æ ¼æˆ–çº¯æ–‡æœ¬è¡¨æ ¼ï¼‰"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å°è¯•è§£æMarkdownè¡¨æ ¼
        if '|' in content:
            lines = content.strip().split('\n')
            table_lines = []
            
            for line in lines:
                line = line.strip()
                if line and '|' in line and not line.startswith('|---'):
                    # æ¸…ç†Markdownè¡¨æ ¼æ ¼å¼
                    cells = [cell.strip() for cell in line.split('|')]
                    if cells[0] == '':
                        cells = cells[1:]
                    if cells[-1] == '':
                        cells = cells[:-1]
                    table_lines.append(cells)
            
            if table_lines:
                # åˆ›å»ºç®€å•çš„æ•°æ®ç»“æ„
                headers = table_lines[0]
                data = table_lines[1:]
                return {'headers': headers, 'data': data}
        
        # å°è¯•è§£æåˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡æœ¬
        if '\t' in content:
            lines = content.strip().split('\n')
            if len(lines) > 1:
                headers = lines[0].split('\t')
                data = []
                for line in lines[1:]:
                    if line.strip():
                        data.append(line.split('\t'))
                return {'headers': headers, 'data': data}
        
        return None
        
    except Exception as e:
        return None

def test_file_parsing():
    """æµ‹è¯•æ–‡ä»¶è§£æåŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ–‡ä»¶è§£æåŠŸèƒ½...")
    print("=" * 60)
    
    # æµ‹è¯•æ–‡ä»¶åè§£æ
    test_filenames = [
        "Lior2025-01-27ç¾ç™½äº§å“_800.xlsx",
        "Lior2025-01-27ç¾ç™½äº§å“_800_Content.xlsx", 
        "Lior2025-01-27ç¾ç™½äº§å“_800_Text.xlsx",
        "Lior2025-01-27ç¾ç™½äº§å“_800_Marketing.xlsx",
        "Lior2025-01-27ç¾ç™½äº§å“_800.csv",
        "Lior2025-01-27ç¾ç™½äº§å“_800.tsv",
        "Lior2025-01-27ç¾ç™½äº§å“_800_Markdown.txt",
        "Lior2025-01-27ç¾ç™½äº§å“_800_TextTable.txt"
    ]
    
    print("ğŸ“„ æµ‹è¯•æ–‡ä»¶åè§£æ:")
    for filename in test_filenames:
        product_name = extract_product_name(filename)
        emotion = auto_select_emotion(product_name)
        print(f"   - {filename}")
        print(f"     äº§å“åç§°: {product_name}")
        print(f"     è‡ªåŠ¨é€‰æ‹©æƒ…ç»ª: {emotion}")
    
    print("\nğŸ“„ æµ‹è¯•æ–‡æœ¬è¡¨æ ¼è§£æ:")
    
    # åˆ›å»ºæµ‹è¯•Markdownè¡¨æ ¼
    markdown_content = """| English Script | Chinese Translation |
|----------------|---------------------|
| Transform your skin with our revolutionary dark spot patch! | ç”¨æˆ‘ä»¬é©å‘½æ€§çš„æ·¡æ–‘è´´ç‰‡æ”¹å˜ä½ çš„è‚Œè‚¤ï¼ |
| Say goodbye to dark spots forever with our advanced formula. | ç”¨æˆ‘ä»¬å…ˆè¿›çš„é…æ–¹æ°¸è¿œå‘Šåˆ«é»‘æ–‘ã€‚ |"""
    
    # åˆ›å»ºæµ‹è¯•åˆ¶è¡¨ç¬¦åˆ†éš”æ–‡æœ¬
    tsv_content = """English Script	Chinese Translation
Transform your skin with our revolutionary dark spot patch!	ç”¨æˆ‘ä»¬é©å‘½æ€§çš„æ·¡æ–‘è´´ç‰‡æ”¹å˜ä½ çš„è‚Œè‚¤ï¼
Say goodbye to dark spots forever with our advanced formula.	ç”¨æˆ‘ä»¬å…ˆè¿›çš„é…æ–¹æ°¸è¿œå‘Šåˆ«é»‘æ–‘ã€‚"""
    
    # æµ‹è¯•Markdownè§£æ
    print("   - Markdownè¡¨æ ¼è§£æ:")
    markdown_result = parse_text_table_from_content(markdown_content)
    if markdown_result:
        print(f"     æ ‡é¢˜: {markdown_result['headers']}")
        print(f"     æ•°æ®è¡Œæ•°: {len(markdown_result['data'])}")
    else:
        print("     è§£æå¤±è´¥")
    
    # æµ‹è¯•TSVè§£æ
    print("   - TSVè¡¨æ ¼è§£æ:")
    tsv_result = parse_text_table_from_content(tsv_content)
    if tsv_result:
        print(f"     æ ‡é¢˜: {tsv_result['headers']}")
        print(f"     æ•°æ®è¡Œæ•°: {len(tsv_result['data'])}")
    else:
        print("     è§£æå¤±è´¥")
    
    print("\nğŸ¯ å­—æ®µæ˜ å°„æµ‹è¯•:")
    
    # æµ‹è¯•å­—æ®µæ˜ å°„
    field_mappings = {
        'english_script': [
            'english_script', 'English Script', 'english', 'English', 'script', 'Script',
            'Content', 'content', 'English Content', 'english_content',
            'Text', 'text', 'English Text', 'english_text',
            'Description', 'description', 'English Description', 'english_description',
            'Copy', 'copy', 'English Copy', 'english_copy',
            'Scripts', 'scripts', 'English Scripts', 'english_scripts',
            'Prompts', 'prompts', 'English Prompts', 'english_prompts',
            'Messages', 'messages', 'English Messages', 'english_messages',
            'Posts', 'posts', 'English Posts', 'english_posts',
            'Ads', 'ads', 'English Ads', 'english_ads',
            'Marketing', 'marketing', 'English Marketing', 'english_marketing',
            'Sales', 'sales', 'English Sales', 'english_sales',
            'Copywriting', 'copywriting', 'English Copywriting', 'english_copywriting',
            'Headlines', 'headlines', 'English Headlines', 'english_headlines',
            'Taglines', 'taglines', 'English Taglines', 'english_taglines',
            'Slogans', 'slogans', 'English Slogans', 'english_slogans',
            'Captions', 'captions', 'English Captions', 'english_captions',
            'Titles', 'titles', 'English Titles', 'english_titles',
            'Subtitles', 'subtitles', 'English Subtitles', 'english_subtitles',
            'Body', 'body', 'English Body', 'english_body',
            'Main', 'main', 'English Main', 'english_main',
            'Primary', 'primary', 'English Primary', 'english_primary',
            'Core', 'core', 'English Core', 'english_core',
            'Key', 'key', 'English Key', 'english_key',
            'Essential', 'essential', 'English Essential', 'english_essential',
            'Important', 'important', 'English Important', 'english_important'
        ],
        'chinese_translation': [
            'chinese_translation', 'Chinese Translation', 'chinese', 'Chinese',
            'translation', 'Translation', 'ä¸­æ–‡ç¿»è¯‘', 'ç¿»è¯‘', 'chinese_text', 'Chinese Text',
            'Chinese Content', 'chinese_content', 'ä¸­æ–‡å†…å®¹', 'ä¸­æ–‡',
            'Chinese Text', 'chinese_text', 'ä¸­æ–‡æ–‡æœ¬', 'ä¸­æ–‡æ–‡æ¡ˆ',
            'Chinese Description', 'chinese_description', 'ä¸­æ–‡æè¿°', 'æè¿°',
            'Chinese Copy', 'chinese_copy', 'ä¸­æ–‡å‰¯æœ¬', 'å‰¯æœ¬',
            'Chinese Scripts', 'chinese_scripts', 'ä¸­æ–‡è„šæœ¬', 'è„šæœ¬',
            'Chinese Prompts', 'chinese_prompts', 'ä¸­æ–‡æç¤º', 'æç¤º',
            'Chinese Messages', 'chinese_messages', 'ä¸­æ–‡æ¶ˆæ¯', 'æ¶ˆæ¯',
            'Chinese Posts', 'posts', 'ä¸­æ–‡å¸–å­', 'å¸–å­',
            'Chinese Ads', 'chinese_ads', 'ä¸­æ–‡å¹¿å‘Š', 'å¹¿å‘Š',
            'Chinese Marketing', 'chinese_marketing', 'ä¸­æ–‡è¥é”€', 'è¥é”€',
            'Chinese Sales', 'sales', 'ä¸­æ–‡é”€å”®', 'é”€å”®',
            'Chinese Copywriting', 'chinese_copywriting', 'ä¸­æ–‡æ–‡æ¡ˆ', 'æ–‡æ¡ˆ',
            'Chinese Headlines', 'chinese_headlines', 'ä¸­æ–‡æ ‡é¢˜', 'æ ‡é¢˜',
            'Chinese Taglines', 'chinese_taglines', 'ä¸­æ–‡æ ‡è¯­', 'æ ‡è¯­',
            'Chinese Slogans', 'chinese_slogans', 'ä¸­æ–‡å£å·', 'å£å·',
            'Chinese Captions', 'captions', 'ä¸­æ–‡è¯´æ˜', 'è¯´æ˜',
            'Chinese Descriptions', 'descriptions', 'ä¸­æ–‡æè¿°', 'æè¿°',
            'Chinese Titles', 'titles', 'ä¸­æ–‡æ ‡é¢˜', 'æ ‡é¢˜',
            'Chinese Subtitles', 'chinese_subtitles', 'ä¸­æ–‡å‰¯æ ‡é¢˜', 'å‰¯æ ‡é¢˜',
            'Chinese Body', 'chinese_body', 'ä¸­æ–‡æ­£æ–‡', 'æ­£æ–‡',
            'Chinese Main', 'chinese_main', 'ä¸­æ–‡ä¸»è¦', 'ä¸»è¦',
            'Chinese Primary', 'chinese_primary', 'ä¸­æ–‡ä¸»è¦', 'ä¸»è¦',
            'Chinese Core', 'core', 'ä¸­æ–‡æ ¸å¿ƒ', 'æ ¸å¿ƒ',
            'Chinese Key', 'key', 'ä¸­æ–‡å…³é”®', 'å…³é”®',
            'Chinese Essential', 'essential', 'ä¸­æ–‡å¿…è¦', 'å¿…è¦',
            'Chinese Important', 'important', 'ä¸­æ–‡é‡è¦', 'é‡è¦'
        ]
    }
    
    # æµ‹è¯•å„ç§å­—æ®µå
    test_headers = [
        ['english_script', 'chinese_translation'],
        ['Content', 'Chinese'],
        ['Text', 'Chinese Text'],
        ['English Marketing', 'Chinese Marketing'],
        ['script', 'translation'],
        ['english', 'chinese'],
        ['English Content', 'Chinese Content'],
        ['Copy', 'Chinese Copy']
    ]
    
    for headers in test_headers:
        found_fields = {}
        for target_field, variants in field_mappings.items():
            for variant in variants:
                if variant in headers:
                    found_fields[target_field] = variant
                    break
        
        print(f"   - æ ‡é¢˜: {headers}")
        print(f"     æ˜ å°„ç»“æœ: {found_fields}")
        print(f"     æ”¯æŒåº¦: {'âœ… å®Œå…¨æ”¯æŒ' if len(found_fields) == 2 else 'âš ï¸ éƒ¨åˆ†æ”¯æŒ' if len(found_fields) == 1 else 'âŒ ä¸æ”¯æŒ'}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
    print("âœ… Excelè§£æåŠŸèƒ½æ ¸å¿ƒé€»è¾‘éªŒè¯é€šè¿‡")
    print("âœ… æ”¯æŒGPTsç”Ÿæˆçš„å„ç§æ–‡ä»¶æ ¼å¼å’Œå­—æ®µå")
    print("âœ… äº§å“åç§°æå–å’Œæƒ…ç»ªåŒ¹é…åŠŸèƒ½æ­£å¸¸")

def parse_text_table_from_content(content: str):
    """ä»å†…å®¹è§£ææ–‡æœ¬è¡¨æ ¼"""
    try:
        # å°è¯•è§£æMarkdownè¡¨æ ¼
        if '|' in content:
            lines = content.strip().split('\n')
            table_lines = []
            
            for line in lines:
                line = line.strip()
                if line and '|' in line and not line.startswith('|---'):
                    # æ¸…ç†Markdownè¡¨æ ¼æ ¼å¼
                    cells = [cell.strip() for cell in line.split('|')]
                    if cells[0] == '':
                        cells = cells[1:]
                    if cells[-1] == '':
                        cells = cells[:-1]
                    table_lines.append(cells)
            
            if table_lines:
                # åˆ›å»ºç®€å•çš„æ•°æ®ç»“æ„
                headers = table_lines[0]
                data = table_lines[1:]
                return {'headers': headers, 'data': data}
        
        # å°è¯•è§£æåˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡æœ¬
        if '\t' in content:
            lines = content.strip().split('\n')
            if len(lines) > 1:
                headers = lines[0].split('\t')
                data = []
                for line in lines[1:]:
                    if line.strip():
                        data.append(line.split('\t'))
                return {'headers': headers, 'data': data}
        
        return None
        
    except Exception as e:
        return None

if __name__ == "__main__":
    test_file_parsing()
