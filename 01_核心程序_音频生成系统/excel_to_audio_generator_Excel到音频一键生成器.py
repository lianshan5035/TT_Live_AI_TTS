#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excelåˆ°éŸ³é¢‘ä¸€é”®ç”Ÿæˆå™¨
ä»Excelæ–‡ä»¶ç›´æ¥ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ï¼Œå†…ç½®å®Œæ•´æµç¨‹
"""

import os
import sys
import json
import pandas as pd
import requests
import time
import random
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
import subprocess
import threading
from io import StringIO

class ExcelToAudioGenerator:
    def __init__(self):
        self.tts_url = "http://127.0.0.1:5001"
        self.output_dir = "audio_outputs"
        self.temp_dir = "temp_excel"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # A3æ ‡å‡†æƒ…ç»ªé…ç½®
        self.emotion_config = {
            "Excited": {
                "voice": "en-US-JennyNeural",
                "rate_range": [10, 25],
                "pitch_range": [5, 15],
                "volume_range": [2, 10]
            },
            "Confident": {
                "voice": "en-US-GuyNeural", 
                "rate_range": [5, 20],
                "pitch_range": [2, 12],
                "volume_range": [0, 8]
            },
            "Calm": {
                "voice": "en-US-DavisNeural",
                "rate_range": [-5, 10],
                "pitch_range": [-2, 8],
                "volume_range": [-2, 5]
            },
            "Playful": {
                "voice": "en-US-JennyNeural",
                "rate_range": [15, 30],
                "pitch_range": [8, 18],
                "volume_range": [3, 12]
            },
            "Empathetic": {
                "voice": "en-US-GuyNeural",
                "rate_range": [0, 15],
                "pitch_range": [0, 10],
                "volume_range": [0, 6]
            },
            "Motivational": {
                "voice": "en-US-DavisNeural",
                "rate_range": [8, 22],
                "pitch_range": [4, 14],
                "volume_range": [2, 10]
            },
            "Soothing": {
                "voice": "en-US-JennyNeural",
                "rate_range": [-2, 8],
                "pitch_range": [-1, 6],
                "volume_range": [-1, 4]
            },
            "Gentle": {
                "voice": "en-US-GuyNeural",
                "rate_range": [0, 12],
                "pitch_range": [0, 8],
                "volume_range": [0, 5]
            }
        }
        
        # äº§å“å…³é”®è¯åˆ°æƒ…ç»ªçš„æ˜ å°„
        self.product_emotion_map = {
            "ç¾ç™½": "Excited", "æ·¡æ–‘": "Excited", "äº®ç™½": "Excited", "brightening": "Excited",
            "æŠ—è€": "Confident", "ç´§è‡´": "Confident", "firming": "Confident", "anti-aging": "Confident",
            "ä¿æ¹¿": "Calm", "è¡¥æ°´": "Calm", "æ»‹æ¶¦": "Calm", "moisturizing": "Calm",
            "ç»´ç”Ÿç´ ": "Playful", "vitamin": "Playful", "ç²¾å": "Playful", "serum": "Playful",
            "èƒ¶åŸè›‹ç™½": "Empathetic", "collagen": "Empathetic", "å¥åº·": "Empathetic", "health": "Empathetic",
            "ç˜¦èº«": "Motivational", "å‡è‚¥": "Motivational", "fitness": "Motivational", "weight": "Motivational",
            "æŠ¤å‘": "Soothing", "hair": "Soothing", "æŸ”é¡º": "Soothing", "smooth": "Soothing",
            "çœ¼éƒ¨": "Gentle", "eye": "Gentle", "æ¸©å’Œ": "Gentle", "gentle": "Gentle"
        }

    def extract_product_name(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–äº§å“åç§°"""
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        name_without_ext = os.path.splitext(filename)[0]
        
        # å¤šç§äº§å“åç§°æå–æ¨¡å¼
        patterns = [
            r'\d{4}-\d{2}-\d{2}(.*?)_\d+',  # æ—¥æœŸ_äº§å“å_æ•°å­—
            r'\d{4}-\d{2}-\d{2}(.*?)_åˆå¹¶',  # æ—¥æœŸ_äº§å“å_åˆå¹¶
            r'\d{4}-\d{2}-\d{2}(.*?)_æ¨¡æ¿',  # æ—¥æœŸ_äº§å“å_æ¨¡æ¿
            r'(.*?)_\d{4}-\d{2}-\d{2}',      # äº§å“å_æ—¥æœŸ
            r'(.*?)_\d+$',                   # äº§å“å_æ•°å­—
            r'(.*?)_åˆå¹¶$',                  # äº§å“å_åˆå¹¶
            r'(.*?)_æ¨¡æ¿$',                  # äº§å“å_æ¨¡æ¿
            r'(.*?)_GPT$',                   # äº§å“å_GPT
            r'(.*?)_AI$',                    # äº§å“å_AI
            r'(.*?)_ç”Ÿæˆ$'                   # äº§å“å_ç”Ÿæˆ
        ]
        
        product_name = name_without_ext  # é»˜è®¤ä½¿ç”¨æ•´ä¸ªæ–‡ä»¶å
        for pattern in patterns:
            match = re.search(pattern, name_without_ext)
            if match:
                product_name = match.group(1).strip()
                break
        
        return product_name

    def auto_select_emotion(self, product_name: str) -> str:
        """æ ¹æ®äº§å“åç§°è‡ªåŠ¨é€‰æ‹©æƒ…ç»ª"""
        product_lower = product_name.lower()
        
        for keyword, emotion in self.product_emotion_map.items():
            if keyword.lower() in product_lower:
                return emotion
        
        # é»˜è®¤æƒ…ç»ª
        return "Excited"

    def parse_text_table(self, filepath: str):
        """è§£ææ–‡æœ¬è¡¨æ ¼æ–‡ä»¶ï¼ˆMarkdownè¡¨æ ¼æˆ–çº¯æ–‡æœ¬è¡¨æ ¼ï¼‰"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å°è¯•è§£æMarkdownè¡¨æ ¼
            if '|' in content:
                lines = content.strip().split('\n')
                table_lines = []
                
                for line in lines:
                    line = line.strip()
                    if line and '|' in line and not line.startswith('|---'):
                        # æ¸…ç†Markdownè¡¨æ ¼æ ¼å¼
                        cells = [cell.strip() for cell in line.split('|')]
                        if cells[0] == '':
                            cells = cells[1:]
                        if cells[-1] == '':
                            cells = cells[:-1]
                        table_lines.append(cells)
                
                if table_lines:
                    # åˆ›å»ºDataFrame
                    df = pd.DataFrame(table_lines[1:], columns=table_lines[0])
                    return df
            
            # å°è¯•è§£æCSVæ ¼å¼çš„æ–‡æœ¬
            try:
                df = pd.read_csv(StringIO(content))
                return df
            except:
                pass
            
            # å°è¯•è§£æTSVæ ¼å¼çš„æ–‡æœ¬
            try:
                df = pd.read_csv(StringIO(content), sep='\t')
                return df
            except:
                pass
            
            # å°è¯•è§£æç©ºæ ¼åˆ†éš”çš„æ–‡æœ¬
            try:
                lines = content.strip().split('\n')
                if len(lines) > 1:
                    # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜
                    headers = lines[0].split()
                    data_rows = []
                    for line in lines[1:]:
                        if line.strip():
                            data_rows.append(line.split())
                    
                    if data_rows:
                        df = pd.DataFrame(data_rows, columns=headers)
                        return df
            except:
                pass
            
            return None
            
        except Exception as e:
            return None

    def parse_excel_file(self, filepath: str) -> Dict[str, Any]:
        """è§£æExcelæ–‡ä»¶ï¼Œæå–å£æ’­æ­£æ–‡"""
        try:
            filename = os.path.basename(filepath)
            product_name = self.extract_product_name(filename)
            
            # å°è¯•è¯»å–Excelæ–‡ä»¶
            df = None
            file_ext = os.path.splitext(filepath)[1].lower()
            
            try:
                if file_ext in ['.xlsx', '.xls']:
                    df = pd.read_excel(filepath)
                elif file_ext == '.csv':
                    # å°è¯•å¤šç§ç¼–ç æ ¼å¼
                    for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin1']:
                        try:
                            df = pd.read_csv(filepath, encoding=encoding)
                            break
                        except UnicodeDecodeError:
                            continue
                elif file_ext == '.tsv':
                    # å°è¯•å¤šç§ç¼–ç æ ¼å¼
                    for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin1']:
                        try:
                            df = pd.read_csv(filepath, sep='\t', encoding=encoding)
                            break
                        except UnicodeDecodeError:
                            continue
                elif file_ext == '.txt':
                    # å¯èƒ½æ˜¯GPTsç”Ÿæˆçš„Markdownè¡¨æ ¼æˆ–çº¯æ–‡æœ¬è¡¨æ ¼
                    df = self.parse_text_table(filepath)
            except Exception as e:
                return {
                    'success': False,
                    'error': f'æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}'
                }
            
            if df is None or df.empty:
                return {
                    'success': False,
                    'error': 'æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è§£æ'
                }
            
            # æ‰©å±•çš„å­—æ®µå˜ä½“æ˜ å°„ï¼ˆæ”¯æŒGPTsç”Ÿæˆçš„å„ç§å­—æ®µåï¼‰
            field_mappings = {
                'english_script': [
                    # æ ‡å‡†å­—æ®µå
                    'english_script', 'English Script', 'english', 'English', 'script', 'Script', 
                    'æ–‡æ¡ˆ', 'è‹±æ–‡æ–‡æ¡ˆ', 'english_text', 'English Text',
                    # GPTså¸¸ç”¨å­—æ®µå
                    'Content', 'content', 'English Content', 'english_content',
                    'Text', 'text', 'English Text', 'english_text',
                    'Description', 'description', 'English Description', 'english_description',
                    'Copy', 'copy', 'English Copy', 'english_copy',
                    'Scripts', 'scripts', 'English Scripts', 'english_scripts',
                    'Prompts', 'prompts', 'English Prompts', 'english_prompts',
                    'Messages', 'messages', 'English Messages', 'english_messages',
                    'Posts', 'posts', 'English Posts', 'english_posts',
                    'Ads', 'ads', 'English Ads', 'english_ads',
                    'Marketing', 'marketing', 'English Marketing', 'english_marketing',
                    'Sales', 'sales', 'English Sales', 'english_sales',
                    'Copywriting', 'copywriting', 'English Copywriting', 'english_copywriting',
                    'Headlines', 'headlines', 'English Headlines', 'english_headlines',
                    'Taglines', 'taglines', 'English Taglines', 'english_taglines',
                    'Slogans', 'slogans', 'English Slogans', 'english_slogans',
                    'Captions', 'captions', 'English Captions', 'english_captions',
                    'Titles', 'titles', 'English Titles', 'english_titles',
                    'Subtitles', 'subtitles', 'English Subtitles', 'english_subtitles',
                    'Body', 'body', 'English Body', 'english_body',
                    'Main', 'main', 'English Main', 'english_main',
                    'Primary', 'primary', 'English Primary', 'english_primary',
                    'Core', 'core', 'English Core', 'english_core',
                    'Key', 'key', 'English Key', 'english_key',
                    'Essential', 'essential', 'English Essential', 'english_essential',
                    'Important', 'important', 'English Important', 'english_important',
                    'Main Content', 'main_content', 'English Main Content', 'english_main_content',
                    'Primary Content', 'primary_content', 'English Primary Content', 'primary_content',
                    'Core Content', 'core_content', 'English Core Content', 'core_content',
                    'Key Content', 'key_content', 'English Key Content', 'key_content',
                    'Essential Content', 'essential_content', 'English Essential Content', 'essential_content',
                    'Important Content', 'important_content', 'English Important Content', 'important_content'
                ],
                'chinese_translation': [
                    # æ ‡å‡†å­—æ®µå
                    'chinese_translation', 'Chinese Translation', 'chinese', 'Chinese', 
                    'translation', 'Translation', 'ä¸­æ–‡ç¿»è¯‘', 'ç¿»è¯‘', 'chinese_text', 'Chinese Text',
                    # GPTså¸¸ç”¨å­—æ®µå
                    'Chinese Content', 'chinese_content', 'ä¸­æ–‡å†…å®¹', 'ä¸­æ–‡',
                    'Chinese Text', 'chinese_text', 'ä¸­æ–‡æ–‡æœ¬', 'ä¸­æ–‡æ–‡æ¡ˆ',
                    'Chinese Description', 'chinese_description', 'ä¸­æ–‡æè¿°', 'æè¿°',
                    'Chinese Copy', 'chinese_copy', 'ä¸­æ–‡å‰¯æœ¬', 'å‰¯æœ¬',
                    'Chinese Scripts', 'chinese_scripts', 'ä¸­æ–‡è„šæœ¬', 'è„šæœ¬',
                    'Chinese Prompts', 'chinese_prompts', 'ä¸­æ–‡æç¤º', 'æç¤º',
                    'Chinese Messages', 'chinese_messages', 'ä¸­æ–‡æ¶ˆæ¯', 'æ¶ˆæ¯',
                    'Chinese Posts', 'posts', 'ä¸­æ–‡å¸–å­', 'å¸–å­',
                    'Chinese Ads', 'chinese_ads', 'ä¸­æ–‡å¹¿å‘Š', 'å¹¿å‘Š',
                    'Chinese Marketing', 'chinese_marketing', 'ä¸­æ–‡è¥é”€', 'è¥é”€',
                    'Chinese Sales', 'sales', 'ä¸­æ–‡é”€å”®', 'é”€å”®',
                    'Chinese Copywriting', 'chinese_copywriting', 'ä¸­æ–‡æ–‡æ¡ˆ', 'æ–‡æ¡ˆ',
                    'Chinese Headlines', 'chinese_headlines', 'ä¸­æ–‡æ ‡é¢˜', 'æ ‡é¢˜',
                    'Chinese Taglines', 'chinese_taglines', 'ä¸­æ–‡æ ‡è¯­', 'æ ‡è¯­',
                    'Chinese Slogans', 'chinese_slogans', 'ä¸­æ–‡å£å·', 'å£å·',
                    'Chinese Captions', 'captions', 'ä¸­æ–‡è¯´æ˜', 'è¯´æ˜',
                    'Chinese Descriptions', 'descriptions', 'ä¸­æ–‡æè¿°', 'æè¿°',
                    'Chinese Titles', 'titles', 'ä¸­æ–‡æ ‡é¢˜', 'æ ‡é¢˜',
                    'Chinese Subtitles', 'chinese_subtitles', 'ä¸­æ–‡å‰¯æ ‡é¢˜', 'å‰¯æ ‡é¢˜',
                    'Chinese Body', 'chinese_body', 'ä¸­æ–‡æ­£æ–‡', 'æ­£æ–‡',
                    'Chinese Main', 'chinese_main', 'ä¸­æ–‡ä¸»è¦', 'ä¸»è¦',
                    'Chinese Primary', 'chinese_primary', 'ä¸­æ–‡ä¸»è¦', 'ä¸»è¦',
                    'Chinese Core', 'core', 'ä¸­æ–‡æ ¸å¿ƒ', 'æ ¸å¿ƒ',
                    'Chinese Key', 'key', 'ä¸­æ–‡å…³é”®', 'å…³é”®',
                    'Chinese Essential', 'essential', 'ä¸­æ–‡å¿…è¦', 'å¿…è¦',
                    'Chinese Important', 'important', 'ä¸­æ–‡é‡è¦', 'é‡è¦',
                    'Chinese Main Content', 'chinese_main_content', 'ä¸­æ–‡ä¸»è¦å†…å®¹', 'ä¸»è¦å†…å®¹',
                    'Chinese Primary Content', 'chinese_primary_content', 'ä¸­æ–‡ä¸»è¦å†…å®¹', 'ä¸»è¦å†…å®¹',
                    'Chinese Core Content', 'chinese_core_content', 'ä¸­æ–‡æ ¸å¿ƒå†…å®¹', 'æ ¸å¿ƒå†…å®¹',
                    'Chinese Key Content', 'chinese_key_content', 'ä¸­æ–‡å…³é”®å†…å®¹', 'å…³é”®å†…å®¹',
                    'Chinese Essential Content', 'essential_content', 'ä¸­æ–‡å¿…è¦å†…å®¹', 'å¿…è¦å†…å®¹',
                    'Chinese Important Content', 'chinese_important_content', 'ä¸­æ–‡é‡è¦å†…å®¹', 'é‡è¦å†…å®¹'
                ]
            }
            
            # æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ
            found_fields = {}
            for target_field, variants in field_mappings.items():
                for variant in variants:
                    if variant in df.columns:
                        found_fields[target_field] = variant
                        break
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if 'english_script' not in found_fields:
                return {
                    'success': False,
                    'error': 'Excelæ–‡ä»¶ç¼ºå°‘è‹±æ–‡æ–‡æ¡ˆå­—æ®µ',
                    'available_fields': list(df.columns),
                    'supported_fields': list(field_mappings.keys()),
                    'field_variants': field_mappings,
                    'a3_compliance': False
                }
            
            # æå–è‹±æ–‡æ–‡æ¡ˆåˆ—çš„å†…å®¹ä½œä¸ºè¯­éŸ³ç”Ÿæˆæ­£æ–‡
            english_field = found_fields['english_script']
            scripts = df[english_field].dropna().tolist()
            
            if not scripts:
                return {
                    'success': False,
                    'error': f'{english_field}å­—æ®µä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå†…å®¹',
                    'a3_compliance': False
                }
            
            # æå–ä¸­æ–‡ç¿»è¯‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            chinese_translations = []
            if 'chinese_translation' in found_fields:
                chinese_field = found_fields['chinese_translation']
                chinese_translations = df[chinese_field].dropna().tolist()
            
            # æ ¹æ®äº§å“ç±»å‹è‡ªåŠ¨é€‰æ‹©æƒ…ç»ªå’Œè¯­éŸ³
            emotion = self.auto_select_emotion(product_name)
            voice = self.emotion_config[emotion]['voice']
            
            # A3æ ‡å‡†éªŒè¯
            a3_compliance = {
                'emotion_valid': emotion in self.emotion_config,
                'voice_valid': voice.startswith('en-US-'),
                'scripts_count': len(scripts),
                'scripts_length_valid': all(50 <= len(str(script)) <= 1000 for script in scripts),
                'product_name_extracted': bool(product_name),
                'chinese_translation_available': 'chinese_translation' in found_fields,
                'file_format_supported': file_ext in ['.xlsx', '.xls', '.csv', '.tsv', '.txt'],
                'fields_mapped': bool(found_fields)
            }
            
            return {
                'success': True,
                'product_name': product_name,
                'scripts': scripts,
                'chinese_translations': chinese_translations,
                'emotion': emotion,
                'voice': voice,
                'a3_compliance': a3_compliance,
                'total_scripts': len(scripts),
                'filename': filename,
                'file_format': file_ext,
                'has_chinese_translation': 'chinese_translation' in found_fields,
                'field_mapping': found_fields
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}',
                'supported_formats': ['.xlsx', '.xls', '.csv', '.tsv', '.txt'],
                'a3_compliance': False
            }

    def generate_audio_parameters(self, emotion: str, script_index: int) -> Dict[str, str]:
        """ç”ŸæˆA3æ ‡å‡†éŸ³é¢‘å‚æ•°"""
        config = self.emotion_config[emotion]
        
        # ä½¿ç”¨æ­£å¼¦æ³¢+æ–æ³¢é‚£å¥‘+ç´ æ•°åºåˆ—ç®—æ³•
        rate_base = random.randint(config['rate_range'][0], config['rate_range'][1])
        pitch_base = random.randint(config['pitch_range'][0], config['pitch_range'][1])
        volume_base = random.randint(config['volume_range'][0], config['volume_range'][1])
        
        # æ·»åŠ åŠ¨æ€å˜åŒ–
        sine_factor = int(5 * (1 + 0.3 * (script_index % 10)))
        fib_factor = int(3 * (1 + 0.2 * (script_index % 8)))
        prime_factor = int(2 * (1 + 0.1 * (script_index % 7)))
        
        rate = rate_base + sine_factor
        pitch = pitch_base + fib_factor
        volume = volume_base + prime_factor
        
        return {
            'rate': f"+{rate}%",
            'pitch': f"+{pitch}%",
            'volume': f"+{volume}dB"
        }

    def generate_audio_files(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        try:
            product_name = parsed_data['product_name']
            scripts = parsed_data['scripts']
            emotion = parsed_data['emotion']
            voice = parsed_data['voice']
            
            # åˆ›å»ºäº§å“è¾“å‡ºç›®å½•
            product_dir = os.path.join(self.output_dir, product_name)
            os.makedirs(product_dir, exist_ok=True)
            
            print(f"ğŸµ å¼€å§‹ç”ŸæˆéŸ³é¢‘æ–‡ä»¶: {product_name}")
            print(f"   - æƒ…ç»ª: {emotion}")
            print(f"   - è¯­éŸ³: {voice}")
            print(f"   - æ–‡æ¡ˆæ•°é‡: {len(scripts)}")
            
            # è°ƒç”¨TTSæœåŠ¡ç”ŸæˆéŸ³é¢‘
            tts_data = {
                "product_name": product_name,
                "scripts": scripts,
                "emotion": emotion,
                "voice": voice,
                "discount": "Special offer available!"
            }
            
            response = requests.post(
                f"{self.tts_url}/generate",
                json=tts_data,
                timeout=300
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # ç”ŸæˆéŸ³é¢‘å‚æ•°æŠ¥å‘Š
                audio_params = []
                for i, script in enumerate(scripts):
                    params = self.generate_audio_parameters(emotion, i)
                    audio_params.append({
                        'script_id': i + 1,
                        'script': script[:50] + "..." if len(script) > 50 else script,
                        'emotion': emotion,
                        'voice': voice,
                        'rate': params['rate'],
                        'pitch': params['pitch'],
                        'volume': params['volume'],
                        'audio_file': f"tts_{i+1:04d}_{emotion}.mp3"
                    })
                
                return {
                    'success': True,
                    'product_name': product_name,
                    'total_scripts': len(scripts),
                    'emotion': emotion,
                    'voice': voice,
                    'audio_directory': product_dir,
                    'audio_params': audio_params,
                    'tts_result': result
                }
            else:
                return {
                    'success': False,
                    'error': f'TTSæœåŠ¡é”™è¯¯: {response.status_code}'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'ç”ŸæˆéŸ³é¢‘å¤±è´¥: {str(e)}'
            }

    def save_generation_report(self, result: Dict[str, Any], original_file: str):
        """ä¿å­˜ç”ŸæˆæŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(self.output_dir, f"generation_report_{timestamp}.json")
        
        report_data = {
            'generation_time': datetime.now().isoformat(),
            'original_file': original_file,
            'result': result
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š ç”ŸæˆæŠ¥å‘Šä¿å­˜åˆ°: {report_file}")

    def process_excel_file(self, filepath: str) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªExcelæ–‡ä»¶ï¼Œç”ŸæˆéŸ³é¢‘"""
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {os.path.basename(filepath)}")
        
        # 1. è§£æExcelæ–‡ä»¶
        print("ğŸ” è§£æExcelæ–‡ä»¶...")
        parsed_data = self.parse_excel_file(filepath)
        
        if not parsed_data['success']:
            print(f"âŒ è§£æå¤±è´¥: {parsed_data['error']}")
            return parsed_data
        
        print(f"âœ… è§£ææˆåŠŸ:")
        print(f"   - äº§å“åç§°: {parsed_data['product_name']}")
        print(f"   - æ–‡æ¡ˆæ•°é‡: {parsed_data['total_scripts']}")
        print(f"   - è‡ªåŠ¨é€‰æ‹©æƒ…ç»ª: {parsed_data['emotion']}")
        print(f"   - è¯­éŸ³æ¨¡å‹: {parsed_data['voice']}")
        
        # 2. ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        print("\nğŸµ ç”ŸæˆéŸ³é¢‘æ–‡ä»¶...")
        audio_result = self.generate_audio_files(parsed_data)
        
        if not audio_result['success']:
            print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {audio_result['error']}")
            return audio_result
        
        print(f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ:")
        print(f"   - éŸ³é¢‘ç›®å½•: {audio_result['audio_directory']}")
        print(f"   - éŸ³é¢‘æ–‡ä»¶æ•°: {audio_result['total_scripts']}")
        
        # 3. ä¿å­˜ç”ŸæˆæŠ¥å‘Š
        self.save_generation_report(audio_result, filepath)
        
        return audio_result

    def batch_process_files(self, file_paths: List[str]) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªExcelæ–‡ä»¶"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
        print("=" * 60)
        
        results = []
        for i, filepath in enumerate(file_paths, 1):
            print(f"\nğŸ“¦ å¤„ç†æ–‡ä»¶ {i}/{len(file_paths)}")
            result = self.process_excel_file(filepath)
            results.append(result)
            
            if result['success']:
                print(f"âœ… æ–‡ä»¶ {i} å¤„ç†å®Œæˆ")
            else:
                print(f"âŒ æ–‡ä»¶ {i} å¤„ç†å¤±è´¥")
        
        # ç»Ÿè®¡ç»“æœ
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"âœ… æˆåŠŸ: {successful}")
        print(f"âŒ å¤±è´¥: {failed}")
        print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¿å­˜åœ¨: {self.output_dir}")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Excelåˆ°éŸ³é¢‘ä¸€é”®ç”Ÿæˆå™¨")
    print("=" * 50)
    
    generator = ExcelToAudioGenerator()
    
    # æ£€æŸ¥TTSæœåŠ¡
    try:
        response = requests.get(f"{generator.tts_url}/health", timeout=5)
        if response.status_code != 200:
            print("âŒ TTSæœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨:")
            print("   python3 run_tts.py")
            return
    except:
        print("âŒ TTSæœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨:")
        print("   python3 run_tts.py")
        return
    
    print("âœ… TTSæœåŠ¡è¿è¡Œæ­£å¸¸")
    
    # è·å–è¾“å…¥æ–‡ä»¶
    print("\nè¯·é€‰æ‹©å¤„ç†æ–¹å¼:")
    print("1. å¤„ç†å•ä¸ªExcelæ–‡ä»¶")
    print("2. å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶")
    print("3. å¤„ç†æŒ‡å®šæ–‡ä»¶åˆ—è¡¨")
    
    choice = input("è¯·é€‰æ‹© (1-3): ").strip()
    
    if choice == "1":
        filepath = input("è¯·è¾“å…¥Excelæ–‡ä»¶è·¯å¾„: ").strip()
        if os.path.exists(filepath):
            generator.process_excel_file(filepath)
        else:
            print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
    
    elif choice == "2":
        directory = input("è¯·è¾“å…¥ç›®å½•è·¯å¾„: ").strip()
        if os.path.exists(directory):
            # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
            excel_files = []
            for root, dirs, files in os.walk(directory):
                for file in files:
                    if file.lower().endswith(('.xlsx', '.xls', '.csv', '.tsv')):
                        excel_files.append(os.path.join(root, file))
            
            if excel_files:
                print(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
                generator.batch_process_files(excel_files)
            else:
                print("âŒ ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
        else:
            print("âŒ ç›®å½•ä¸å­˜åœ¨")
    
    elif choice == "3":
        print("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼‰:")
        file_paths = []
        while True:
            filepath = input().strip()
            if not filepath:
                break
            if os.path.exists(filepath):
                file_paths.append(filepath)
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        
        if file_paths:
            generator.batch_process_files(file_paths)
        else:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶")
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()
